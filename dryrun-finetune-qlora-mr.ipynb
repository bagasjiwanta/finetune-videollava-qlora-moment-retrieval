{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune Video-LLaVA on custom temporal dataset\n",
    "\n",
    "In this notebook, we are going to fine-tune the [Video-LLaVa](https://huggingface.co/docs/transformers/main/en/model_doc/video_llava) model on [a-temporal-upgrade](https://huggingface.co/datasets/jwnt4/a-temporal-upgrade/viewer/moment_retrieval) dataset which is comprised of 2 video-related task: action ordering and moment retrieval. However, in this notebook, we are only going to train for moment-retrieval\n",
    "\n",
    "Video-LLaVa is an open-source multimodal model that can accept both, images and videos as input in an interleaved manner. The model architecture is pretty much similar to [LLaVa](https://huggingface.co/docs/transformers/main/en/model_doc/llava). However Video-LLaVa leverages a new universal visial encoder to seemlessly handle both visual modes. As we'll see, fine-tuning these various models is pretty similar as their API is mostly the same.\n",
    "\n",
    "* Video-LLaVa [documentation](https://huggingface.co/docs/transformers/main/en/model_doc/video_llava)\n",
    "* Video-LLaVa [checkpoint on the hub](https://huggingface.co/LanguageBind/Video-LLaVA-7B-hf)\n",
    "\n",
    "The goal for the model in this notebook is to train an adapter layer on top of the model with LoRA and enhance it's temporal awareness or capability.\n",
    "\n",
    "\n",
    "The whole training consists of 3 stages.\n",
    "\n",
    "**Stage 1 (this notebook)**\n",
    "- Training dataset: 640 samples\n",
    "- Training loss: Cross Entropy Loss\n",
    "- Validation: IoU\n",
    "- Gradient accumulation step: 2\n",
    "- Val size: 24\n",
    "- Val steps: 160\n",
    "- Early stopping: IoU\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-12-19 14:19:43,434] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to mps (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1219 14:19:43.831000 13398 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t-i.jiwanta/dev/env_ai/lib/python3.10/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    }
   ],
   "source": [
    "from project.dataset.collate import DataCollatorWithPadding\n",
    "from project.dataset.prepare import MomentRetrievalDataset\n",
    "from project.trainer.lightning import VideoLlavaModelPLModule\n",
    "from project.trainer.peft import find_all_linear_names\n",
    "from project.dataset.utils import view_sample_with_video\n",
    "from project.trainer.metrics import mr_iou_score\n",
    "\n",
    "from transformers import (\n",
    "    VideoLlavaProcessor,\n",
    "    BitsAndBytesConfig,\n",
    "    VideoLlavaForConditionalGeneration,\n",
    "    LlamaForCausalLM\n",
    ")\n",
    "from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model\n",
    "from datasets import load_from_disk, load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from dataclasses import dataclass\n",
    "from lightning import Trainer\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks.model_checkpoint import ModelCheckpoint\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from lightning.pytorch.strategies import DeepSpeedStrategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    lora_r: int = 8\n",
    "    lora_alpha: int = 16\n",
    "    batch_size: int = 2\n",
    "    max_epoch: int = 2\n",
    "    val_check_interval: float = 0.25\n",
    "    learning_rate: float = 2e-5\n",
    "    dataset_dir: str = \"datasets/processed\"\n",
    "    num_frames: int = 14\n",
    "    num_worker: int = 2\n",
    "    hub_repo: str = \"jwnt4/finetune-videollava-qlora\"\n",
    "    accumulate_grad_batches: int = 4\n",
    "    limit_val_batches: float = 24\n",
    "\n",
    "args = Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('high')\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "stream_handler = logging.StreamHandler(sys.stderr)\n",
    "\n",
    "if not os.path.isdir(\"logs\"):\n",
    "    os.makedirs(\"logs\")\n",
    "\n",
    "log_file = f\"logs/{str(datetime.now()).replace(' ', '_')}.log\"\n",
    "file_handler = logging.FileHandler(log_file)\n",
    "\n",
    "log_formatter = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\", datefmt=\"%m/%d/%Y %H:%M:%S\")\n",
    "stream_handler.setFormatter(log_formatter)\n",
    "\n",
    "logger.addHandler(stream_handler)\n",
    "logger.addHandler(file_handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The processor for this model is a Fast Tokenizer based on Rust. The patch size is the pooling stride for each frame. Each frame is converted to 224x224 sized feature-map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = VideoLlavaProcessor.from_pretrained(\"LanguageBind/Video-LLaVA-7B-hf\")\n",
    "processor.patch_size = 14\n",
    "processor.vision_feature_select_strategy = \"default\"\n",
    "processor.tokenizer.deprecation_warnings[\"Asking-to-pad-a-fast-tokenizer\"] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a custom dataset preparer class to hide the complexity of loading and transforming the dataset. We will now see the raw dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video_id:\n",
      "v_2Sev8z4P7pE\n",
      "\n",
      "duration:\n",
      "45.279998779296875\n",
      "\n",
      "prompt_frame:\n",
      "Your task is to determine the frame range that best represents an action in the video. Provide your answer as two numbers separated by a comma, where the first number is the first frame correlated to the action and the second number is the last frame correlated to the action. Do not provide any other explanation in your response.\n",
      "Here is an example: Suppose the video has frames numbered from 1 to N (N is the number of frames sampled). If the action in question is \"a man sings on the street\" and the frames that has the most similarities with this action are 5, 6, and 7 your answer should be: \"5, 7\" (this is an example).\n",
      "Number of frames sampled in this video: <num_frames>\n",
      "Here is the video context: A man rake dead leaves in a backyard.\n",
      "Here is the action in question: <action>\n",
      "Here is the question: What is the frame range (start, end) in the video that best represents the action asked?\n",
      "\n",
      "prompt_timestamp:\n",
      "Your task is to determine the timestamp range that best represents an action in the video. Use the provided frame-to-timestamp mapping to associate the timestamps with the actual video frames. Find the most similar continuous sequence of timestamp with the action asked.\n",
      "Provide your answer as two timestamps in the format \"mm:ss, mm:ss\" (e.g. \"00:10, 00:30\"), where the first timestamp is the start time of the action and the second timestamp is the end time of the action. Do not provide any other explanation in your response. \n",
      "Duration of the video: <duration>\n",
      "Number of frames sampled in this video: <num_frames>\n",
      "Here is the frame-to-timestamp mapping for this video:\n",
      "<frame_info>\n",
      "Here is the video context: A man rake dead leaves in a backyard. \n",
      "The action in question is: <action>\n",
      "The question: What is the timestamp range (start, end) in the video that best represents the action asked?\n",
      "\n",
      "action:\n",
      "After, the man mows the lawn.\n",
      "\n",
      "answer:\n",
      "[21.729999542236328, 43.91999816894531]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_dataset = load_dataset(\"jwnt4/a-temporal-upgrade\", \"moment_retrieval\")\n",
    "raw_sample = raw_dataset['train'][5]\n",
    "for k,v in raw_sample.items():\n",
    "    print(f\"{k}:\\n{v}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each sample has:\n",
    "- video_id: id of the video\n",
    "- duration: video duration\n",
    "- prompt_frame: frame-styled prompt (asks the frame number of the action to the model)\n",
    "- prompt_timestamp: timestamp-styled prompt (asks the timestamp of the action to the model)\n",
    "- action: the action in the video, which the model has to find the timestamp / frame\n",
    "- answer: [start, end] time of the said action\n",
    "\n",
    "Now, we will transform the dataset to the format that is understandable by the model:\n",
    "\n",
    "For training sample, the format is:\n",
    "- input_ids: Tokenized inputs with shape (Batch, Token)\n",
    "- attention_mask: 1s and 0s tensor indicating which token to attend for the model with shape (Batch, Token)\n",
    "- labels: input_ids but the pad tokens are swapped with -100 (ignore index of cross entropy) with shape (Batch, Token),\n",
    "- pixel_values_videos: pixel values of the videos, shape is (Batch, Frame, Channel, Height, Width)\n",
    "\n",
    "For the eval or test sample, the format is:\n",
    "- input_ids: Tokenized inputs with shape (Batch, Token)\n",
    "- attention_mask: 1s and 0s tensor indicating which token to attend for the model with shape (Batch, Token)\n",
    "- labels: array with shape (Batch, 2), each element is the answer to the question, e.g. ['00:20', '00:40']\n",
    "- pixel_values_videos: pixel values of the videos, shape is (Batch, Frame, Channel, Height, Width)\n",
    "- ts_info: timestamp information for evaluation with shape (Batch, Frame). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = args.dataset_dir.split(\"/\")[0]\n",
    "processed_dir = args.dataset_dir.split(\"/\")[1]\n",
    "dp = MomentRetrievalDataset(\n",
    "    base_dir=base_dir, processed_dir=processed_dir, num_frames=args.num_frames, num_worker=1, processor=processor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = None\n",
    "try:\n",
    "    dataset = load_from_disk(f\"{args.dataset_dir}/moment_retrieval/timestamp/{args.num_frames}_frames\")\n",
    "except:\n",
    "    dataset = None\n",
    "if dataset is None:\n",
    "    dataset = dp.prepare_dataset(use_frame=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset['train']\n",
    "eval_dataset = dataset['validation']\n",
    "train_dataloader = DataLoader(dataset['train'], collate_fn=DataCollatorWithPadding(processor), batch_size=args.batch_size, shuffle=False, num_workers=1)\n",
    "eval_dataloader = DataLoader(dataset['validation'], collate_fn=DataCollatorWithPadding(processor), batch_size=1, shuffle=False, num_workers=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video width=\"640\" height=\"480\" controls autoplay loop>\n",
       "  <source type=\"video/mp4\" src=\"data:video/mp4;base64,AAAAIGZ0eXBNNFYgAAACAE00ViBpc29taXNvMmF2YzEAAAAIZnJlZQAAjRxtZGF0AAACrwYF//+r\n",
       "3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE2NCByMzEwOCAzMWUxOWY5IC0gSC4yNjQvTVBF\n",
       "Ry00IEFWQyBjb2RlYyAtIENvcHlsZWZ0IDIwMDMtMjAyMyAtIGh0dHA6Ly93d3cudmlkZW9sYW4u\n",
       "b3JnL3gyNjQuaHRtbCAtIG9wdGlvbnM6IGNhYmFjPTEgcmVmPTMgZGVibG9jaz0xOjA6MCBhbmFs\n",
       "eXNlPTB4MzoweDExMyBtZT1oZXggc3VibWU9NyBwc3k9MSBwc3lfcmQ9MS4wMDowLjAwIG1peGVk\n",
       "X3JlZj0xIG1lX3JhbmdlPTE2IGNocm9tYV9tZT0xIHRyZWxsaXM9MSA4eDhkY3Q9MSBjcW09MCBk\n",
       "ZWFkem9uZT0yMSwxMSBmYXN0X3Bza2lwPTEgY2hyb21hX3FwX29mZnNldD0tMiB0aHJlYWRzPTE1\n",
       "IGxvb2thaGVhZF90aHJlYWRzPTIgc2xpY2VkX3RocmVhZHM9MCBucj0wIGRlY2ltYXRlPTEgaW50\n",
       "ZXJsYWNlZD0wIGJsdXJheV9jb21wYXQ9MCBjb25zdHJhaW5lZF9pbnRyYT0wIGJmcmFtZXM9MyBi\n",
       "X3B5cmFtaWQ9MiBiX2FkYXB0PTEgYl9iaWFzPTAgZGlyZWN0PTEgd2VpZ2h0Yj0xIG9wZW5fZ29w\n",
       "PTAgd2VpZ2h0cD0yIGtleWludD0yNTAga2V5aW50X21pbj0xMCBzY2VuZWN1dD00MCBpbnRyYV9y\n",
       "ZWZyZXNoPTAgcmNfbG9va2FoZWFkPTQwIHJjPWNyZiBtYnRyZWU9MSBjcmY9MjMuMCBxY29tcD0w\n",
       "LjYwIHFwbWluPTAgcXBtYXg9NjkgcXBzdGVwPTQgaXBfcmF0aW89MS40MCBhcT0xOjEuMDAAgAAA\n",
       "FypliIQAEP/+94G/MstfIrrJcfnnfSyszzzkPHJdia640AAAAwAAAwAAP8j+NuVUetgS4AAABO23\n",
       "IUUjBX4jH5TgCAgRq9Ln+Q/Rlq7OZAupyn9i3RqjBYWhPUOxMBvooVRYW4nsHOxO7IcOubUO7PpM\n",
       "CoqIbegvrj7Rf6fQh22Zl/eWfI2u0QhLfy7k9AwMzh4stemByqhWqu62YZCfvXKEV9feYJQDLhFm\n",
       "ESNAo0S+t6FMVfPCWdW4I8lkCab/qcHwrnsjDe0xYoJvFZ5ZSaAf9VW5qOIh/kxOMBaaL76gUmoC\n",
       "kjaz+ZsjAPc+/Uy/x1kmI4K5vfJ2MVn6gE2GkI1LVciTJlmS9QuaAyyiEOiWg5JwtIxYQQ+dTIhl\n",
       "KiEZAOOyatbFECPIbPRso2hbwyx3aqqsLtYwE4o36VUOcsjP3tnX/NJpRsnOOOtqxqIyrfrQXfbd\n",
       "hl2aM377hmMU6ZdNgLXQ/V8nH7SymPD35R8BFyakgw9RnrgwApbTgPSzUj/VBoKvUu14Tuu4fzT/\n",
       "fYhjwzDRXU/ah9IFF2RzPyVzdPVeZpdgDPEl2pzMA/GzaVEH3SGlC2yXqgpF9eez4Nl1t3XP08TT\n",
       "O380NXRXFrTmkHr87NPsvxHmFFKtyEMMdunCnVV3AMdvu9dCobDmmcyFD1FCQjgOoPOmQpTYaWVJ\n",
       "8u84Jif9Sbgn0eTTUgMAUHBx0jYLoftwnaqXdaCEN8LTSTmCfujiRXfJpw0ppUVRulPRutdeAPTK\n",
       "TMPurhc5WyjvxtqSXfKCAA7J567JcshYVLfg8moWsOGYLsp7NvN11AXz+8gqKIHnopF05CiKSN8c\n",
       "2YoykWiUMEHOO4GtFRHyt+CBBlbd3qcDAeIZuLsPLpLhDt7BYvsLXiv0+yqUZ4279mfkiLVDiOHH\n",
       "/ng3dTg/ilvEvhGP4G8f4rgmFb+ZtW1ouYclR/GgoWA/nKZVRJUrZYRUQBSlSCATM41FMC4OjToQ\n",
       "aC4qKh0ZJW1Oewl2yFOg3AhGMsr145AJuJPLyK3256PI4XH6IlzPYM5oOAySaTugKkraTMNM4o9Q\n",
       "vsPRCSEF8EcqEKMesl6h9xS634gBf3RnawXlvMRKUzah7hOsnFOTy538pE6mQLWp2Fh65xgSVuW4\n",
       "Cc4k3XIKrKtj+RZ914INYirG4IlHmr0FzZg9HXmfqEsvSOKq4JHBPhnfwP7ooKBRm2kwnKvMl7/v\n",
       "RBU/tAxFcLdo2KAQ0GcTG286vD31keEGHSXDgzkd4nwSB4JF6WoSA70OpdWH5mOxfbia7YZXyDaH\n",
       "8S4GlJ42MEkb0jLzO2/m/CVEHYrqgSSpuSAY4wa5q2+S7dXgQFvsbvM2JRKi5ahqg1am5wOh1OHU\n",
       "G1oUAiB6M3kO7r0UCxx4xr1MPnIq4vC395/kroPCtgK1SQQdOEPr1IPpfELPxAuzOLHoFIxSRSVx\n",
       "xxGer74M+2gmQw7mm4i4I40zWpZvZncSGL+Nv2RILQyrlrp4uHmq9zckpFcGOpOLNxsJjoqiePxD\n",
       "4whc4Y4iYbco8S/KyuH17hG/iLbMMNC1LxYWD82ElO77d0mPNE5bWifvKDkbIGp9xyhOt+Mw8nsY\n",
       "ecMcVOcp0GS1txCiLWdLbeXU5yZGAb7fCP2HjIg1nOQ1OZF5mxi9uhRUMbtLwKkivXna/3H1Hu+Z\n",
       "XB51eh3nq79NvWp3OH/u5+IrObheaohh7t8J0Ipq4UPCO/a507EYBjRGkPebafq27BbpiwVPPNB+\n",
       "wHtF8+lXm1zprH89MUP2geUPQxque/8DAuUUlq5LG5T1TaLLezDm5ZdKUdHQxjJmcMl8+svLJmnl\n",
       "YB6otb/2iY+H9FCy5AjNEFwjgDGz+IOygCs/poIK9QgFHzRUgzj088BSh7LJvdgB/Bv1WVP5ywJ5\n",
       "fFjKwIIodWmKQw8Ex95yDPopXTdInNEx2CBOFat3iwszNvaXbwZuSUkRWi9gYRSQnmpge47EJv7k\n",
       "azN4A0Javzm3X8LKlNPfAxzZ9mVGq2im+Ngf+YtiF2gsofgobXmRebE41fNxmnT2NRyw2ZOMhpXe\n",
       "Rw0+fPn7v4hq8m6n+9UrF49JwvK0SlzBUOUlchQuYEMV3LYkLscCD8TzC87xX5Aep9kuDroDo1in\n",
       "vLSW7I0I8n3ScXkPUlUgQU1z8zeUwvuW7099ptXH91gYHC3w05Q4kqK4u8zEsL/rip8jMSxumsmQ\n",
       "V4XWA3Qf2DdcWT7SFIB6iG+GNVP/n06fbrhKROANUIMW8ern3RN+y95jmLwEh1GhKfHYVlqQoFqQ\n",
       "S53cgp3ojuYol3tFYRZb3Nk+cP+pWJ0ZyhnfaGlyEmJMGbIj9iMtnvVpM0ohmmO/mUE0NWc+p4pq\n",
       "AeGjaNfChfCSrpSWDPICmWogmG9j5cBefHejuXJdHJdyRgF48qPc7BTp3XrgDVc9nIn25z8DFY5x\n",
       "dCK6e/QW7aSFyDxeYHiP/3BdMy5WBFLA/lapyAUA5LzBSc2O4IhJk+eLeW3P5Pmi4549OZm1lCrw\n",
       "846e1dBQkOEavVP1NSIt9wSe1IhfznKQAJx43xVuSeIp3cJjSi75cbG7HnBAuk4KvP6+xPvtAJDs\n",
       "WTXkbQkbEwCSc1gHwT5Klnp4F3KXf8JpcGfHQ5Aw6yQsRhAAwgfu7+qGKBHTBRqN9CSeWLlnT+fb\n",
       "/OdPuVrFJfG9XcBUkXd8s/7NYYRV4Xqf1IlJqjiHcpxBTpFsVcyEP35/vDgWuFEskTjOr0CxPZcD\n",
       "AMOUaab/1QXd3R5Gq4vBV6toSZQE3TN1NYhdKK9m7xANhmHq5REDm4TRen7cWiGMjESWJtzI1ats\n",
       "jPbg0n3/YGBDOSdJFPjfmDIUkjLgItZAZuiys3S3USUzHrCSjBDHp3Yt6EdzGfYI6IpzNtx9Zd/G\n",
       "kuydHHxrajeeFZum1ToE8DLXRSBAQCqRYoA7a+f0qRREas6aogA5PeD5gL+ClFDUqO8Ao/do5u5a\n",
       "4gVg/lOEM5laec7H1PwgTtLa/vKzdbgAT9u0bjUvI1/6p9d6u1j5gxhS4joqEUkhWs5lcgq0Qo0R\n",
       "tjrSWP6t9RmoZy5KM3u70S36HYuoH9zmQ9la3r5ywMGoMKNY2QdxYnnD1GB8axT9JhOM24MWfnTy\n",
       "Nt6IltqQN8RJc0BRPWIkNhiGTU3bTzgMK9eutNOk7fmQu8csS4wT63v+8+fBbBuD0TiQOvsi6VUa\n",
       "4QiqXaFu7JZUAExC1fJLoKi+npG8WcDnnZLC7no2RyX7HUTAMWviPjOWPTgHy0Ve/cPLln9Vb8SE\n",
       "rmjy5gXaBUGzTttW2jzYLxMHPHK8Djcy9+CzIf6WMfDVrk0tf+d2UXN9Ncw/s0U6LMhNuy3cEEY5\n",
       "IgWm1WBi3wipWPoNfFX5nfHYuDlBRAlykXEt1YGMkiWwkNN+wxZF0zp+Yq0naS/4ly3kjTfUUTdN\n",
       "X8AQ9gA4AatiAaFtAeX/Hx9I5qegAFsaUOULKrCkTPQRBTZ1xRupwhNA0Bqxj61ij1yI7+F4wHXf\n",
       "YmJ88Z6bwdYYF0FClLQAwE4r3dE6FC4nyo8DAz9dcvOuv/VJR7+qXvE1sMRUciN6nV1aJu59Qrn8\n",
       "qipaTiDg0GQkwN0LScAGZren683PmQmGT3clLgjqXBKwEm5fV77zqFWs3KB5u5m4Xng2QqKqhkss\n",
       "NYbbq0uPPzU9Ib5wLK2WKRfzKlZtyk6R+31GdZkBefWzYiC/u90Jv4ydyICAD+556Y+LMyyMkgrh\n",
       "Bcbz+o12KAJaBvhcGKJVewKrNSpKNCmFWeQiEH+HHE9qLINVyAprdGcEAsJGTSAQzPyy+mH++ygx\n",
       "G5UyAxtRZA/QV8spf7a9fPX6BtNlDehrf3gt8rN2VRQh+DVZDVhgDlPMDBaf6FdtAxtUKKyr01SH\n",
       "7cjo6K/9zMmPiVD4J+jSrcDckDNIY42YH/CgC4GTtgK3y1YVlcu7l/FmNj6cO0R/XSAKy/bfhUHr\n",
       "n8sdk3ONmi5DCEcSp+EnHZWya7YSNXhkl9wWBShn1IV9CvQ66iFivXLl6T159weTxLYPu2D0XIX5\n",
       "p0z4P+hZBAnvS7qZ/oAVv5fyalthAPi3JJPuhrGs5NY6CMhS+9zVffvroAACQTOp64a803Y+BOkD\n",
       "1OVrtj3PqUP4rZRkVzWxAT5hCVMWvv3k/v7R1ZYmLcDpD2UeTSPDWi2P2sHuuzzT2siUJHfC1aCz\n",
       "+inAgpdYyApy+TexpYojuzArK4XiMIM9tf2J77vvQsIHNprDRp7ko8hS8ZS1bNZ6jbrhe50oHPTi\n",
       "YI+YBWmwAfhNIz4a5c8Dm1nQ/dl/Yv7k2GzIAxGEI54021ybAPIc1ZlnbsRR1SBefPn1OIzQkh/R\n",
       "cmY67RdIFkr56up56xO/D99Ib1eXXOniSkgAzx/LWUG01TlIvvtmL4SMM6TUrCdbXILTiRu8lRZj\n",
       "PnY2aanL7nk0thc+bAqoM0gguRsH5zawjJrJsHl7hOKqqSoUcfHZ3PP+pKm3VazgjSoA5YQ0CaOe\n",
       "2keNq/H4zuFao0/3NbodvlEi094Roo5f8Tv/EKgsXdHSG7H1nxwVc1J9zRevvoQoumOgVWIx7tbi\n",
       "48EvGkLIF9R9lO7TIC5RW9CzHJkYLiYrEAtQhEMNIG3fD4tDJXlg+kJmQ3Yam21rwVN7FzTnUOwM\n",
       "zYhsWDodEPp7CdQg7MjfPcq1/25ab6SL3ogmSrX39jpcpR2hqma+qNjzEW9An3ZJUuLt8QwiDbyh\n",
       "7c5M03RhvFVTclzl09ovhVaOkogVfwoZrRGKtHCDGsLePNCjMBbh3gux9ElStVhiW6YrRGF24Yem\n",
       "2gQpBkdkdKAuhdESv63jOogNgJ2pZOJyAUa4mIFkym7su5HmQlAd3PLboIcmUcXJ6ah4TWmME8xf\n",
       "P4GrbwSP6f/FSmIVf3yujFL7sUQBJeVBQXikmX2iGAEr67hEdL5kZ8MWxxQmt+qOo6mjIZTbPe4c\n",
       "FA5CaM5dZFNVKVwMeNtBav5zwOeEXzyZGMPssnAzxw3Pwurxo18NfVTvnny2HnqLCCse/i9Tok1E\n",
       "8nELoukBONmMHhBQam2qRzvBykZGo4TQm4dMcGr8TDLpt0YKW9GYeznFtN0GsQAHiAWBG87QKmfl\n",
       "ue9cTedn1RYH1g9OjAus58TNqEe1EfhhOnFONxYKvhyaTvQZbTzu4uqpr+GvgZJRSALIFT7HO3/G\n",
       "PnuYLuNYyZ1HasWhLZINaN+dqBKEf89E5Xoomy7D1lPmWPVk8gVI3gGKLTy6FLCZilpXebFAMvna\n",
       "UK6tkOoRSaeyJu6G151n2kIEsrVzzfgngX/FOYSUIqyI9gcOVBTZORFHVAsZP12csespbSHOYOmx\n",
       "o/8PvrkbmOowFiVrGDKnMw8kUnBv8xWr/ieovHVVmw2x7pjVD1GKzDHRSOs9WaSwmdGvT+/I/cRU\n",
       "GcjK0JWDNWMvF3rg0qVsKgvujMzrgWfsoBqcREXR7LWYRpPeOhXC4IS8mSy94ByYAZ57R4ksgtlj\n",
       "XMwBYnQ2+tTRSR668yBxt98APwHeWbtzgdbs/zqxLPSkllX/QX/4zG2pCkgLGOVCud7wo02DandA\n",
       "VJahbf1RkQ+YCw4a6XXUMwOsLdFBKO1ZkAhJAyINlyDgKLVEP0wgCdbDIwARwB9t602bf2oExkuh\n",
       "31hzuYN28NH4/0N7cL88UUFdLRqp8s/+buxh2zNRHV+9jIDlxYO9C35IbjJLFpbtdm+vLM9tz1Mg\n",
       "8t3/0oeSZzNVAsFB2DReDGpdL9k0xFbSYrc3jdnwVmhTIfvj8jJO2CSxCdusIzAcKLHfmbvpW4pH\n",
       "/H4SYi32VhAz4pSBBxaojGxWAcnHGQ5+6MRB+HcJkQakvhr2QcAdU/LVWUPHq/jodyLCPKj2l8ET\n",
       "4vgdLnqmaTFSAYmNyZDyA9oUmMtz8a++RUymcP7zKQ+XchEGUGQmM7QBcVcK0nEjpv8Nf1SsS8km\n",
       "ykKGXLzajGYEngV6khnrFX4yfrUZ+ucfT+RfJsCsCViiJkT/TxjCv38uxavvAzYnMyBQKQjSqCqL\n",
       "Q0g85h2ePvZLItBiWSiunXZW2Wmd1NrYndWi1SZL6Iq5gI8+PtkeD+B7qWw1qWML73Om2YTSfxSU\n",
       "jFseApSugSo4xGYF81N215n2htM41fpsxGLFzqpGBmRFvoK/JlINuVOqKJoAZB2A5LUOzN+2IOT0\n",
       "eNEUO5IDnLQsDvQlp0rbHjcw4+iXWbxgP4TULYJ64hcbkZvk9S1KRqfvvTTl/YYVU6895uB0wGze\n",
       "RPCNc4wN4BEhslKEmrleQWlP1p7As81HygKkbMa7YN6zGn5zHQHNk1lcC+C+V6XpJNfghijLp0K3\n",
       "6rsBXagS4W4s/jVK/F6R2ooZaZi9Icd8/cE5QC0galz6NdSPQ0GmRM0LtRCOIrnTSh6XggBf/A1N\n",
       "s5EPsXFXoNLgDC5hB4Pb7t4p2JeBIXbKGIQ1+CUz7A9bG6bqNP9bQl6FeGUrnMMuHV34dCCI6hlc\n",
       "jNhj5IEAPVcnav9xgSTAFYLXk5qKfIQLXu/rO9MiA18QFY8TXNwdTrYTPrDZhycAgcRersXALRxC\n",
       "IRZ3JTDwIr1w5zBpZhuck1dz3UjNkyx1UZoC1iCdJ9uZHlRy/4AuZPqfUSkDYEWsH26dkWv+oh2i\n",
       "1tMKgF6FQhyk8Ou04HiqFL984A5V+y9Al//pfVEcgCAZZ8ECTE/4+FF1WG8oLGFNL2kGexRBVeoO\n",
       "jbJMRa7Gz3p5tkwtwo4CrHINtcnPZ6a6+chXYCWO/vNykx5VIU1J5HV+/igWblPZkLAqRIlKUuw6\n",
       "yMHHaO1X9x4YaOhKD6l6ObcFlAP7yvLPgeyyUDh0brmRnmFwYRN+J0sMP1nZjUJ30hbPgP/Dydet\n",
       "lfcIv4deDhvW4+5VpuTugRXTrX/otwXBapsmf59tF+u+xWtn1mOtheT2PBfKtLG4cz9r9cBwyJWd\n",
       "kxRXeHXkjpHxJVUmSrABCaRjgHAg1VsPudaPMJKcPKtQ4zNxsDmH42m26Uzcclx0mmNCX6kRNzs2\n",
       "ytVZAHNFq3LRaZbddmMpu1IesMU/O/DRS/Cqb1IsGNWn7Ty9Vhc5+sIbhCob01kJg9EyLHAaem3g\n",
       "KyT6JILkfYpVLkDe1yuMaljcL4FQ+7RadNq42Iz+zxGnT143KwcA0dwvLBg+XrzHPEbEoTtWvnAc\n",
       "WXHqNU/jEJWCN5LXexbMZqsAbGz/uyRtafn3sFXbUYtEfo0nQ8PS6UAwRJMFJF+YXiqVUvR0alFt\n",
       "2CAGIn9/lXl39mqzxxnMVdLOOoUZJowd0IaSSPERl77rP43+IV3nmRT92aULMByHRFs+suUFPQoR\n",
       "loWvTL7XywsdaCHQFc9M9zHjAi1zpLRzlclp0/8uyM0RnONoJKVD+t+sZ9+GwlNJ5/tljimyR8wI\n",
       "DO560ZjaVhnWTAD1M5/iUISGS6ytqIhxNDWct3NTD7XUI436f0rN7R/5kXVbMt7rMkDur2WXlZ1L\n",
       "62cmNW/rsdBpfTnJDOJhm0u026k2N9CpyrSyYaA9/vQ5/2kzYCrhhaOyoxVCXc8Ts6QPrrMPs7Mn\n",
       "jmnafHOHpnAJKgUYWz/Cx4zPGZlhcF88xs//d8MJ5GaODJnyFf/WNWime33rsIhJhGjpYTDtR6Ew\n",
       "FBtkDSL3v9JyKF0Wb/fK4tq32ZjJewj715EDeBo4en3cUOZIqPInPnzxMSAxg23mmci4Ahk/NEda\n",
       "Ah4IVEOz/j9Ca3a3JzWWDKfBmcMZW+lshsrNUchN1Ne7MCs0P01DSXRO3g5uDAAEe8MyVPXMGaTK\n",
       "6i6kslys1+OCwhMPCpC0iVQo1eToxgthaavJJ7U7HBhtlTaQikTyPjFkaShvyjbKfqAMqtKKBcQo\n",
       "McD3AQ7qWRbfG+KTLImaeah7+jJXCliZjzz079NafMUTMNSONUftgU8+le8LooeYUALXVFTgGTQw\n",
       "AAAZMQAACIVBmiJsQQ/+qlUACQ8ufsXF3cQBBtu//hD94ElAAlnaNH6fHZbiauCkyjRh5P/yoRNW\n",
       "dfOFwrxykKNgzp/V8acR0NzLxdhPLfAh/WLO1rrMZ3Ca/6xZgpO/QgQVcVWAQWz/LU1dugAOMJvG\n",
       "P+M343Nc+16eyeI4t8EQN9ayDLYnvK9zI41Ro/JXMMHyOQEe81xqcnPiV6F0paQIcOKbj4cQ5pYy\n",
       "CpW58uXQAAADAFYaceN2ZoyRB80mlvRTxMpqqEvIhFxjjtFSJToqEUgScvJpDnbiXRCsoKuzpcPM\n",
       "K8gABweb0BLFnU7fMaRKC0jS2mL0DdmjnreO2nGsse3i67yb08i2C9Tbm3U+7C/jVHO9/UPFV1xz\n",
       "78LQbgj+nAB7mK3wLSOEnAqMSC5m/lpTceKC8t+zI+tcB3YG0W7spM1EuthE2iGGk4xeBV81iMLu\n",
       "wF5aRhtGeAn/tX4GJIm1FLtScdqNflcqCIiNQjIOhbTxEmOR/YYkbRmtgAq23CI5TNItnu+oe4a9\n",
       "kW0QRESzn1PIoNwh+qZ5b8JEBD+ZK+JmRd0TOtOJjzMPZ1RJH42UTt7KUHOpJvLj78fl6C4at8l3\n",
       "ptBUucL6oT9pCUADibVBbSNP1rS+dVblc9vb+1xtJ8XiFA7vn9SFsClb2T9vBCtSQAtVPVFGRF9E\n",
       "gbBFDFE4u+Vwo1qcE8jcfovRiVHusEPRVMiAtag5SINtNt3Jtdw/Uu8xQBg9TOd3YqT6rGHyfIHO\n",
       "WBvyYS8Tq8but8SODDyjeyN5XkzX28QT76xsWF1GYwLDeFsihZB5HOhyzHNqk/05N4w+XfuWMiDK\n",
       "gQklBYVicpuGEOt3+ZRtFbipoXx18rz/wEM66BC0Mdd8s72SvlJVhEs93j+jzK7aXJXM+Bs/zfUP\n",
       "XbK9yQSCdty7tHx+Ok7paUNjTeCgXbKxRD4y+ocFFs7hyPZnVQelJRlsqQcuAfTBHNQ3sRvz9tQ1\n",
       "xUr2brfA6ae9Q1a5h/IT55JZZ1jDRy792TRw5NTNX8N2MWIE4PxJW/GWDtp15qMltnM7iu+an+3a\n",
       "ZojaTNKIItGq4s6AvAPA01hqXCFouSC4Yu0+x1tfBswAB9Al7Kx2LVmhTyfeMrQkKvGm4XOoaMTs\n",
       "E8iViNV5W5mPaVEMIClBgFcA9IIF7mzxtbgoofpJFhWfkF2eIIp3+npcjihbn3jttFdkmDfhsfuE\n",
       "Uzeg9f2eWypTPWIQxik+yPKAFYQA70mtVuglUFqry8k6Nz6OKxHIAA/LATlZ8yLZAFSofLXIHPMK\n",
       "XBw4/vK1XjiUaMMcUgw8R9ylMBszWlUnvQBiqYmIbOpc5JrUsFt+fgSoBNxgpaJ4TRIUO70XSkhc\n",
       "Iru6ZADQ/s7AdC7zbv3FsvZRhQQM2XqjIJhxtrlFKW9EdgaPCEIkpKAZaDX7U/DCvgmva1Lx+0SP\n",
       "xpS4Ev1wSHaS2HNWEHvQkKpRLoL8xEAsKG5hhUKL4+qv4+WoooJVkDnw+yqcLchcswrCfc+VNfvr\n",
       "dUx6n4uYRQi9WvU3+kKvn3HiLnI2zofQQGZSCW3Rxy3BqOvi9HYrLQ20SDKxG6If4Nvm+2q9HJQu\n",
       "ouubeiZlDSPkKkcCZJwHZFi1VdJitUnOKHYKRL4HkBykP2P2amjVoA5q1zfQyF5fOQ4MeWbqLFml\n",
       "iu3viUlwUr9/Ckb2ed4tD5sH54QOBMmwaXxV7fasUj/q1hGGmfoIPgAAJRj7CuVXa3dXd7sfw1Ht\n",
       "E0gK0/2/rXTNSNZrLMVCw0A87ZGUF/Bzl0o7fKUyfDzsOcriqI85HlGKIV7WQUaeYDLuKoXhN/dX\n",
       "xJPrB/j3S6Je0dRk7KQObg42vqNPEMlI49ikiF+IvBT6dVyP9BkNPJdgofGQ9oSZmPapMYFYLmP2\n",
       "4dECGo0gqF3mQLeH/C2c04DmzbH4U4aG5d7gRPqfs0ZYsKsBzgrnSM1hPAYlRszBmO0UHQBoiD/v\n",
       "zrzB9dJ7+pUinTde6fQrvSHkWFb1Cpkp6c4OKxSKPyKDj2IKGFWjAKeVjWyZNCvbee19aAIGOvQg\n",
       "f4NSMpKzDkdA9VJ9SZUAkBQubV+S61w7a4WvBPsLQvcb2SJgHK+4k2rOI8F5GAcQwAnDXSNoAL8n\n",
       "k9rN6aHgPOs825Va4bNeiLerbvhBgziIeX0/f7tlt5r17CxKvfNzvxHYcufIy/r8FNOPjZRHl+Ku\n",
       "HBvpeN5hjgxDOoxbqioPET7xm4yIXDm/A6T+xHiJ0kWiv3RIVx9Gj/xN5kbtJHAWTD0/NV9yTCPh\n",
       "4HSAhTuKilNl8rrYamurzWS1DALJcCt/yN+DqyuqiWZAI8AH2QpsQKyVOuTstOU+jJa6tUmxTCH5\n",
       "bhRy5VLJADZ0SuMl5CZBxU3Rdh9yVhNGAWwYoM4oIabsHRN+jE1z3R/Vyy5twfi8cECw1cQH13I/\n",
       "JruNDPIKCv59xFUQyJK7e/iIZIG1Om464+HYhkDDD1LiyesnAI1dGaFLJNzNF7k8F6YcDrBX7RYd\n",
       "LZJxNBsVjPMXLg4ClKguLbqy2n0qlV59gMRh9uymjJIVOJ6OZBZGb6LukZ/5Oo+3VY/iFWFz0es9\n",
       "pWjjkc5Yv4reaReQsaIa4Ya9JwCK0SHxvFJ/YFQSwAbcaxLwy9MtfxVLHqVTduXhChLGDyOsy0ju\n",
       "FYkyMzsU77U3gHp1CWHk57X8vfoZWDHGn0hMsA/Amn48DOA29oazms2Mm2WJE1XF0U9zFcqTDptq\n",
       "uN/wCKXgK9bpiB5WZ0jl/5Z+Q7rGhsbg9j2+t0y7hDGzq1Xp+GuX5nHHCZv325wad5A4xIr7J3oa\n",
       "BzuEqtyv5OXWOZ8JsHI/OD91rVfWlyidWCQKlkPQLOIm8mmvxI9x/3cQl2qYn7e5HVhQeKhdxSH1\n",
       "6DGLkfLV2p/pkiUT/X6Ll3a1i6npAZ8AAAh1AZ5BeQ3/ABkcHMe+9PzpigA5tDSx/ZS3VmNVB1qe\n",
       "ACXMKpne8dOIw04nCjRQu6p22KLK/5vHQdqehS0rj0YmqH+A2M3cvshWdzQX2ZewjjrxqgX/9QPx\n",
       "rtR2A1iV07TOodtkv+Jid/XzcrSNFDUvIytT1HIAWQQyS2GGOWesSjAn10AAlCFHAu9QcS9SSlpj\n",
       "9esp0MyhzAiSSbRe9d0yVAuHJo/4zUPhxw/O6rw/hSz9qK4qo0tcKiK+qElLhheNps68vv+A0W5x\n",
       "WiOH43tU2E24eAU5NOUfhT5bC2zLv20nNC7kpGxo7q2Ntd1dqr4mmiqpeTg0nShnWGIhETp6ytEZ\n",
       "zweHOBf5Yy9L0CYamkc7oWepvuff5sCKebyojONC3VavYz1ZnvFqmQ9OsTpoAV814iW9Cq5JMny6\n",
       "RYvsKO4vTsjNopt7ZLVH6JaxRtXtQ48BG5SrJ0TUBGjUTj6THSC6yyMn0flk2ktPiYn7U9F71Zsl\n",
       "BpnDPHoO9CqokyG8pl0BPP2e6DtFBMZUbuGez9BYx6iW5MREOGCshxDzXVxGrrrMWWS3cKPJfsy3\n",
       "TfkTSYpxZwAVLX/laLq/TjVAapXm509xyegT0E+8zt9JVBrtzb8hHgzBFbCValrEYTsOfpBQ8VU3\n",
       "9hdcfIxhF+vQkbBHvaoH6oD7+32NtP3hQgkujDCIfEvcG2VrVS1zcg98DAxdAWcvKp/eIdVu6bxk\n",
       "SF9X+zeL15aoIOIoJitS6wan6pGGdpFYHCx1uqzs3Wycrvg8JLcPUynorJ5DRCEy7S64fN6K2vMQ\n",
       "IMTH7BQoAviA/4rt0oNYMknOD8a5NTwAKMKSoVIs/OGex1V1aotOA2DHscVLEO8dtwoxA0o6N4la\n",
       "g4eOURPOsePOaBCUmc338e5QHRdJz5gZd8GrUMPlfsQmBLkUKxaK1Rlhf5zbjuniNvd67l6mHbmU\n",
       "NvcyrozLEHA2vwq4RoGBatd6MroMwdkLCciiqOd0EXL6yxK0AllYW1FfkRR1RgXuJxz3oVhHFVTy\n",
       "P+h4bTuawzUxFLY9ty6VYYSbLSDgDsq79VI4NEnNe+0c+9iv08Bp3H29H9rzBfiHvY9ndaZMNVUk\n",
       "GraZJdjknz0oUEFywty/oR2ZlKttqIolAshkDhgOz2fidJcSZbdPJJGg+4GMvzR2bCtx3SZaDYRO\n",
       "PnvgebmDdiOo6He4QZKH2R0KsidKkF3k81PhiJsEn2f8weq7wYriAGAUHs+eks+5bgHS45T0g7Vi\n",
       "yI11OROhso8YId6ZCfcq90bVaNveqlVZXjV72dWHCdy+TynEgZ+okoY0o83E5f35HfeHgCpWy/JG\n",
       "O61kU50XVs2urMFkNt8pHpWVXoJMXQEzPQdcr261nfV8bddratl3gRNSGneCGADSPUb6ffpY58ww\n",
       "XQcHoM43YvO7r/72vGqvEL2hmKB3Qq7MOP9lQN/cDCxc+S3GmLbWaqc/dqHapTtFK566SIJBTV7+\n",
       "BnK2WbvRiIdR1XJr7sfGSwZ8O2BucJw8EEYhAmXrXeb0fNNfoZEmDWJSR+NazB/RRLqa6vowl25j\n",
       "hK/gQUF2/4d1IAiFvNxqgxrR3pZrYBo4xHWOHXVg6QTZg2iT9LSasUU++lGSLKodeH7uuJna7CQj\n",
       "Uc9XdLS3llX8veM1vy92ws5vAj5Tdm3Xx0TBiXBJPLoHgaWSne+LW56FtoNOB4GEYSNRvRrk7orw\n",
       "mtJDG3hYCAvHP69XyIID1VrswTHPmj27Buv1PNuv/87NrdgCicxmviiytvebCiXsvGNTCyZu5d/x\n",
       "UwcExG7r7DA2Y4Cjal+NfTIklmAP0ucaVw4FmH5U4+5B5DZSccwbFCHE2yVFlHGKaTuIbRSCMJSP\n",
       "/UGAk76TmbUFij1dHre/V5lABtam8eR2P52KFMKueo59mMMrmSdWHMWALjCX3AhpVEcPRhAZe0UC\n",
       "UCSPzuruiYdWccTnSF3yXCZGpLWUmqAqwFa+zoJGlisHax68FhNv6YFEhrGYxv9Xm8qkv/65xx0j\n",
       "OqxzEDsVtaXdDIuUbICf2qnaM6+W38XErwlIGAR3tYhMtSvS80NFmM0zgAvL3PWA8+2Z3UALPl4q\n",
       "H2ukl64DAlBExouRU0eWqIl9X+TJKP76G2lliLAiObUiT+lStts+l0xUs50yxnsecBh1EIpxIc9l\n",
       "hYAcmXRqCjVx87oanyJoqJsKj8ZLa5+8zRmFlbwFMiVMydu3l2a7PoEOK/5fjYBPtSdoTzAgnuDG\n",
       "V5qdL/i2TPZgWMRX79IvTrVDoKfWhOeUgB9vUi6gf8bh2U7lL+IOs/sUHaAA2zF9ynNah4SqU5bM\n",
       "cKXrg9gD2gONFNV6s8chKLBGr5oQfKla6c+jQ/JXkTOpe6Yow8/ZDWkeVwZaC3o3pk+VvB5ox1Qu\n",
       "JgIdOwTfWDDjdpVURdaD3wJKIRfsmmXJJxcZLocuhYMkGoFCZf2VVolUOwKULtIqzkqxoFPpvwOx\n",
       "Xb9mrOJIljWZKjI91c2H/Wv352LzIP39xt+cT1OrqVln95Ixll93eUtsm7i2EdT4sIUdv1FWrprw\n",
       "ul2sphYdqfJyfaJhvz2F/ajlmekD2tNlsTMvUSv6lMYJftxNONXb7wMWhEkD0HK7WJyJyaS+sjsG\n",
       "O+94xeDvLlyCMdoworH9QWRBjEa3mVWKzOOQmasHofWO2keZttSauWrJ7yMX2PZmW+E7l3UeQ7XI\n",
       "4VBdK6pXBHz6jXYQftFYq/Mwxa2/vu7Sb7N2hsXgQPMoXUmc/kCKLg8uUj7ObexWuA1QrDzzA/Oi\n",
       "4XzpMJP8t2k/hIiypahWKrCHCGjTMVqJ3Frh3qWV8IdTSE+n3tOypmO9yrrpE9PPsgalfH6dXptA\n",
       "1C6h4EdMVG13pJGw9xCzsVMDrHDW4/TS4rcAAAgJQZpDPCGTKYQQ//6qVQAHf2l9t+j08wALsn9h\n",
       "ictEuu/OCcEA5vin/PjGx4hKLr1E+2NLTq+ys1ZzFiR86I5i3M3y7hXLH6Ph4bSv2GUZcO0bYM3J\n",
       "wg/uw7tDO2mLIqjPIeR8Z7FhnAwrS2lWK24BvxTQiOjxxyWPYJrhFjZCYFZWSYE0RdYwCbqp0+hy\n",
       "pQev4lKjTtqWKzgaCVEms0C88LoDithbC/cimNfDDYzIuCWfHpt2zJD438qH96fukRug5ElhQAWN\n",
       "b3me6dzIIazsYXnaOM8ogpRtxfCx8H6PkK4zVGfmJE+bwYqwjnIvFKyKfWKZBNCLbe7jNkWxw5wJ\n",
       "ZbKfyIt0RlZpvwXbL1xPt/W2TVX0UERclxFQ98xOmlISi1+rhLIDczvHFOAc2rJ6aUcd0yzA5w9V\n",
       "Gxoo/ldCWI+XhG9dsrmUgUS1mxcXZJJfPfY7Gy367umiXWtyHso+9I+hp7cBBUA+nsuWtyyug1Tp\n",
       "buROSf/eQr3EFZCGuJq5F0EKgwtwAw8hBx4VeA9pNNor+KHrJkWbY36V6TTd71wCdfR/DeyRvQ5n\n",
       "1eFJRYkl1k1Sc0DbP7cc9S/0TC8ZZPFNrDHc7V9Wc2MNoMCRskb5JOw5MQpxtDvjPB+Z0p/vn0Rf\n",
       "663Vl1hgdoDSmekMuvj8O4WJaN0KAEX9lIOydOM11maMCMXMaPq1syvZOMnvif0W9WMqAp6Y2agy\n",
       "9YcwM5D61LYw8Sg27MpLXrGC3Ako3t4GaWkkztSSEIsalXMXb4EKhV5nINyzQqtmJuDrDHin87Ec\n",
       "IXr4dvjuOqJ8YhVIQ86uTOuKI83T/KKtO4b3KTk+ERVXYGwPoFpkMSXPWcrkGKuv2tO+hUwW2D5I\n",
       "vKv4gqiLune+pvu/0J5XyttpWuG7v9hETZ9Un26S8wR9nu3B2GNQCM+GjjgqTLPkbO/zoKy+JGA/\n",
       "t5OGvM7066rFJOaxEnFlJSaIRE30hdjB+LqlCzb0UZ2k3aT9ZGqho43/JpnsD2w25TJzKSt9UwqK\n",
       "/k1u/2QUdfEHt6GDUi6s2a3KwM2kHwcV/VC4It0s79Uh3oIToXPdh/fOrB9e50VV2UUAEASYMHSd\n",
       "ydxKRVRwZHlk0EeDqzTxmvIezxPqbRHKx06+vOnDj2M7vkQQas9SiVfkQrAMbrRTAUTN6QSXgZ8b\n",
       "qYSzpC690eZ4dGQljTyc60LKHMUOaJgUFfqJNMKXFhfG6MCuLuW3qX0CA7zk9nawGiisyP7pCfTq\n",
       "joOqAEbX5LwczT9fxEOPzdWbJ/bNwNRwWMvDJKcOMNQ9StezWROCtA4uRxqSkaTrfgFq7pKiYQgY\n",
       "Rwymy5qNdYrPEkqUrDd9vjwK26t8x0+u/6mQSoaAf494jYY5V+LBor8lu7Gy4FQ0WPZnYZCfw3cE\n",
       "E/m2s4hhRZpCLCkw1pWlZKu7jCFDJQut23jumtLwCvGiRbUjcSK2Uq2Bcaybd1z5xWJf31Ykf+JE\n",
       "fOJUg8HLN0/9EJ+9toQ54qav/plTvkWzJZYwVfDu1Hon7XJX0CrQInwZGCxPeuiWXPKqqpOlVvLr\n",
       "DgDFNjYkz7pllODVRI6c8CAzB2ycsx0V1iydKPgvroCatPX6vTcg5vWzEnSk/1q384d4DjpgLLIx\n",
       "6Sq1YODQPIayU7N0kpIJswOliW1uSz2hs/DDOaNEAUChXMHAoevGqrALjg+VaWXNJmpagYmVeX1i\n",
       "WTGbmyMaCnhpxrMJ1y2iCy11nhF2UmSM51ux896K+OBhmoY1VZAz7YnCKOTyesmRL/K8/sUnn1Ey\n",
       "Ca329NRZrBPZpjzE9cFSfKIYIJbaUsdYjEOKyW/l2x92oNo3qSNt8UdzpGTdYYFoCTgo2sijm9/W\n",
       "bhlJGGufUchf0VI57BSP60k0QgVCDyiJ0mIo14nvtBS2B/x9HClzkUTttgAVTKHmEu8iC7T3rC6S\n",
       "2psT4yaNDYPCTydOjaCUiBHwvXRm5yM4jlQ+TlP5pzh5JEhd8X2E8i7NF/t7axwICoPvR36ylNpF\n",
       "IlAtJqQ0HsqrJEDMW42H6S/J/6HI6kFs11vS3wAZz+cp5SGEXfJz9abkTf+VbyDktS07DtI30tcR\n",
       "waWtZOi/YUjlG70m/kzmbcRxxw6B13qVDP37MQ+uwqAV42qFLG+8Z1Bs6W2w9x82WhtU68BtHt36\n",
       "eIEGug3NSoX5aepIl6D6SYpQ/xEFlCYtKJt/dPQXu3s7usZH5bYg+QmeX5JRY2X/Am9Lq4Bb/4Ol\n",
       "c1IqaE7HJ4wWbxlhHGTA3ELX4elC7K2D+A+2Nv59gatXFz9CuNlV+jBnJilnlQmSoLHmjEj1N1j4\n",
       "QyXFDy/QNvgfjtX7Vsa8qFYDisF041LMNhIbx7qNs/QUBpHa11LWV2sxprAi9yitbJFf3tr0lMp4\n",
       "U5yzaIFjWvOhZ3qfSd7uiWxxfXZRtGZ9WvV42uO/pBMU/Q2/u5y7/m/72gc4AWJYu8F7cn4M+f1s\n",
       "T5gbo598xQ2fSEkIUxDBVKq/NGv0IJfWTLle0YieQ++NqYdcNy4ClGhEnJw73gKmt/QOot+sHMmB\n",
       "y3L4jNq71DOxoaGPXjq9Xu3tldz8TcIK4b05+vuaBRwymlr5ovbolOED3RC6LQh8ZvICMBcVcKLj\n",
       "lvZFRe1G3kLXQcst/IksQIM/+PGEt5NhOS0Djz51rCLruqC1Lw7SmREJpbdM0XsXRqiRu9pZLPkt\n",
       "rqcD4KFKnrQ4Cy4dbfoRXvUjmg13N2hZ8tja1Jz5pS2v2QwAAAnoQZplSeEPJlMFPBD//qpVAAiP\n",
       "Ln2hDhegAsmJab9hq9++w+84eSNX4dlt5d75vDy1IAv0aDA3fc02YBRaxEt+17vSdZ6oJIo7Q4ix\n",
       "LZa88oEPdJUpMYVe0wzFcWNnxvfEBiJOHN0MFIG6rKotfaTHJ8gcvUe8G9UUa67bqx6cqv4l6hyV\n",
       "dKdlDXu9E2zhKTVsV0qCXWLrHfEcU3fHzfANLP2GhWxLh77gK0WNAoFO4WfN9APF1KF8a7dqF8VY\n",
       "NVQJgI6FjP6GWrXA1cySBjhk4wYP87mg1nP8snRZgcbRkxmnHyq8eYcBGQ6hGjLAn2SyyzMAjyOq\n",
       "y7n1JQN9YBWUItRg76oDMQ4/ynzjPGFhuFBUk0NNkEWkx+lTUIkPjGc2R6JgTZWZRneJnmlydjBB\n",
       "Xn49n0XJLMq3p1Wu5Elx0n5MV61TJDojCTiikt/hVCWZRTbwDuQgwW8TKcE47tvzuvdlg/dB4eX8\n",
       "X7st7bPknn9ohS1yWatEDRsFLRnfadt7x0yUWixpXrsw6G4ULcwtPlifIJ81fJAbbxAOK9cE/C3b\n",
       "b0d/HOHBeB4VvblUCAqlXI6v0XPINN/4MwKnUEGUbupprAcRkcUE9Wec7RBbXOCRwiJQEWgbWgKz\n",
       "6hNSqBU/7AjmS8f8MtGSMEn31+5FJCqBYxwPco7IfK6L2kSTgUY3OFEQjlP+a86NlpKJ1GytpVeZ\n",
       "fupggAOcdUsdVJx3JFx0GeJY8/VAGVMlkmOFf8W1yStv/BwoiF0tcJZUiSzmTYOtWf0IQjaAGi8S\n",
       "LZlO5bHlh2UE3xHb4AM6236UHtvuH4U/2HzRulAstWZTppF9r4uhK15ICBvvyO6Ejp5md1Vu86yZ\n",
       "MVxY38L4+PU1YXwKzhp0D0lzN/quNAOAciHE3Qbd7rnAxoPbl0BdRm+cgIIrvMYRx2wab8YztNtL\n",
       "CpnJn/Smy3JEmIjwiJ3i+inSiwvq4sE3fp/xJ/RVU+8KTI3m5RSndMgdFQSE/x87Sp0lRNrXlzYl\n",
       "VU5QAJ5wUOimewgWBqlskGEbWaCXTruTfOUNPhrqBcwshAEN6gHjFLQfl8qfJhDs/GT4iQ2FehVW\n",
       "B3drB42AfRwQh86PmgEMyuox152mzb8kbX27rZjUbU5ZMfq16MgfGHoRIomwdDNbzoHtHMaeR0dE\n",
       "Wa8kUeLhbL1pW1RKe1cDNmJNg64NkUFsxKNO9chk5dIt4gcPUMF2jKeZvhBVdngZkBHb2xAuXlXI\n",
       "9OKwlqbkoYHJqzw9tTWoRKpHLQGzI1FCcg5jYwvp7Bx+s7h2bk9zQt0+CUc9d6b+BunIG7kVhBXP\n",
       "Q+XiRQR3sTMFLsdKVzGQDcLNi2mrWCrW3F71bKHGA9VRnIgomMfz3vqUdawS/luiVdliAwOYnTIH\n",
       "PDJ+i3bQvpzlRo+9Tj2wE8EENQ5/oPTTfahi1l2WXTjtGXdc8qGS7fpUeUF/bPJJslpcw1pSOdTi\n",
       "SRt3yMme7WUdBpVo6WJNgbEPQy1wpj+EoeUrCIvNCBa2n/WiD0JwZ/dhfMLJJVIbFwk149yuf8ov\n",
       "7ouwNjyEL/3vMMpF3VDnIOCGA1JdDxzM18RiJKYey3GDQrv3/3FUwy/YxVjZHC5y5cB/mzJLkwxl\n",
       "Z/69zB938W3EYwdmvLZ91IvSJ7z1sbBPLHSYVsqRN1gdaopp4qHLRTYODRthYaOnZIwCad7J+Hwt\n",
       "Jz8UqoUgIHrxoaJvKZSO/w949L3ZJIjrAckK4SyWK4jj3m6qGmdn2d0dpEBYh0/iNZmema1Aj9eH\n",
       "kwmeZx7GIxbyhsrwTOWyWNRICganwY/7FGyVPIp2M9h1Y1aAi9SdXrTcSPpnfBGMX+aZ0qnXlSDC\n",
       "RuDxLwqUXo9zCV/cDgXCHYZ+HfDIn/gYPh7S+1PuYNMfI7rpi1DOrubxhYuKUXry3dQlZSNTkl0t\n",
       "bYBXv0yu8UEM104mM1eicJ8Clx7snigex2vcOA6VAxgAFG5EOoOMjBU63I6k3PBQdJjahz9X/Mlx\n",
       "tRHR63GgtLNPLYV2v4P8fDwkwRzgS788c6JNi9ozqsHpPoqEPNC+OI9imavyoXjGfkuvfi9AlP1z\n",
       "mwUOfbp71NaLDNC1q129RFViZKJYWwjWyt+xh4NRwPQ5OtwZo6S4GO7+5iyO/EgVk/xzbgQ/aq1z\n",
       "kNvwUrySnRELI83bbVgXdPvlbaSb0pX+EPocI215I2gwFHhxe2kO3ccOAyHuOe5zDO4/poAelUSe\n",
       "vz4Rj9NP9PGGRfjuFf3JoBtvKbTGVWy0bzYsdC/e+jW+qi6ewWeIcFLkYm0h8q8Q66fufHrUaD3E\n",
       "H/wkGHBF8N4iXSX2xB0Y8z1FgUTv/gBaZ6DN6lb8lCQPHvikxbwq1HRYNu8K2diQOR25hYtEzGsS\n",
       "JLQjgMSCo01Mv71GIdoUlnlFqiwSF+7sfCZ2FIqeESlPbfRvZ4kt2hHemxn7twJUdYLRKw9NMpmr\n",
       "cNzQPAW/ulnyMsr5UiNAOrJDv3vVfe+0eu5oaSHsjXjjCQyAHEVV2Mi02mw12AXb6B1Vplr5/kw/\n",
       "Jul6oKwkFowCVTwLpzHyHfw4Nmt5ntIz2v2aeXigrGqQivGiKoZ32E6ODptpRoe6nxbwi61jX0ci\n",
       "T8dkm1EYFJ6VR4xWBKvjWKCoyGYfgvDqiJ1CTaW7v7BoSFwbGXO0vBCq/S+40EMNJJNgS4oCH34V\n",
       "X4f4onPGb+WuLgSLWD0FETy1HNh6+jikWCfybsf6v6D2c0SBdT6hPutI+4ufwWRpbOiRA8TNSCeP\n",
       "e9QgFSF+P0DGkxXdLtic4CAv7xEULiHijTJcc8xtyCYrBRDXf+lXqYmYKndjz6irovwZaSqZ6gcj\n",
       "E5ujCC1ESVOj9gQ4CKYjNZuFamNt7SJ5uTD2PKS9IZrWZgSrl8IuD8OBlwkLd2xI2Rl47kiMbufz\n",
       "TupZ8NIowjp1Vsq6VqTFmREjFAUEt5V85kKRTHqe6WtDbu4zw0gp98WLRsw/VVdWyLWUYOoIb7e1\n",
       "LyeIhs5GRdBw+LbuiK5naeGvMCB55H6mjXW+eXQEhpM9k2yL2Je6+gFXuqmfnB1eeInl01kQ+yz6\n",
       "1aX2uvVWZbsp4r5dz3bEW4XzRE+usyFhnMnByNNwwk4bVvVJ8pakt5r+iSTkTaHnqFl8Yh3WELYj\n",
       "UzJS30cS8tQX9MEEWSl/U/pVJWfiBMbvI24IJzA+Oa0ui94QoACV3Ui1zGT4kXEE0fyAK2hXrVhc\n",
       "CZ+rFZZidbCdXINGb+d9/r5WJwv/zhsAXYwen/EAO/21RheNgFMNMbhMadxbqM0ggoiLYijvtuOa\n",
       "MBowpPxc5QSAieJsXKsX53WsHM+RrDq/oPT57Xv+ilOMpj5j3paLMDnxwK1i35yX5HsWlLYfwc/y\n",
       "8pa+Ge35O9sJ1QAABesBnoRqQ38AGR7wXKEvtl2ji98/1V8EfUG8bHDOQmoSZ+a4zS5rQwr2peSM\n",
       "4ZgwJTPZYM3RJAcUCMAhZfXnddWHslClvPJEeWJrUIaLFNWfaJhrA3q3Sg2/yZZgc/7nawQoUxQb\n",
       "t4ygg1u2AhPyfodJJCKFSq1ysTefgKuVWs9ufaGLipohXMHY07msHjw6kN9ZaSVeA8TO99xrMQWC\n",
       "b5XFwcl4qShbxs8+uTvaDO9I6APVvLWTJ5h9ghLt7LFmSNBfWM7UH2G8/WTNeSBlfpGlZZ+oHSSd\n",
       "NU1rzFpNM+UHYbmJjuJN7fhJ57NUrDU5h8e/S6v4nWwYBMXhz4YUobrmMeiJmPCFOFDhEr8ZY4wF\n",
       "s94wKf9b364JqPvDYIb70q+Le6kQG/RfEhWRnoxxfrI/2a08f8b1lMiJ63M/xYlKF3mwLiKo9rc6\n",
       "T5vhkf5WWmnnhV25qhnXs0dTQ97z4GH6G/kQjRthtuJj44+ukl/pby4Ju1CI4gbmd/3hfkmNo4G9\n",
       "ym72gMHKY+mVP/x95nSL3Svvz8QEQ8OJ+cHbSKMZxiKrgCS8DdTEgijcmmrMI5/jJD846qQS/ZdZ\n",
       "lKwmh//+J8zD4HbX2wPUCudqWFbcZaKmpUO61ktMsteWzUAen+aVfEaVzN/TrX94uks7vIxAyucK\n",
       "B20heVPhPb9Ej7KiSPOpWVm1zLA/imKZQmKSvuorjZWFksiwhvy3HuW/x/gFsMZkILqCeCRF27hX\n",
       "EPVgTMv6kIGVO5IwTkepFh3HSexgoUNhvKCdZassPLfq7Lpe8KVpZLch7+LEb9HKGvxvi6rp69UV\n",
       "eXHbM7tTAfnnCueDkxzWjT6l3LWe5l6sdomr92dpdZuh2lM2wCXnyTumpFSP4X/ghUdZTe9jSbPx\n",
       "bUFuvFOBpwOU2PTlfJg551/CeoC6RugMxC8owDDxGVZYNlaQeaGOopfkmVJhnfTQz6+stgPXjhne\n",
       "6vCH9k8lM8FFYW6+Wcr3X6wbI4yQfzDQ5PLc3RFbx3ahTNbuvz1CrXE950YlAhCCHqDC98zWfeOc\n",
       "lFQPLez2HB6gP6mZar6WkAZMQSFfQHnD0oJp2hy3vPR8Oo7E/ywLjm/dWNLs1qAe8pdasVby9ql7\n",
       "6pCgVTRv45QaoV3UnyT7q8SfOY/Z3+u8/WpNXPXNq9QHtYU/cUlQBi+/BaKUJ4p/7JyK7ofH68FH\n",
       "SJzOkinSZMmkXmB+3t+nJ8SJ8/GyiEH/zYMbQduVS09NrrW67WInxIx/ogoeR+xo8X3znyX+VSPf\n",
       "ucaLZunfkvpyTq53xLcr1bRbN2yvYvfziwzXKfKxZLtUuwdDn+mVBdnPNgCnesE3rPHxZW9s9gFX\n",
       "1Ko0M7gSp7oTxvq+n2xBf8nKvlxt7VJg7HlrwN+bYeUy9b+2A4LF9s3lS13Q8TgTX3tqJaNOiLt5\n",
       "iZNbUmEzrzuwfhn50Qc1OLpSBI43Qu8GFJldOY/tqY0mDFKngxTH6VOGt4B8AVNojAN6nSiNvXcF\n",
       "4A7aM/n1q1vlFOlkOo+zdj5YB6VAV/H1wmjhKum74pCFEg20xoepEbIFU+FtzXEIwL89U5QlksKk\n",
       "0PDitxWRvK/ZMbBOSaoj5Wi2vm0udRGFrb1yrMkWLQ2lJHLF9ZnHIhJ7nuF0KbOC2HVXoNiOQncr\n",
       "uijnry3ulWDlfcCxdi2DVmH2Q+nbs7hFwI8gaDPxNi9t6QEbj44I7OOahANqXqTFExbwbvbqLO4M\n",
       "AsY6EA23YWLvsKuWEzGHt/arn+cYQHm4m2P2TCvKCGQHe+YTWZorrSJQHgv2KZoITA2N7aVXJOgP\n",
       "Yw05N6gd8IfGoz+63mmxdq9k1SPeewUB5lxLEZNu01m0gQ7h6dzxl18Rrtq95rEWhJmWXmYs2t5O\n",
       "KyfUdRXsF/IFQ775D7XVFIiweiFeLED/bhH8IA82OeuGNeJumaNKCIOVFnlNu9RaL6Ijym98RVJK\n",
       "w4PX2dPl4Yrfwd79nl97gZgDHZb4JVggCJVZ4jfnrnP7mWYlS8Y97Sg/iXQom4EAAAdaQZqHSeEP\n",
       "JlMFPD///qmWACELMnzLjGLA5zpGiAxQVGF2y+RbnrpbjB/vTjOPAAbjCV5XymYqdnvVDnx2xlHg\n",
       "/qPVW2xPdMUgQAFpeK/gAAE9Pry56jqo4cQAAraO8xps8lVMz+mmfZOpMZ8R3cjGKM9CtTCQz1qk\n",
       "gCIqoa/RYjdDUPBUXXbOhu9EFlhjIjOuPwo6jx0kXqcHi8c+mlyUdiZWxED+5oBI+PcR4AGzZ/Xn\n",
       "szv8WyC6HKKZhRxdiLlkx3xohAoyD5E8VluOEf7vzOQ584dVudgT4OJG4km3e9tAAakRUeAvygBt\n",
       "+KnfIf+RatArta1sKcq2QDle/PVJN795vqqVRQXO0QfikyJWeV0tSLE2w5UtJyzsMWo69Y7G+V6U\n",
       "0bqBHARI2+gFRXj4sLf/il0fD6dPbVCfvWGA4tmztHCA0lmdxiUjYI9XuzPEfm3lXvhIrm67VxFG\n",
       "8MiSulLZ0movxiuIssE+Dbk7Rjitfk+3HtHwFccSUpSIlJaBSMT9fZy26Api9nh/pxiVzy/inrhU\n",
       "2jb1AVUnnmyFlK1pmTxfQldZyad3IcNLJaOICloZWhF4H8LwSZhZ3esu96BMvawPMvyuTK2DG3qk\n",
       "1zml2Mg+RjZlrNZSPrPUJAF6hcscHFFSt5n+Q72Dc0q76JBBsTMc8GUGB2ZC6HDE86ZpOMxYDh6f\n",
       "MK07mtVcIresgb9yffmqxSOxrgfvM3Fu6D0z+63lomqiG85bKPPerWwfv4D2lRfZ5boW/2pfvdbY\n",
       "inbMGSHB0+IX7/6GyPIRUI8SXbVzCUE5INPMnwDfgFOO63XmdKJrImO5KyDF9CR4+adlelZhnckc\n",
       "P+uNuZB0KXs1O6R60uRR1VadEaGZcbjX9izIECnkswecP8N0uGhtojnLjYxBmDPFmw/XUsxHUrT3\n",
       "f/+Pa01O/FO+XkCuHEYW2+DmQCCLaRHOSYQ49W58/3gP83mD4QJb0cOf8ZtPaEBBiar/qYe1i3ax\n",
       "Cu9y4RST1oap0PcIPez3ivc3IT+vMCljx3OHN4Mf5EOJyfVucae6y0/EYLMtSRJSs1yaWPedPIzu\n",
       "pK3rmy1c+ZsXJS+TQEg2m5d6Cguu3SM3ZhIqMKaX7Uk+84ua7cX/6ARAH3N5cqVzzr5wSeRVfDgm\n",
       "MlnoR6yMop13vDPQE+KioTG4pwoeKBXX5t0ILdlccmHoc6yMLtqbclNPg/zsVb8L+knIFaMx31IH\n",
       "QmMCIyfCSxYX9KLQ+WxxeenE4sS+751xbXPtu3J3BrLQVb+5Vlx4ERktDK5Pij0r2+zabJ+kshd1\n",
       "BpTJmpv+w1MCOFQkrrgR8z6x6dikV42uMuaiDkOJxKPpzmjqV8IYd02uikstLkw6/62CQvKGW3Wj\n",
       "LxwVG4+v0iX4d3tMZIHq7qZeiAuAfiWyAGWs1MP5hCqnKS4tjFaL1779NF3QU8tkoLXQEPcMi2kV\n",
       "m2nGDsJGfhultW8bkWGbKbG7f/hs5DMB/AA94KOwPNv8NLBMxeyNuFzigUSQZvyniBLFtkIjCTWP\n",
       "KTrrj5uAyixQuoxCo8FU8ySyAntJUq2v5sqDcHkB9+ABxsmgf6c+WyUcym7Rzhl6yuG40qn5HvQu\n",
       "24rP3Pag6qHNn0v7YWG7enKslmUmddHxMyOuEyLqLDtCD1RK7WlHdJWBirnzF2/mRwEoHmxdCpyQ\n",
       "SKnw40APnCtTB2+j9NS80ATcETUph1mchgF6xVq0MHn6jYM4zz3oxNcuKS4mIFE5SgOKjcTIgoKe\n",
       "iT3jguXmX8SBan4+soGoaSBcM31FZkpa1wwMB1n/OTy1Pyz5HgAcQi5QoPAM/hgeYvwYGCGftmo8\n",
       "cx9+MCIfuScJuYrVHad3HV/jHDkGo3jxeGon1KpUitPin7sSnRzpS5gqghjvXXadXVWlY4zoipC8\n",
       "3SPY3NOmPxzWpu17HMLEpXPo6j5eqWpD1Hhm9j8xCGK09oqV3Y6x4ocZ4l3GC9Yzqdpb5n2QW+KA\n",
       "AAmXA4IEQjirMm3Rks2+/LEgX6KAjo7Grsf6eb8Ne54oHZJcTgoDcqN/1TtWqnNAXuNgYhzVEmKy\n",
       "QdL1U0sB21TwAQBpRKuuHLgk6Ye7nII9TmxR397jGIIJUvzAw+/VfBflc8B3V/b1wB3p2RsDbTN8\n",
       "OyohQ+OxaeG0cGWOo231zBlXO7TkgAEcc72fOVqpHb75rwtRTlGleqbHDSR/x2RJ9SxwSvxjJqwk\n",
       "lU8f6LM5bmu/oiv6v7leJneX367+Tri2wW7aNwZ1a0E1SS4AAEuKSviQA0nDyDfkMErb4NwPxY2B\n",
       "CiDboYLnu5C5ilrbv3YjOiXa++kNa5AEL45biidWAddit9KKivizG3r8wbaozWjmbSw+fAJaD0sM\n",
       "0xiVgO9uHZE6HV48KMCTSuWIIceLTgw2sEsQoAqIm/OxBG/su2ZjdPx8kgb0ukXC1K6rpOZlLh0W\n",
       "Tt2ucAyLIbbXrUQUlI1cT78WNI1MQLvwjh+5tq8E4rWTAvvTJHLh/5BM4kvOYEt1i6Qh3QAACQsB\n",
       "nqZqQ38AF+AFDWdCDTm2QADROiAAiDqfSCxt12fCM4u+fFTfqZ7SCYO5pbHb749DTAr5GbL7/bz1\n",
       "0TP8HQPc30eMxCiYgwtkAIjSNSQ7HgOyJH5/0m1et1+h4T31nt1w6RZtN8HyC0uopaywlyL5vB6z\n",
       "PtvEI6vaAAX9J3K0VBeWkLUYRCU/2Gl1ugTC7+La0KiMc+W7ze18NyzBO+dPfF8zJI3OYc7LylLQ\n",
       "i67RJt2aUmXxmVlNPxc6/lkkTcWdUEo+Jqp2RYqv+LwybWItvMqn+jV0wK3PxqFODgO2UQW8W9Ko\n",
       "SLv+AkO/7nh4kffpEokb+AOrxX9iVC4Z3/R5U+uPtvmQ0/Qso0IElI3X0RTg/Jy9r0fSQ73WLRVo\n",
       "zLseRCgP174D638wZKUQqs4Pg/Ht736KxPHnzJ5npOZ4lTiVuw7OTQ1aliMrQ2w6Bym1ICDvsAH/\n",
       "ByxUmgJ6xYgCfcnWNJepJDYz7hiOaaTP+LmDdrf14gvmTQSrcHsrIY83JJo4XrFIBs8ZFwO/Tr1j\n",
       "9ytZmUa5BQ635MboviH40PCeuVlFnQVZ917RxbyAAYFqNBBVQAfHj4UpLxEa/5UZOv2CLM4MzuKg\n",
       "HuxzZKH7AY7aSKoqMsYJ5rn1I5u2XlJRVtY5+iBi6QqMwMIYquroFkeomQoRUSpEPF4BCkhygNlN\n",
       "eYrIpqI6kte1EO6npyeV1Vwh3BJ93pI1zbAufEHUPfLL6TsdqPDl6mrYlixpzzuNt+bmDUpqSxyI\n",
       "HypnhJPZCMcpeiukNmfZ2mXEN9mAlhy81vsBZAmq5Ewwef5mipcHmqn4bAWqnmuOv3eobnpatmJq\n",
       "P/AJ1C+mvpKdDGoNs9s5pD5erRdIAeGNabyk//9L+n44pJVoeDN03+8GtMTZGhBpOEp7LH0rAAGU\n",
       "co8+KCq5lZ74s81INxttqygZTDFXN4dyKGVjr/c8AUCEqx6F0KM7rFPmhq1C89UQEkCv1WAEQ9Sz\n",
       "FbCPkRnAfPX2cXpphkQJCRin4dmQKHjAJylQApSLCOibIS4bq0UVJvXWet05nUNdmmXZMcp3gfQm\n",
       "snkbqvV78ivy6VCZ8xR7R0GA9E5wbLBUOlvDCYTZ8wHOYOJQEQOMXhPFNjDCVXx91ofT8M+Xgv5v\n",
       "4mxKweV8E9ZhhIesMAsAOiu5NAaAQzVgc2lGdVYkSJVqzgD57xBJ+qnFg2h7s9GI0YT3iHvY0ZSy\n",
       "r/RUzT9r/td9T3oiR+yh/Ct2Ngl57YpAt3YeXP+SQYQwR9maUM0vul4W8CTh6Xpl1EKHKmZcDSd0\n",
       "vriVvyaEykK+RYTSiEsS9jzBvPLw4WtwKzBJkcxdgtM661WPf7gFLdwImk05METlp+uICUzwCpPh\n",
       "UjhpknGqG515T18V53paRCn8clnaSNCy+4mWJv5jX9hVabPghqDdD+3DO5uChwF8t/oJCBQ5mcfa\n",
       "5M353PiCpnxeDqipMjBvY3bZtQMC9JcEuQxQ/3wJtSTEsY8QnuLKFkT1eKpX3NR2FPU0mLWR5jrJ\n",
       "JnYQ2P4RW+wwftK7ghtpahFnprCvmBwchUXfwFJYb0jAgSCJoTJqYe2kuojxYgnsxJWm1a4D9IDN\n",
       "1daIRpobeqAt7hxPiUsN/4QY5+D8PGFlimXgWq5wQUU7zdZeNSc1n0khQotbqQnNMfHB7Vqhsgk3\n",
       "CUa2FI/3CnAs6jY85QPVcPDToEtxdc/Lialpufz/omKe3SKZFVwuG0y5KZ8dqLkl+PQJFCFaLZyD\n",
       "h/5KvqbKEvmv3mpN5KeQvNxR/hJCY15oqe/SJihQ3oFkJdztBpkgMhenF/BeWFWw/orrqOsqsa7V\n",
       "VAoJmuLbRr7nVXgFV7u4YnMsRAX6xTveMhj/6jPzgGx+omQ+tP3/OWeUNYvijNCZuZr106yO1yuY\n",
       "vDuHvQ2SUd8YEO8VwW51ZjRPu0kIb59aLRSZqtf5bYtrcc8bDDs4wszDfCqT/24VMFs+gJ9L1jv3\n",
       "X/jGOn4+LeOBKnXu7AxqCJP2UVz6JiRT+TDd471Cl6pIs1jX91qVZJ47JGtdSq4qmlA4ddSbyl5k\n",
       "igy5Fs31Y4uxwnhy0p0yj7taNWlF9S5lHxHGswtC4l8N3WdBXuwINbTHq6UPfUpcdKahbI6Ukfxz\n",
       "7Clqm6psmBKzXd8DIiB2Oh7hMqZOQPy1uETzSJdIKzY1ETg/lmZTqkIDWrReWCW86ulxpjnbOXMK\n",
       "wTK6T/OrJrvunoX0ypIwbBPzoSeFu0ps3A5LDjqKkvHHq8bNT/E3NmYAmBVaRDq3C1izKb2JcNx+\n",
       "J1R2ZvYsK5nFLaVebP5k6BcAethtJIo4IsVPtv5rSwWgtGvqpJaN3pyixZsu4mcUriAeofqJy8U+\n",
       "OvPn3pvlBOG7J17ecWlRrpUu7NUt9EP3q5Pni0qOH9Xc9h/tNxg0BpAaeSS5cJKnzjCb+J3R/gnb\n",
       "ezUomV1SZVf9YNUOUorDC4s+9FtW9YA1RPv794ftV+vgX300bVtBpQmPY8d5ICta43t0WOgz6aI/\n",
       "7oe4YPhk52C3HT8hS494/QvbZqeo4vJvYI1JbpJI1FDEUEW6sui2O4ChRUdjIedwmjBbsGMPNyu6\n",
       "KsElYrinhOTXGa+W6aSzsG4F6SO1VoBYPH5ThHvHKwTgAinqW46US51qaLIouK3qXOpwXKa3t72j\n",
       "4z5G4BNdWq98X4ar96qesOb2ejU9smuNF2fZiJJeFbziqpVlJ5UX8F07bw/tEkyO1buxM3goMNNU\n",
       "7DUp+xXyJB+VP7qo/eCaPCdXaopzPZw6VtXFv5+wzsqc1HtpY3CfUqA7bBrdYELARE8Hck0SihZ5\n",
       "rlV7noqeaaoP77uowS4MP2oQYj0otMIDHNHDMrBqr76btv+64QTYbF/r0nVPltDm/h1o8J16wq3D\n",
       "dVnbteO7eEG3AboNhP9ZBja/gI7Ma2EJ+LJyKzARLhHB6z9kF/HE74tyfZGRuSr/TTGFbEawe0av\n",
       "160z9reMw7Z8EzsVzB8uvEloEmmTuFE9M2D4kSgKEQLss6fxI3Vsmpt2izazZSwslyfYbW7BvcrO\n",
       "fZ9NRAXbEoYlqMAE3sUYYcQc9r9y4lj9OChwSxWgQwAZUQAABopBmqhJ4Q8mUwIIf/6qVQAG+2l9\n",
       "t9mudABalAHehufeFBB8D8grrT279a/W4jbW4Q7wXMLSJCV4vugjhI4Wahdw0VKtw/p16D3zuD04\n",
       "SIfggyWsgbMROu8FUkQmQ1IPRCeZvyEHteLo1dfjCwOyJpVXDDOKllpg6hF63vA0H+YSksTZtkFi\n",
       "YTBK6O1wNm3GekmFivbVSo07uuXGjLGCrVWomE17KLdYpJxZUzpvI+FrfaBtyZxTnShjHuNOxdGr\n",
       "p+ed5E5isL9fHwzGzloMds/emymiJ0IU3APtreYQJv0j8gHnTAK29UbV1hfe9jxTloAsj8SxbjMZ\n",
       "BdDu/YZkitsWwkjuJZy0b5SSQBsm7IMV3rXGnXEON3chHR9GcAAAAwBjk8E+xjkGx5n/a+Ytu+aw\n",
       "uLXwJxTNPNRtBx9n8o6SFl0Dj7tfSLrdUj+dYCm5vXzFI1b2uz2cmMKckC5JunrbnCyx2GLC/vp7\n",
       "avNf2GZhS1Ec215lf3vissIAAC/8d2n4ciBcDTteQLe8Pz66UfNSxziaEduNywa/9hNTgUVO4M+N\n",
       "egJQbbDIz0zQCj5H95/88JPhv8PdYJiiFvj4etIhiL+rn37Mj5I4WkEZfX4K9Ru9Vu+GcHHDy5gl\n",
       "E2EMGy4l2J+lomMzCuMJwIM6nBpQAAB37UfKEKnUB6HyjPX31OKCm1A3NharjEOs/5Exk0QQpjXE\n",
       "yMaUGTyX4S2ZiusjTAR/K7brSaSGlwkfjHTFjUDzAhDca1HTESwwz73sJe1++Ig4CdDu5czGst76\n",
       "U2yT2v4mSnU0BP3l83p6+T9tx13Pnap0mh5Q2xBGnEdxvkNZMeYP5tMBWkq3iQN58T03xLKABKU0\n",
       "Whmi33G5PMU3oy1WyPpi8cfe89QqeSfA/K+iV8E1+mhZJeYQ4bVrqowSq9Tc9dAX8i7MSUAIsgal\n",
       "qjboXmBzY8dJmDTqRAPBUwfJdEX+14FUO1HvWDHWBlfpIXsht6hkX5hxrlm9GeG5ckrXecVeLcUo\n",
       "1cBe7wkMrCZ0yMkQ2Tw6WtHH9TewBEkuxsvNUPyMt+tiZ9QzbSdmCg3wjN6kBdaAJjFoctG8H/Lh\n",
       "v2KAOGP9MRSEjIMaNFZCrYMixtXKeJBrrfkdSAYb0L0RZ8azc9tHHfXPJC8lxEFNVvsB+ChXjfCh\n",
       "B6ysIMISPV0MZXjN5E6QokgCT1pUlEBoI1vDu6aMWzl5leYpkuCAulagOnjlVqlkS9hb+DszF90d\n",
       "MNrZgZ112Q0oXTedNWOIwWy4bRyBxdmrMLR+LkB5gHI664qCoP0/IcFVAR3E9yP+tA9YJMwNl1aa\n",
       "9qYkWdSodYAEcg4XcvjssVbovWFUjQ9anrqITjptlrroGACZJq2t9t3XK3UxbQhOwy8eBDQGgXDI\n",
       "6dleOIGhKJF7ZAniefjsAH6ayZpGSLJsCkDhu1DG8aknf7InQjmwNN54oyMYFlGZE6SEsDRsKkOx\n",
       "fTKV2yC5U0bZQjWwICq/PzZpwh8AcgQzO9MdIIxOgjNDRiRe7W5/bP5QWPojwNIMJkCO8xlanle8\n",
       "fWE00ZBRZcxv2qYPba+QzyBhTqkqad+AETRNqqKrijf2UU8AGDEs80IytE3iTN8WICOAbx1z5WAa\n",
       "jesMrmO88WjKIRgeMiQfnseS+GEthwYoJ58eYbf6GZqeoOobMQv9SI+X+Xkk1lpF7QFKkhxEOBvl\n",
       "tXjsGUPC+NwDU9/oPBFVchPP9b3//BpVDRYPvjjFG0uM0Kdl2jHjbeUUYZWcFnnBWReDGsEmjon8\n",
       "m/3+RlCfPuGqrHxlfeVSPi4XAsqQQDxM1X09u62rDuscC82mknBkFfOZ/BUx+Hw99VfUAi15tHvs\n",
       "Vnec0dOnyI62BwtXy7wxN6QbA4lgKEIakYbETQiz8C4zYKDnV8cUDn4cWswjE7V0wCL1ZKbdtfWV\n",
       "guTn4pOgqQQwWNMtc+ZkkZWp+8jG/UPME0rkVjaMhkUQB3SZ4yq7S+2Hu201RAnRVFbMynCjld/8\n",
       "TKg2MhJI+4HiQiFuO0i6K0JyOgnkQORh5fZXyuVvWWu/V0X4VS7XZJEC7Ga/tl7iFBjum/MfqJ5S\n",
       "G4oPSpPUZ8oc4vFS2HyyDxtzZRPn717LZy6BQ5Zt4Ez7BPnwy+AiGRYbaBEqr0xp63qgCveCVhBh\n",
       "f8lfWGvojUXqt4Hjs2L1bhA+OeaWkTOsdzVt8jWfsLD/0uweRRnfOgBdJNavacqGaS5zZcYbEqwT\n",
       "gCAAAAyNQZrKSeEPJlMFETw///6plgAbK5gi7jB1lI0mTN+3Oj5yAAdls+Mpg608GPPtbDTmSdNy\n",
       "wD37SNwXn1naGy7UION576TGR0gSIdigrMNeSl+e4tfAooFRyyFmPQkI9JqgDqV+kRPyJ5tSpjS3\n",
       "cOjD1eGfnoIeLjIN7YWAs6rw+MeLyhq7G2C6fD7/zefF5vEik1K/hel0D7JC+81v83sIiRuAPePE\n",
       "ZAqWIWTFKfW2hy6Pd/lnvbwuHcndwh7dIGw2+cjNnBxkTJxv7RVFy/3i+nkHcYOOluojOvnWwTkt\n",
       "ltzG8vr7KiGXi2ALG/J5bc78rhQY/F24VvrTpD2QQ9+ATKPn2Hmcp5mDHTUnguDq3TgAamiAQqi9\n",
       "FBTyUoCx0MD0Ri8pXZ2K6PeYheopvWP4V5Xwpy+Out/YE0+JruBfiGce/XoCLGX5S7evTo00ZNWu\n",
       "8GiM9BTMhqRV4OS5K1Ofw2zlvQYO9SzJ9C5qQAAiyqiIfDhqqhPBYpedebmEdWdpT0chA5yNDfC6\n",
       "E6GMZ4NkilH6vHUsG1o18Zuw6s7UqNVh8Lqi4HI8wdIH1DKUovqO2OhxZE4QmiwdlYUr+YKVdh39\n",
       "BjKutRUWbGHxK+DTsTiTBwQs73JZC1QO3O7LT+bZioX43QUIvexslRBeaf/eKjIbjYjVDeCiIL6J\n",
       "SV9GisRZ83Lbj/Iie46NFWLpkDDPTGxe0DrzxD7cYvN4j9lqeqCXomEGCNhRklBbGr6IIbWMnxeO\n",
       "OiGviChjUP3Y9nuVfNMBwtOsD/Lx62/D/fYwOAAr+ehIswUCUweGGc7zOoaD4BXi85XR1CuJPMS9\n",
       "sd3rbMjZ11gdyoD6wYVkWvlQV4o5+U/NdhET/c4y9cT2T/r8mWz6EFRFFoAHe41SPuLkQAzEWdMd\n",
       "Fw+ZqlAu0ROV8b0Q3zvdkUZUqUdsXk8GrAa6W09Z++22LF1Z8Vs+AK77nMKX7EQSdVS3lLWoZqUl\n",
       "c4CammKj6YoxCXsrGj5jwPqXDH4GqUGCkA2n5Gn+owh+I29264RXV5oGFCegWO3+bPBG++n8hwqf\n",
       "PRDKA43d9Elq6AOUe0CTOOV+sRzINMaLgu/ns0DoKQABbgm0XIJbJXSZYZZ0wvi7iXp75Sg2CCv4\n",
       "8o3h3mL0jjT2Bezl1YlUm+9PWRCga/K3kFo//GTgGmwZYhoRRo+x+WelUov9WJXQ/XuuqcH0cs8Z\n",
       "lB8m8iUJow5zRHju6TioXZd8n2iJvEFgAU1qNzaaFagRuasN0AAbeMc/q2WMTKtpXmNOX/5+cO1T\n",
       "eILhDlMcX09YgEqSdaqvK/gOb7vG5DbaHSlunP+gCNsMjvH3fNNNRQXjIi1mU4e+/ZsZRYeDDDlO\n",
       "fOOaWknwcGinNC9dwAA5j1AdD4yIk2xKH1hdYv4raC297jnAx1Ete5UW5rn2FX8MiWeVo7hLZqoo\n",
       "hbh6Is02O8T5uAZkrUwAUGrYg5taibDnXZI51v2VU0hR3y6AAr/tKF1e72azq/Frg+yjZ+TgL/cN\n",
       "uv8yNeVuJJoOszxmvXZLQpRMVEk0KooEZUZcmtZSSwYr7Kh0YrZwn1knlvpAvzvCnHCc5Q9rnW1E\n",
       "dOT+r7xRIuimMeMt/P10OLELhKiHgytP4kp4TiPaYANLDVLQAeNeWImDCboysD7iE7QXpCPWge3k\n",
       "hXo8BFpLJO5WEVGVTFGG0GBS2AHCRHG5DQwgY7sCHI0GkwYayZFIKuGeJixY87wTOGVtDmmLIs1/\n",
       "Vr3wdHEcuKsQgdvP2usR585QOzIq9la3SSi6+zsICBZVAAA2hjz5rM4/d0rAysCQs6ru9rPHWWnV\n",
       "bzdo5BUp8JDr12DzeCFP9Qvfa09v9hlbqIft+mCxZcbmjU6EU+KVQNY05vK6T5SweIv6Ml5o2+2l\n",
       "VXBBitQUud3r7w2GRpqNHekAAExVIY3fbr/D0e2rO6Y+yhXdS51v/nQ4wk6EwhRp7XgQliFmFPXk\n",
       "Di+41h+1Eqzc7iyF5EXSpNpiLhzg3fNHHMS9RLX/Xb8ImvBws+DqtrbxtmxuTB1ewnAaOIEYhC7G\n",
       "N1rCMk5v8ldyIAOmV3i67JVDmPp6CxemMbMJANN9Xg5/pQIe87Q2JIJsVFHNmPF/JOdvGqaDB1sV\n",
       "rZrbOmHzvsg0z46L8RugZNTbM6+dkoMVjqBBZyTf2NSrz1yXgKyDY27qcRhE6vj5sxjMiujVHrtc\n",
       "7VmJL4oNIQ50npz6fgOIQwaQEYk5P4bLCnvhTGS1X6UNSGAXt+LJS0lVocmZCbevNuphF1F4c7Dq\n",
       "XODMQvRc+YCWaBogGKTB991Rsk7FwPXr/AwaQg781rtevfgG3Nld6jn+Ah6wmPafGZAAnaC5oEB4\n",
       "VpUe4agNlW3Z4tzCEtJEd6foCXWVqq7hT6JGgTNdQ0siY2MAtkC1CX5NfAMD1cBM71WaT+HS4PNy\n",
       "uWhA9RZEDfyLTab4dYAN4c3o5khsiFmU62olbYp2WTUP514H+JfHZjpR/kWI+VqPHl1r8aTJWiw8\n",
       "QvM3OdS+wDB4qb8P5ZGqAXpfiY8BQoc0nQin32syPvg7O6P7ZTp9HGA0sreEPGpEh4s1vVN4E+6/\n",
       "w5TuDdF6lQxpSjvbDer8Mkt9xCWyj8S7beDw7rZJMJ/uGhQ0mjFzbbvplKxjX5b0FzRtrNW1T02R\n",
       "o8y8Obt6mBvX29XaAUh/n1PQedfzbOJJe4VBr/7eV7R67620Vpi1+FjM8PFrJI24dyRUqPviUbF+\n",
       "GvxE6r+V20UHIn0V+UGS1OKltBCFMsWvLWIMR1D6sWI4eQgvZL3PDcNXNi6b/wTc7LiQaYOFMF1h\n",
       "1DJm59dp1ieZ9F4ybarv2zuIo12h+Qhbu/TumhCytcEs6qPyNfE2hUc/UBFlvaw8h3CtXtdjPWBe\n",
       "Yz+cA6uFWcgbcXJ9bCv7Do1DGEx4eXFTl+rqGBRXJtlYrF/c59XhFF7YfexeK5w8R5RunfHI5uoH\n",
       "B63bNp1yu3n/b9WiJs6NrRN/qsxbIJCAbTLM+OvRxex4MI/ewtMqolj60wdVxHw+DfJGzNnnuuAW\n",
       "Cq/dyX2zARAvCaF3Hhy8BKhYfLITOh1OxAPNoU572mZc5ZgK4jCphzCu4yb/bu+pz3txJtfir7BU\n",
       "U02l0vJ4n3pY1y4esLaV2YSPSEnWVbYBgCdEcHEkgFIjNzAAYiT10IFPy/YQLx0W/7uW799e1Epr\n",
       "j/uyHqiuvizmo9oIAPxTlEF7htWxMiue0MghRLX7Jx4gmInCW4h/fUy8qBFG1DQtM+f78x7ikKSV\n",
       "JpqwLUfnxJ0uqq9RairwDm5Rcf1XpVsYKSINj/uNc4KmvXGEyif++oULsu5ZxdMfg+qwV9LkKEVa\n",
       "pnw4nkQbsMsB33zYK3rIygHGPPHB0HDKIA/6C7Ed51krrOZn8HQXJ15+uw4Ku39aql+j/Fxbnkdk\n",
       "pwmikcErLjgTJ6pe7enint6sP9bG3xY3gcw/u2Np7gcrot8NV/BmLc8cLi4S/9eErrUFqjKPjsfV\n",
       "L1wa1rxh61X9rFfiDHTtDCMIdUyowbu0arE+lbzqkbjSEkMqh+O5bxhs7gRb8VT5K/b6taMAOSOM\n",
       "W2uZbEaL4PbNVUoOfji1vvMmtJA09QZOqVCcf/MaUBXoyDBEbvtq/0RIU/Mz+RIkQXYWnv4UKvGh\n",
       "qLWuJh8g1xTsFzjhoO7kPUdX1DVn/XHga1HVU6ix55GURgL4V65B2b69NBxh1ZHksGIHQ0RIwM19\n",
       "KcMdydQE+wmlx/cpfr0SkdG8zNctRYGHRApI1XAV8EPiZadJKWy7U8V93KnYm66HYXXm88EMTDk/\n",
       "0liYJed7NSFMfSp+Uh0kpkCk649Agzq4DzGxILDYSrJfQExsVP+dMPkbfwwJtYNMFXxtx25Dgz+S\n",
       "qtdDbFr7OFbI+ubWgME/G9VjxqZoZ+Kg1iSgsMRCD/ey9XYczDi7YxOsy6++QtiAyMJaQuWfRjn+\n",
       "+3K9yukGrCY0ULpAncA4cp/2guhXYC152Vb67r1QFxXLcvHlpjCJPoR01eW5AXNL7gw6kXAAQs9h\n",
       "oYZbJ1L6opSOkkmR8mAqeooAC7OrW5iwOB4zEA6AeaPwBfY2bhb60oGJ/WxaQQj47S/rJE5BdbbB\n",
       "dV/1fWEApniFqX5F9v+yrVXgZGlvsMMrPDrNmYPBQDS6aC82zc+ga/Uxyyo4/wb3l6zyfim1Fal8\n",
       "Vfce1///+AUZ7AKwOocdwSIUyTbPwj+9uXdiDfv5luDX1hEpdnHDNHaVn15nGlELYZzG3qRCyl+x\n",
       "9ZbEcrWGDbyuAaYeeqxOL8ZxLa48ewarIKCAAAAFigGe6WpDfwAVBABnmqwADtIfxcJ8lRr+9yMN\n",
       "uWLdu/oXF1di3zXnHsuOWNSZ52mrGaA2vMpq2yTpxCSf3az7z7kBxLE4GBQ2UxDMsMTih+IwdhUc\n",
       "o3Ny3TqIm4aOCUaW0yj4dWchvvs/6DDQ8bcuy4DyFp7tTkMJIdquBk9l128z731Wt4CY+YCjai7e\n",
       "uzKWOuUgUHJcD/H1WVoXIh6M978DJZL/SI09CIgjYuR5r0zaAXk2KcvKG4GADGxOCF5Nf9IAK0xj\n",
       "0Fj64qaCMKBXUe0rMLwXJjl5L/mX0cTtZD6nMUIsIOhzYxIHLYMh7PLNEaUPm6w9uy557e1yheXw\n",
       "zbtptt4hIjEGKAI3H8jM3B3vPAW5zGIlvLrqnThM/U3Rii5uqffiTjxm/ucwPXjvdeoLC7xjWy5E\n",
       "Oqd0QLX7jpGkFf3lLP2DED32K3eXqbMyL05Rr9NmnjmVELFqSPP5q6zSb2VvyoIWclGW1bQKHDYZ\n",
       "Ll3geviUgWnEaNQ6q1/aq1X4X7kVvbv8JDu5d1Wzqdw+j1wY6S/WY2jYnqrN+joSF+Lt8cQM+ZE5\n",
       "ZEM3kcbif6QXdBJaJR/fMf5ahXauBpNXkLX5rsR/e34UlfB115H1yiVsZmvudKpobyXR62fIvhZY\n",
       "yTRvkQ3rFwDmbIeOhTTGbC0lV6QKImdHySlo3n9/r4eabBgi++Qx47/UX/saaye0GRqwrlvioxxB\n",
       "eCJujNBqM8LUVVBeO6vuJRLxfE0VmHPKyxaP8XilWax6aEH/7j2bMSy4r8iCU6sJFy5f4yu870ax\n",
       "3cGLKWU0cFOheS/9owLxsJAIrNdSswAeTTKjDZC7xFP1U/VD8dg925oOP+eeROY/8oje8cMLVbod\n",
       "NuxSzZSTPNGM7Yxy3b6rXvqT8rvMfB5DWicFuOOGpn+k0kA9wZw1OwGBJJNL6GCZ9rhfrsILyrTx\n",
       "WyVgHfKRoqvbRViKwrsp5UeC2tcx42hIl+z7aQCtg0RcbaysYbYoUQOuz+xJWGcwoIhKJlSzFGZi\n",
       "47S3r+/m/eixpcDsH3R8FSofwZ2c6hbIzju0LoXyIQrRUUZD/2ik1vP13nt9uwaYZAe+h1wEJjfD\n",
       "wbMp8Q6HOujS8kWGIZXXXIWo1KL/kC0OWZiEDAOw4tgDV6LBCA0m9LUydUvrVsak/uOax0+xEcAI\n",
       "i/c47Sq9hp0D4caZusshbtRNxzeHS0X1bzBL9pVkMZJ5kiUp6s9bQTc4+dZ9qiJu+ETfIUBSGyuj\n",
       "uIFM8FZn8ZRc/2jf9KEJhpGJtwrNi9c4jIBiYnb//MAOdYR67ZpycKwm7zVcZbl+oKA0CiX8KEJE\n",
       "C6O0vYAQ7go5/IBjd+DbJljCNbA+/t0yUPjst8mquXVY/kgV0L2nFKH/Iym29QO1//zFtr7vpXq1\n",
       "6PieRJKA1o6fsUJ9TZi5Vnkcgt+hFikuAOK5x1bB1rkThRSW71YJeHpHDG+YCAijq3JknEBXAeRh\n",
       "bCX7ZqOqQcYEnE9z6TyjdxgT4xV3qQEQny8lhZCdnOTzRigf8Omg0I9COAr4yBESABUGk/Eh2FEK\n",
       "dAMzoDsPbIsAtV21OFpOk0bZ2Zgg6VfGE2J/DQqwlSJAaxDHLAhkOd0Vcn0EWbatz9rYqa60YoHl\n",
       "Mg0iT+uXrXBNAEczOhw7Bw6wuToSMpSkLDchJkQb01xXZ5Ggl8p5WeMCYcmY4V6/pAbGOIs6+vrx\n",
       "dv5J2IIHwyfrfrcxv+WaLR1QatmpNIy8+lg92R8mnlc8CiZ7sJzIfSoatxsI2mJF66wxfgT5qhIL\n",
       "XgaeEwT7wkB21WejoJj98zgyn++DJAik04YbTDuEkQFwYrpvvZ1ztBl86pchsajIi8EoBxl7y5Rl\n",
       "dW8kkRVUWeuVhWK7az/6snWszK3igHdBAAAKOUGa7EnhDyZTBTw7//6plgAW4XClwo/2hEEQv0AD\n",
       "La85x9daZhgdscQ0fbhAPqUZLpr1/3NjgnqHvYLA0rj4SFeEg56c5MAjjFOBcVJz74vUb7v5FQWa\n",
       "hk4k0f0Lk0oRY5Fv7uD13sncT9mSNtzocODEIWety+FtsU9hq7UJtdyjP95rj4hvaFSufr1LOfxR\n",
       "XNonE5n0IGG4fEtj+4xLGqCVjdAMDAYvwLACklnOaitsHDk0RTQikCvk1O5Ibizj26ojgJNBoywe\n",
       "5wHu4AGuVp6FF/8o5wS27557Umr/Z9gVUQRwYVYA6JOcS1G7u0sIcfmFN4x/cmp6l4YNmRO+BXSV\n",
       "EdvtCvzPOjtchDvSxNSt+H04G69sl9n28KL+HgO42YCHqblKNuiPWzWLZhUHzIIUmbp6xGKExR3+\n",
       "HDggJpYqtuFqGnyGj5eWhiNEmnr5s+Iu0PTRxwOcSrqHudbSVSBoe8Wqs3Gi9M72zqGMqfoL1Hrt\n",
       "0yqbrd8PD/qqG7O8LNyka7VmRwx6MficUOcGiLnR8JYbx5VJNsCvwXUiApNSSkRJERcnU6J/4scQ\n",
       "f8F/VG00YENlYEx+UiPuI2r3hiDICaetKk9pXmoFVL0D+UzMR9VlN/J9W9U5ZgjeSVqPOG4QvDS0\n",
       "8PxW5aVqRnk6UNlPNZtChIcSRzAgz/UyrN8Rkj8TPv8MgdPzNzQrX3esjlm6Y6wblbgecRweiqrf\n",
       "inTPVZJxr+htklhyLeQgBB2WkHXyn0AcM9NvKFXlhvYQQ3k++l9XH5kf1fxJrZS/wHQoAFAVZOGq\n",
       "eTt+Gl5vJH3tBAdr/rl9mkcloZ0edV78KOLj163qy0G3HWK5c/JfdFQhZHYorb7ti+gtjj5uHWda\n",
       "WnlpAwp5Pv9e9eW4CPt94GqP33f/vVqFc4n+yGJvRRhFGSxw8X+G0fsE7ISA634m/TGjA/0rvU5N\n",
       "qMK2YW3Oni3qhtfh7Ig6ZdJ+OFnKmLgN+kq24Fon/hGAtJop4QQSzvnBaQweb5Ee66JekSif6bgN\n",
       "p3onEA59eEWEK7qTx/u4e2x+qeG1502Bx8LLJJWhRC642frjj768fNfE/O8vdDsmC9R9AfIvi7ou\n",
       "w+18BLbNuzTe8/j3IxSi5x11yXJANkTKwtJqZ22b0G8bQqKX5varhIj1JUGcWUo/hE+uYKJrFP8b\n",
       "T6kih64s1H5n842H4js94G56npS7+bojvLqvCon2yA21Vr6Y+ZHxQcIvpZk7tQF92YnShCBNjsPD\n",
       "KUJlfNSskavIPlN49v2ToeeCN89F9u/kfAVQuMkcxdqnOywAGTQ/vRRJWg+GFKTAwIfQPP9jzw28\n",
       "PrcpFlRPApJJSaPVg8l3gav5mFF+K6J3t8ZKp0PLYkuNvjb9a8nlm/9ZUk+sK3KqYs3k8e7maU7b\n",
       "QxJAK/HDOaaTb80XIOM1vrJw713dWi4y7yY7aUqoznEFRas2+6C2ad5wHHp73Lu27sjF9BJLnHWp\n",
       "zbbOijl3CRGnrtrMtsRb0kwMKxFIhBTDI37dwYm4bkUeLlsFm6D8MDATOp/JE+8Hcz0N/pwrZCYb\n",
       "xy2ql0NCLkxczrTYMbhhyc3Yi8f1yVeugqm2hOC34BCF+xt7zDMMUzdAa5pteX5c3THPtiPJB/Iy\n",
       "d4//c/argM5+3L6RXMvs1lZPlBjoJLMFnmDQYUqbTVlRYNKhdjKHHeVuRww+xoTB3BUxKa7wtbUq\n",
       "/p8aUjaolyrz1fCyA+FErnqW0Fh8Cw+s9QEEnzy3iCXoVPK5qiKNB7Ic3vK2elh4fFHPdzHSvZu2\n",
       "R9a8308/Y85jm59RHcOdTubuB7My3jQEpWUJ8fJdc9mf8WE+Wfg59X3UQARO+04GT90YFHYoklwj\n",
       "tLbZ5u+utk9hh99hOsrzedxlGQyecvz+DTcVoUg4bs9himprRZyfnOrj00Le1BxT1HqMaFkLQh33\n",
       "ij4yUdrf3RSga6J12d0GT9QgqUubv9/kgL4N5Um033l8nPtGmU47tikHwOM9/2x4LbqH029mzXBX\n",
       "9IqOTRzslgM063IX2p61rHSB7QeTDxZH6r4tDgiLhFNHDTd/z7XlBQSUNi0iN+9PNt9HQLsNEbf6\n",
       "4QK/w6mJhamy2HG5v3g3qk1BvZjxWixFj/8oeVttX9DLhg2UYy91ORKY5j9LG3KQmPhE0Zam/jdf\n",
       "luPULZ2meGIreTgBVdTgZrL13YxiO0kcdfLYIsr5OjBknWYbVahGdz7QOXLmpTPlwsNyIXgdBH3Q\n",
       "gvG/c8O3kIIQNlxNi7ljzQ4Yo75zc3agN7+4lUo9f5MFWmwT5Xjxb7fkAmcmd4gqPpdECBdUwvC3\n",
       "D+3uei3AQhysyldW0MjSA+Ns3xPpHNu1CCU8fqJqAAM/meJNjTY1lFByPX0ZMDgO7v18KSgDv5PI\n",
       "G5Mjr0YlivRw7CuZ6f1MZpwufmdBC7uTkP4ITF9FVmfEH4FnRTtfIC3S54nlcijmKNO/t8Olx3i0\n",
       "4ON5CY/zgbVHN9sSXsCp+25alxa9SdGYMz9LZ57kZaFhAlM3qfuDMoYxgaSvrNjy+Q4/r79I2zy6\n",
       "itH5UNmYSZevK/Lnzqy+CNeZkcV9XZsT4bMMAWf5gNTY1N4OPfFgM9dWEnxUI/fkf7M5e7P1+pmD\n",
       "8r5C3ahMSKAoUw4kRrwFz36ELJKW4B+x7cwqOORrjvhaGY0B988iQvs3lPCB+m+VxSaPQDJuO51Z\n",
       "1/5+si26FYX3ORtkeoXCmprdZigUogsOm46r+j38KOvTKxwJCAajV2OHSVrG7AABiHg96Dsgp+Mv\n",
       "R3c+wsvJExeowSakmEvRozYqf9cDOmlq8/QB7GqY0cAtIoXHraYe6XARqXbt5V7Hbw6e3JyQliuT\n",
       "Ufb/8Sd81jESKgT00mS3epw4GIys9+8pAIfnfVw8+phhy0uxCdJ5JVuWt3BDeMltifD9nX2SXdPz\n",
       "5p32yvJmyiwlDSSKL8au35nZ4A4kW6jVse+rsSQbjPbt9lzvIMIyp8D466tF2ZaFkMsVLPbbn8nR\n",
       "UzcUWZvhz8lGM6d496s06jtRIe+0DLbVOoZuL14UYZNDs8OSaRb6WHEshUUU+NFUFqQg6Y3wbGUg\n",
       "eqeoXUvpW1BTu2pYqNMpn7pMKkkCSpwpchbpnc2kQ7VWljAXBGzJzlHgSzH64gUso2KtXYJHSe5s\n",
       "LbkTLGGLecRwgX1kVFY/7PMhT9gH9lEHJ8CxQihrLJIC7X2479ZfJgGkRijzmfNfNS0m4JUPhqis\n",
       "lXWUXFp1uUHrzSKhgNUPhp128rTCdpHXc3VqVVUES/M2Hnc5Nkusw4LCE/+Mt5PegTwRlrAROP19\n",
       "8pGyvQw5TqKALLKrmHrJfeU+ZVWgZopEeHaxUQ5k9GcIzOUMQf982oVbR1siz0YJ95y7/1mH8nCX\n",
       "a1FqBJ12S/xeiNUoCd/tGX6kRWL0bzAsadG+jWJMppmQIiaPKXLmA5NwNLft1DvCVRAWWwAIllk4\n",
       "yn8dy5tKTgIqmgzrsAnzhJqI9hN5RmAAAAs/AZ8LakN/ABeS0uNo9RABtVqHZNqTuesgPeL/P2Ln\n",
       "OTvJ/zsoWnsWnSIpS+/LpqtG5Z2E+hgOiiO6jD/LShdJoV4ZYn58kD5rQ3GFDPht2nViSNmul4xN\n",
       "iGmjwb/7LVTXMQMx8fhk9FdUscjDGUrYASXYmfiYTsm+EYKV9NrTcCA6vK0thsR5owwEQsUJ2kBG\n",
       "Vm7FSo1o9tWeoqcggXzYMQi/nrCuAoR6iaQNl85EIWKPka7k0vO4R8cWvz5xKYM+Fr2PSFJM942k\n",
       "T5YNIoiciyWZR4jk29jlEvcPPktgW034epihZiDnqCoWP3CUliIsOGh+8I1kyXihmdmRz3bu9e6G\n",
       "maGvqT98TVX9iMl+2p9fh5kN0NDXLY1v/U3uY7IQF9oW67R0eVrKBgYratx4E64ctTfrXuwyHuws\n",
       "8x/Fh1dknqD8oqExuawed6vngl851Z0p8+p59I9K2JiENZf76Zw9EzYoOYXRXQlcrWI3CVdktCqU\n",
       "NZjIWlZd6RcGenC0TeJx4Bk13+iCJA3YmLUF/crJcRA7jnfI+l+RqKKJAdzwoyUFA2v1qRg+3uqT\n",
       "xduLg2ncsde9kwkleqIJzq5GQBN/Lp6xiGKjyHSI8HQVhC+Ms4XNPoUUXqFvOxUXNr9akfb3dphQ\n",
       "IBJzWGYhuxE4u4JlSuokSdkiq+krw7Smi165A0FeIUgwBtWGEd0hn18xR/n+ustcTTtY/fSTpbwC\n",
       "Fv4n8ix0vysWeWVd6asjhS8cJlihEr2TJuV2CaiJIGm+ayRbZRMKL8ctqQSkXzi2L03nlUvOBaRT\n",
       "x8EY+h6HmoDE+RwlsazpKxdi5wEpk/eFUKzQNk54EKQ3nGiugxZAFd6w/RvXL+8GhqHViKZBW8Pl\n",
       "VH+NRCF3SawPAe8gaAsSXbt0kEi9GkEhTXJPPIRQk/OHrvdl84CJrZuBaRKRpbhUbB2ZdOoZZASF\n",
       "O2jAlM5cePbhdQmbGv1atOBFFQVfPEFBPEIm08tcVGGK5XhOY5QdIt6496XSjUGOkUVz64FK5buI\n",
       "oyqkWbhyEC2tjSpaNWULOTJpg3LwCfHOhh+TFi3oTIfx23TY58qhkCWB9GdDsTUU4xMo9QGkTf23\n",
       "FoYqAdj3FaaWn7cWjTZTxieqBpqbhEIW7N6ft7zaTy2n6GyIz/2Udael1oNahxJMVesF6pB9Y3Wf\n",
       "B2V7fqeZkqo6qoXAEvA+gZFGXxg5LSv7JojD2fo4/BKn1WK13qE/nzRUtvmtzj4Ta5yW605ryFL2\n",
       "LUgvgaOBLhgS6rxXSGgUhwuI7M1NvHC+vj0zJAawbcNqps6aNqh0LFV8/2H+FlWqckq8w2HrFkcK\n",
       "nmluKhyndNHMdkgoYl4K9yhF4RsBzqbSk60un69ewuCRho/cROJmzgOY9RWjckT9kcPmifkZCZdO\n",
       "azVJYqIXtLjKGY7ohLO5giPIwSHzz0BgdMeEYaFn6Slw7D09hFEDC4+AgsatmHboQ7biwnsctvo8\n",
       "xSIdOGqzEcTU1EgJjMGQTSwxVHeMt9OsduT8rY7YCkaYTv19riuE4mqVw9fA2EbONYHxGpanrkdE\n",
       "4+zlkbJEOur3ojM63HILSuMPGzDoFTRn8m2QYK4zSvMltggTWgJZHb1eyl67QpAQ7WgdXjXweLho\n",
       "E3vakMX1V2tTaVVSWPz8axHxtwv3JCQ5dk+Ti2XKtVQreFezuIPCQamSTzLsW+Lt61ArJf/DHM5f\n",
       "pU3bVIdwewMnrv9xaglX90+Jdvex1xt+a75wco2RuoNS7E+RNDX7DlQsIrghOHjVjqTiKxD3i593\n",
       "6nfNkil2IZTVAYW5J1FJzMrI2bq4x7h03Yn4gfs2qpxLee6hLFlh/wI+Kxh249DxPA0m86Q0/rCr\n",
       "1dGIRNOCoIjddjbwvL4hqQqgjDfzwA12WPb8AtszOuzOb5Gb2Rmzgka86mABM9BWrxltZk8pBnTx\n",
       "wQu6/MMVlJOt1GQNNJgt8xthGu8PbhpnsRg5RvjRzztDkDliYbc64/jS7Ire5KRsaaG/VD22FvP3\n",
       "hj6ElWhlKe2PPuFn//qB7L8Viru9LbvZ5tvGeCW+iea6LVCcKxRB4L4E7vnoE8LTz8rQik4N84Jb\n",
       "G4ebu9sT/Yt+7xoX2O9Efp617GyAMfnUNEspsC4aPJDsBEG9Xrr0TYuvXI9e3oeSnltOYo7PEBc9\n",
       "tEDDjGPjhS4ttpzbem0EFN9f36dydmC0IrA9OkZiXIjQdmcx1YSfWUxCvAswuQXED4RSjW/+kGX5\n",
       "kf9D3Z8liD25sQm3hXQER6e9BTeCLFCRGkHHNFwLWLXU8O1C81J6CCAsPDQWdRH9Va9CjP6QdlEU\n",
       "LQ2u1ng/6AaEEM0fe2a2nX8VYZRI7yAZW21uviu0S6o0FaM91S36FfV2TEqldTYLb60Dw0FuANHv\n",
       "RQl3ELdg2/6XadqJrAj+tk83dmQkadKbdYBeJZEh7gMatj6D4pRbQwZ9JYdjAzeb9VkFkCbsdGPq\n",
       "sTyK6OiVFdeZ9oXIUStAiemH2UF6gaEupowDKpHw549bbbIezXbFGdjw1/1xy3j0TAUowlztjBUs\n",
       "Kh3mVJQ4SBy5ZZYrIybxeu46dnx4brTU1EMJMYLGVm84kOSLn/D56ukPF0e5Jdn/zMwOWb4L3rI0\n",
       "enybRXFxnYh6Ie6nOby3Foz6Y6BddGSwLz8qTN6RhycAjEBodmMvQE9gsGY6iYLE/aGrmsdZu2Ek\n",
       "XYhJiNbGEwuT38+k440yUUvxApJhedQXrnQy9Gck/0KCghhDNK9Ux4DvLHm0/yq8PKBlux8pPoKt\n",
       "O7Le5FyT4tqZnYMd8talsKe0/flxr6Mg3xtW3K+KEQYivlbZiUOTy9ZnQrV9xuLvgcejkhSQNf9o\n",
       "C4enEjikeUm6ZRuq/e6cMLcf5/MOV0GLmOgY78yvc1TDtCfIWtMu6gWGohpcT5uw4tID89fK8AUM\n",
       "MiSabWcZz1b7hKatVw7t28htuQ8y2VaysoDMcY0POyoekwUEgo7GKZWnbfwLQrVEfzC4lfU7lggg\n",
       "vbfu9XkW86+JIDJk/SpIZAjEIwihPZR2SzKs2q8S+4IJiDqCVRmBay46flWHQTJqyl09iObi/t1E\n",
       "5W7ioRblc9K+yZvDYJ2f95FIq9ocdySemOQk7pBtSvofybZyCRkBX6+ke0RlAcRTuyX792LA8lEE\n",
       "tdHN9U8cNP3KvxxInkPdw8TA3Vy+w0fYYX8bSJhqLW6sXF8MfaEoyaaiAtRIowGCdte66xaP4PFG\n",
       "xzVO5gCa2hkB9/xN15o2NbAmbQHqWt0yoQgQYMyZ7fSHQkP2Hy5kID2dkIKx0i5xzL43WmVrW6JX\n",
       "TSnF4xcoiqOP/hutAplrhPqM3S2iMXUOAzbWrfDlUfSdXBhLO0tuiXIw+/AD2YzgljzzszslLZn+\n",
       "eo/uwt6e0IRUE9v9uxagEw9w3qoJLg8RK8MZCmRfnadUAkDi+tuLFJ5BQWJyo6aLPQtBoznMtDZ0\n",
       "iVRq0ZpAbesvgz6yDphuWlrYqSXchEa8sfGD7wZzg9yTD9vgjgYRProTpCc/2Xh8Fn4UrwWTiv0L\n",
       "5ccQj9M1iUmm/Rg+A5I9Puh+JYac5gslefHaPjKT5zxwR5ABK5osAeyM2IjoDyPNnwLOGjqZa8aO\n",
       "c+tn5mokx8cOUW1MM1fW1jNfatnRzkF+px3xxp2BgVzhugXDRt7NDvbgeAFRqz3Oo+gh6enNfhsw\n",
       "BAC51tLJk6qGRakkPLmrMYsRaJlYGApe2lbR2GAGHo6G9StLg4YlTBUDMpSX8CGWZAs7MbnjfY8V\n",
       "oV2YtXKxveX6OyXJPqQJwNgiby7ijV43ReutLf3Upa/KqAvp1aD2kJ31JIVjVUAJUJptch/4CPgA\n",
       "AAurQZsNSeEPJlMCG//+p4QAK18fq12MiI+3kYyoAJ2izP0uDPy8pt7pGooYtMkd3TEn46RlCWVc\n",
       "fw9FKoWzNQPyoxFcxuYzByU4TObaE/zs+/rHQ28BY+dLuTxUGFnyYHMx6OhaeGEaYyvL+mi7O5V3\n",
       "+Gn3JPiowgFHScXivNoABaATkNDjnUo39JbhuvDijJxU8jf4/qipbRg4TZ0QBW//s88It6GugBW3\n",
       "FUAIMuSNHBniYnUxUt6Hq/lu8FehFibt+2pzxQmN3QAAm6GfToAQmrwMA57BT0D8b/t9T7cYATFc\n",
       "358lFa+khCv59XFKBp0Yaz7pbwTn/kFq3A4qiyqF5Gq/4uKsyfdZL5sCMmzOSjozeTKK5uYcp9Cx\n",
       "otCRWAEUTptO2OdcqsU8skfIteNd7UWC6duL3BFpD7MJUm+3TCi0Qc47Bmk11aETfoVv5eqV+cWn\n",
       "RIVmoyQYl9geHxOgYYKgOdCM2Ak/BxrIDaQctlU/YYyqaYLxjOJNBHqzs+F48tuNcPAA7PA4Wr9R\n",
       "ln1oD0Br94nHlyolS8ecsIUaGlQWEzbiR2z8CM2QM7oZI4S1BlSDB68v/fKb4T+phkrFPSIzngO5\n",
       "XTGQdBXRBeC7J1ehLeGHPSNO2SVKUVYjrsyy2kt4e2Mlx39MHan/SlSarIOHdoDM5ytp6IorFxRz\n",
       "8uL0vLmiAx6bo1OKwOvHZUjEnrMdvwBE/WSAi+7L5YJj3oRH2B26zn514eL2U+s9YDZTrZveo96B\n",
       "cG2l0sjTVaxrkGjRwXZS0W7bpftXMPmiB+0aASuzGnS24g0hIHmLyKWdAt3lBHz6tPfVthPTNDpJ\n",
       "EjXVeXwZ4jVlLdnlnTwdips3zvsiCko+HGNKcHLH5gH4O/j5muZaM8XRhxh8UBhWgRuhTj4KOtrj\n",
       "6Q2mKvtfsWzOb5+/qjDFd+VygTt7W24KA7uqdYZPwn15jkKhIE6OI4PqLYzf2irp/feeqCRo8LIV\n",
       "ngxLxuM4KskwhIEB1jNiusBThmOHWb/5eT/oAf4g7clRpSxlkyvbDwRZIWOXPCSuU8M5xwdtUIWq\n",
       "FWpDAeDTFqYlWV4ua8YlkH2jxL8qQEGQUmurZeq8PB9wjbIqlyJZJn7hdYwLxtOkqlbjniw42B01\n",
       "JLu/oD2bcJaUxL4K/oPlHELb1Ctx5pZ/SWn172wp83+UkV7e0ctgMaWan482bU55VnZFU63pyuws\n",
       "+f4CQfwU9USt9u4doiGBAwTp2SOszQfRI075CR5MheW5JeBBwg8PNSVo/QcEXtnCR/pxb3qM1bmL\n",
       "4aY3h+UxArOXqs0stcHbtUpvmcVPg/r2Cup3ZBS3FpMMm5V821eRPZtt+wne+ydj6r2MmS+T3wUE\n",
       "HceqZFYlzY6n4NGvAxptZarJrOeNmd1m8DQ7yVlaP32XmlWXA9d1Ug2hzb9q1UUFw3JVsPqL6HUw\n",
       "aiIxkLL/CGVh2ezU3vIjVIxpEwUxBvS06jSfAXElflfuorZPQtpUbYVdm3+tVvU03ijlaq3CaYMV\n",
       "G6F23ngTA/Be1Y018t7oHzA4ii26GeF0fkJS+CgRNT6TLI0TEmfb0JJuNbG4yhL3DjUv6QzCumSt\n",
       "tmGcXYUvRe6b0kAk1T3k0E1nrPDTni7sdI/cDM6Wcx5WWej5Q7If0voxyhzi8nePfxoMdMBJ+c34\n",
       "DP9oCBdz1+p1j2WGLBw8/K4pWgcS6jryMPxZwcK8wz0z+CRu5Z4eYjSnEpeKqAeQnmrJqFbGTIwj\n",
       "VHY74TpmDE60f38KJtWhSXnsxuyMfaISqujfDR5vChFOMU3L2Qr/neaoKe0+B6665aS1I29OJgY3\n",
       "VVc+7/tmnwmSZnGqj3s8jWGnInIiwVB2dFDtqrR5naAPIKKVxFn/7sadBjD2aY11AuIfwPhlPC0E\n",
       "Fus6rAS4x/Up+L0ySwuh7RovL32d87IbfRntJ1lNx/8lSsuTLnVaWcFCVuKAFDdb1GLSpjotE3J1\n",
       "O521Or05/qicOML+7oltaePB0DdOViCAStx3JKC4AR2fVzobgkAHXFt3OGPFHkKhZxuEXlllHsAu\n",
       "LUcm9iEdlJGakPVnfY17F+Kh2GFCkNK5XAvNesz7v/l6/nWLsP2EZjykMZacfeTUZahjwuhjj3zw\n",
       "0P43nOrZS7jFhAl1kJOAfZlpFEY4xrICHI+bx8XnBq1k12Xr/T4OAEFJ7fX3BrqDr/SvEmblE46j\n",
       "qP82YGXKvFzJH/EV3CuXb0vGJbGfH2g9goKtmTUOTeVvYtvnlgzuanWcSnWEx164NAp0+gH4dnfg\n",
       "91NuXEr500t1J48oIWALt/W8LoHCZxXk17AVcrPrko1+6hxmoKIPnfMDUw2S9LmWXxsTCrkPIY/p\n",
       "cN0Yx3MHCViinV+Aph13WdZqWoeqCq2vtuZTNuktQIdDmmwm29v46zyJRzY3vgq8scvrnz9oxwQw\n",
       "LRByshPWVk4MYVoI2FoJd13w9HV5356gYJodz8sxWZL4/8mOgBTlXK2j0qSohC1gfN0O84l/JJ5n\n",
       "ydifH0Fd1Tx2dGx/XumNme8V3GtMy9CYIsqyPLwPMv7dupMzjo0EbbA/rl9EeVffwG4eOXyStS3r\n",
       "Pto49sNKv7/Xo0YPm68LKSWwkPg+Mpa29m40gB8oSVo9yoRLYXGC5kzOYHt/Xl+sdprnPkhehCRY\n",
       "f4IzAdoHbCSIZGghYuPMTj7pCCB9/3wiwvYH/dpKShudNiAVVUdPIQSPMllJ5mtC70xfxbfSKt1c\n",
       "PpezBIa3JzZkycygdEwRLz4UklueySYHWv77UuFTmqg9g+D/vk1HvBZCP8X6vgD2oJxWDE0fRnMi\n",
       "edJyaD/V2c0yLv6xeFOAsWqo0hPDp5aoQyO1sFuxWcsH4qTzPltS4jc0NPS/bLjFwvEQJcof8CR1\n",
       "eNiGZrYyyIQl2XGOr7NWPFMxL/+5Tw0Fp6Tr/wX1cjHRKbyCJAqDrAdzuh97mGRIwjkirO1IeGzG\n",
       "8mwAZvDV0ByuIwX+DznV8AB5bghuPgmgrPZRH1SjmELns/KpO9syYKCLC2oZG8mUZxymodZ1YnLT\n",
       "jnTlbbYr3ORQNiSaS/BCK+lUyTvOVa8gdOIjXKgZvyZFyZ0jWGk4GypVBY7eCbxbtsu9Vr+7MCf5\n",
       "yrWFbOJjvcOoXWoEFuHcwtVR5egjEu1JVbyHxRfk+tLRrbSzso+UXa36MFC5TQ/fTLD8oUD6SfWa\n",
       "XQJhlsQ1y7XitN2frTnDi7j82whVK8DLRok4aD/TOanPhztC+IW1YoAxryGfmpgbnIzisTgDrtGr\n",
       "dBYFbRiun6tGLO1zZL4C/JSIsLSNy/y/92EXhrLBs5BVFLuxhD61VbrMT3pYxATRcS5KWXWScmeG\n",
       "Uo2qe0yMrVxX8hefuqNXgvbf9YK1SudmGlXie62lunBl3Kfn/eOkt7qlRxT9/5mYMOA3/KvABYrt\n",
       "s6aGc/tkx9FtcjG0PHqkTM5fja+DTMP0f+Dg2XSGETlEWuC1vQkDz9znJMT841w1fN/tKrj55RRr\n",
       "n5ZYlN/sb3D+auLHYE3Y3srgKEqP4Nk/dR82XYmzor8yYOkuVaCavzBkMc4U67Y8eNSRLijlcxSA\n",
       "K06xzF3pcVFN/0ASA+R5vA6W4hszcyFlWT13wqVgT/62DF6uSnVALs0XYd0fzNnFibJ3b40QPtA+\n",
       "0C4UwLKFczEMETe+AwDpP88QH5Gi+xBhE3F5IvvLjFjmgDYZ6M8LQ85FiZDQBVPQE2r9kMpm3Eun\n",
       "IrmJS7dISOe6SkG/3RWoAekpoxZpQbNkuhz/IvuCcfXPrBXp3E42axm+jWDEwtKMeR8/x6iHV+cZ\n",
       "2zvvs+clN45Vxrn7QhqG6M1NEbNdPcszfHNAlnHu2ofYGuUPjn3HOT4FVdKI1EvNPxkqnwMscvCi\n",
       "Fn/YPXvXOS+eCeKUcTq2dxdegO/E8ttFW0bdotbByroOb0W2GP4wx9UH8bxXxpC9+GvI5foHezrk\n",
       "x/Jiv1Lb5fjR8ceoZgdfFgV11LbKapage0EAAAPZbW9vdgAAAGxtdmhkAAAAAAAAAAAAAAAAAAAD\n",
       "6AAABXgAAQAAAQAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAABAAAAA\n",
       "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgAAAwR0cmFrAAAAXHRraGQAAAADAAAAAAAAAAAA\n",
       "AAABAAAAAAAABXgAAAAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAA\n",
       "AABAAAAAAoAAAAHgAAAAAAAkZWR0cwAAABxlbHN0AAAAAAAAAAEAAAV4AAAIAAABAAAAAAJ8bWRp\n",
       "YQAAACBtZGhkAAAAAAAAAAAAAAAAAAAoAAAAOABVxAAAAAAALWhkbHIAAAAAAAAAAHZpZGUAAAAA\n",
       "AAAAAAAAAABWaWRlb0hhbmRsZXIAAAACJ21pbmYAAAAUdm1oZAAAAAEAAAAAAAAAAAAAACRkaW5m\n",
       "AAAAHGRyZWYAAAAAAAAAAQAAAAx1cmwgAAAAAQAAAedzdGJsAAAAt3N0c2QAAAAAAAAAAQAAAKdh\n",
       "dmMxAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAoAB4ABIAAAASAAAAAAAAAABAAAAAAAAAAAAAAAA\n",
       "AAAAAAAAAAAAAAAAAAAAAAAAAAAAGP//AAAANWF2Y0MBZAAW/+EAGGdkABas2UCgPaEAAAMAAQAA\n",
       "AwAUDxYtlgEABmjr48siwP34+AAAAAAcdXVpZGtoQPJfJE/FujmlG88DI/MAAAAAAAAAGHN0dHMA\n",
       "AAAAAAAAAQAAAA4AAAQAAAAAFHN0c3MAAAAAAAAAAQAAAAEAAACAY3R0cwAAAAAAAAAOAAAAAQAA\n",
       "CAAAAAABAAAMAAAAAAEAAAQAAAAAAQAACAAAAAABAAAMAAAAAAEAAAQAAAAAAQAADAAAAAABAAAE\n",
       "AAAAAAEAAAgAAAAAAQAADAAAAAABAAAEAAAAAAEAAAwAAAAAAQAABAAAAAABAAAIAAAAABxzdHNj\n",
       "AAAAAAAAAAEAAAABAAAADgAAAAEAAABMc3RzegAAAAAAAAAAAAAADgAAGeEAAAiJAAAIeQAACA0A\n",
       "AAnsAAAF7wAAB14AAAkPAAAGjgAADJEAAAWOAAAKPQAAC0MAAAuvAAAAFHN0Y28AAAAAAAAAAQAA\n",
       "ADAAAABhdWR0YQAAAFltZXRhAAAAAAAAACFoZGxyAAAAAAAAAABtZGlyYXBwbAAAAAAAAAAAAAAA\n",
       "ACxpbHN0AAAAJKl0b28AAAAcZGF0YQAAAAEAAAAATGF2ZjYxLjcuMTAw\n",
       "\">\n",
       "  Your browser does not support the video tag.\n",
       "</video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt:\n",
      "USER: Your task is to determine the timestamp range that best represents an action in the video. Use the provided frame-to-timestamp mapping to associate the timestamps with the actual video frames. Find the most similar continuous sequence of timestamp with the action asked.\n",
      "Provide your answer as two timestamps in the format \"mm:ss, mm:ss\" (e.g. \"00:10, 00:30\"), where the first timestamp is the start time of the action and the second timestamp is the end time of the action. Do not provide any other explanation in your response. \n",
      "Video duration: 22 seconds\n",
      "Frames sampled: 14\n",
      "The frame-to-timestamp mapping for this video:\n",
      "Frame 1 at 00:00\n",
      "Frame 2 at 00:02\n",
      "Frame 3 at 00:03\n",
      "Frame 4 at 00:05\n",
      "Frame 5 at 00:07\n",
      "Frame 6 at 00:08\n",
      "Frame 7 at 00:10\n",
      "Frame 8 at 00:12\n",
      "Frame 9 at 00:13\n",
      "Frame 10 at 00:15\n",
      "Frame 11 at 00:17\n",
      "Frame 12 at 00:18\n",
      "Frame 13 at 00:20\n",
      "Frame 14 at 00:22\n",
      "Video context: A calico cat is seen sitting on a white sheet. \n",
      "Action in question: The cat closes its eyes as it grooms itself.\n",
      "Question: What is the timestamp range (start, end) in the video that best represents the action asked? ASSISTANT:00:03, 00:13\n"
     ]
    }
   ],
   "source": [
    "example = next(iter(train_dataloader))\n",
    "view_sample_with_video({\"pixel_values_videos\": example[2], \"input_ids\": example[0]}, processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of input_ids (Batch, Token): torch.Size([2, 3996])\n",
      "shape of attention_mask (Batch, Token): torch.Size([2, 3996])\n",
      "shape of pixel_values_videos (Batch, Frame, Channel, Height, Width): torch.Size([2, 14, 3, 224, 224])\n",
      "shape of labels (Batch, Token): torch.Size([2, 3996])\n"
     ]
    }
   ],
   "source": [
    "_input_ids, _attention_mask, _pixel_values_videos, _labels = example\n",
    "print(f\"shape of input_ids (Batch, Token): {_input_ids.shape}\")\n",
    "print(f\"shape of attention_mask (Batch, Token): {_attention_mask.shape}\")\n",
    "print(f\"shape of pixel_values_videos (Batch, Frame, Channel, Height, Width): {_pixel_values_videos.shape}\")\n",
    "print(f\"shape of labels (Batch, Token): {_labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model\n",
    "\n",
    "This model has 7 billion parameters. The model has undergone supervised fine-tuning on videochat instruction dataset. \n",
    "\n",
    "We load this model with quantization and only train lora layers on top of the model. LoRA or low-rank adaptaion allows to just freeze the existing weight and train a couple of adapter layers on top of the base model. The quantization in use is from bitsandbytes and it allows for each parameter to be just 4 bits instead of 32 bits. This allows us to train the model with batch size = 2 in a 24gb gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7445671c25c74c338451f63c40158942",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "model = VideoLlavaForConditionalGeneration.from_pretrained(\n",
    "    \"LanguageBind/Video-LLaVA-7B-hf\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "model.generation_config.max_new_tokens = 32\n",
    "model.config.return_dict = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we load the base model. We add lora adapter layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=args.lora_r,\n",
    "    lora_alpha=args.lora_alpha,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=find_all_linear_names(model),\n",
    "    init_lora_weights=\"gaussian\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ") \n",
    "\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a custom LightningModule to control the eval loop and train loop. With this, we do not have to add boilerplate code such as moving the data to gpu, moving it back, backward propagation, gradient checkpointing, and many more. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning import LightningModule\n",
    "from project.trainer.metrics import ao_exact_score, mr_iou_score\n",
    "from deepspeed.ops.adam import DeepSpeedCPUAdam\n",
    "from torch import Tensor\n",
    "from bitsandbytes.optim.adam import Adam8bit\n",
    "\n",
    "\n",
    "class VideoLlavaModelPLModule(LightningModule):\n",
    "    def __init__(self, config, processor, model):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(ignore=[\"model\"])\n",
    "        self.config = config\n",
    "        self.processor = processor\n",
    "        self.model = model\n",
    "\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        input_ids: Tensor\n",
    "        attention_mask: Tensor\n",
    "        pixel_values_videos: Tensor\n",
    "        labels: Tensor\n",
    "        input_ids, attention_mask, pixel_values_videos, labels = batch\n",
    "\n",
    "        outputs = self.model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            pixel_values_videos=pixel_values_videos,\n",
    "            labels=labels\n",
    "        )\n",
    "        loss = outputs.loss\n",
    "        self.log(\"train_loss\", loss)\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "\n",
    "        input_ids, attention_mask, pixel_values_videos, labels, frame_info = batch\n",
    "\n",
    "        # autoregressively generate token IDs\n",
    "        generated_ids = self.model.generate(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            pixel_values_videos=pixel_values_videos,\n",
    "            max_new_tokens=50,\n",
    "            do_sample=False,\n",
    "        )\n",
    "        # turn them back into text, chopping of the prompt\n",
    "        predictions = self.processor.batch_decode(\n",
    "            generated_ids[:, input_ids.size(1):], \n",
    "            skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "        frame_info = batch[-1]\n",
    "        score, correct = mr_iou_score(predictions, frame_info, labels) \n",
    "            \n",
    "        self.log(\"val_accuracy\", score)\n",
    "\n",
    "        return correct\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # use 8 bit optimizer\n",
    "        optimizer = Adam8bit(self.parameters(), min_8bit_size=4096, lr=self.config.get(\"lr\"))\n",
    "        # optimizer = DeepSpeedCPUAdam(self.parameters(), lr=2e-5)\n",
    "        # optimizer = torch.optim.AdamW(self.parameters(), lr=self.config.get(\"lr\"))\n",
    "\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "module = VideoLlavaModelPLModule(\n",
    "    config={\n",
    "        \"lr\": args.learning_rate\n",
    "    },\n",
    "    processor=processor,\n",
    "    model=model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_epochs': 2, 'accumulate_grad_batches': 1, 'limit_val_batches': 24, 'val_check_interval': 0.25, 'precision': '16-mixed', 'gradient_clip_val': 1.0, 'num_sanity_val_steps': None}\n"
     ]
    }
   ],
   "source": [
    "limit_val_batches = (args.limit_val_batches // args.batch_size) * args.batch_size\n",
    "train_conf = {\n",
    "    \"max_epochs\": args.max_epoch,\n",
    "    \"accumulate_grad_batches\": 1,\n",
    "    \"limit_val_batches\": int(limit_val_batches),\n",
    "    \"val_check_interval\": args.val_check_interval,\n",
    "    \"precision\": \"16-mixed\",\n",
    "    \"gradient_clip_val\": 1.0,\n",
    "    \"num_sanity_val_steps\": None\n",
    "}\n",
    "print(train_conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define 2 callbacks: early stopping and model checkpoint. Early stopping stops the training if the model does not do better in evaluation (patience is 3 by default) and model checkpoint saves the module state (model, processor, hparams, and more) so that training can be continued."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor=\"val_accuracy\", verbose=False, mode=\"min\")\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    monitor='val_accuracy',\n",
    "    dirpath='output/',\n",
    "    filename='videollava-7b-ao-{epoch:02d}-{val_accuracy:.2f}'+f\"lora_r{args.lora_r}-lora_alpha{args.lora_alpha}\"\n",
    ")\n",
    "callbacks = [\n",
    "    early_stopping, model_checkpoint\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "/opt/conda/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/amp.py:54: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/opt/conda/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:67: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    **train_conf,\n",
    "    accelerator=\"auto\",\n",
    "    devices=[0],\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/opt/conda/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=63` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efbef18ae0f3477aa537def871975e46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/lightning/pytorch/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "     Validate metric           DataLoader 0\n",
      "\n",
      "      val_accuracy          0.39441820979118347\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'val_accuracy': 0.39441820979118347}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.validate(module,eval_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type                 | Params\n",
      "-----------------------------------------------\n",
      "0 | model | PeftModelForCausalLM | 3.8 B \n",
      "-----------------------------------------------\n",
      "27.2 M    Trainable params\n",
      "3.8 B     Non-trainable params\n",
      "3.8 B     Total params\n",
      "15,371.895Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=63` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d0b053c73c24d16b57cd53c391cabfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(module, train_dataloader, eval_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9700e53aef2f45039de622014fc97007",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "     Validate metric           DataLoader 0\n",
      "\n",
      "      val_accuracy          0.5136803388595581\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'val_accuracy': 0.5136803388595581}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.validate(module,eval_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc5a894e279c487ebb0ede543538cd78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/109M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/jwnt4/finetune-videollava-qlora/commit/00e3c2933eb0730cd834938d3f6f787a94a7a181', commit_message='stage-1', commit_description='', oid='00e3c2933eb0730cd834938d3f6f787a94a7a181', pr_url=None, repo_url=RepoUrl('https://huggingface.co/jwnt4/finetune-videollava-qlora', endpoint='https://huggingface.co', repo_type='model', repo_id='jwnt4/finetune-videollava-qlora'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model.model.push_to_hub(Config.hub_repo, commit_message=\"stage-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c95e21321c7e4d058698b133df4b380f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "574360209a044b2593381fcf8bde955e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/jwnt4/finetune-videollava-qlora/commit/2a68c3634b86cc140db2042e904c218dbe996c67', commit_message='stage-1 processor', commit_description='', oid='2a68c3634b86cc140db2042e904c218dbe996c67', pr_url=None, repo_url=RepoUrl('https://huggingface.co/jwnt4/finetune-videollava-qlora', endpoint='https://huggingface.co', repo_type='model', repo_id='jwnt4/finetune-videollava-qlora'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model.processor.push_to_hub(Config.hub_repo, commit_message=\"stage-1 processor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference with the new model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del model\n",
    "# del trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(dataset['test'], collate_fn=DataCollatorWithPadding(processor), batch_size=1, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3576212e2a741559feeb5a4c581b961",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = VideoLlavaForConditionalGeneration.from_pretrained(\n",
    "    \"LanguageBind/Video-LLaVA-7B-hf\",\n",
    "    torch_dtype=torch.float16,\n",
    "    _attn_implementation=\"flash_attention_2\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "model.generation_config.max_new_tokens = 32\n",
    "model.config.return_dict = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: ['00:00, 00:29']. Labels: [['00:15', '00:29']]\n",
      "prediction: ['00:31, 00:40']. Labels: [['00:25', '00:40']]\n",
      "prediction: ['00:10, 00:30']. Labels: [['00:10', '00:33']]\n",
      "prediction: ['00:00, 00:30']. Labels: [['00:06', '00:41']]\n",
      "prediction: ['00:10, 00:30']. Labels: [['00:15', '00:32']]\n",
      "prediction: ['00:10, 00:30']. Labels: [['00:11', '00:20']]\n",
      "prediction: ['00:30, 00:45']. Labels: [['00:00', '00:39']]\n",
      "prediction: ['00:10, 00:30']. Labels: [['00:05', '00:34']]\n",
      "prediction: ['00:10, 00:30']. Labels: [['00:10', '00:15']]\n",
      "prediction: ['00:10, 00:30']. Labels: [['00:21', '00:35']]\n",
      "prediction: ['00:10, 00:30']. Labels: [['00:10', '00:11']]\n",
      "prediction: ['00:38, 00:50']. Labels: [['00:27', '00:46']]\n",
      "prediction: ['00:00, 00:30']. Labels: [['00:05', '00:23']]\n",
      "prediction: ['00:00, 00:39']. Labels: [['00:06', '00:39']]\n",
      "prediction: ['00:00, 00:30']. Labels: [['00:12', '00:28']]\n",
      "prediction: ['00:10, 00:30']. Labels: [['00:14', '00:26']]\n",
      "prediction: ['00:00, 00:30']. Labels: [['00:07', '00:23']]\n",
      "prediction: ['00:10, 00:30']. Labels: [['00:18', '00:33']]\n",
      "prediction: ['00:00, 00:26']. Labels: [['00:06', '00:20']]\n",
      "prediction: ['00:10, 00:30']. Labels: [['00:05', '00:19']]\n",
      "prediction: ['00:10, 00:30']. Labels: [['00:04', '00:20']]\n",
      "prediction: ['00:00, 00:25']. Labels: [['00:04', '00:15']]\n",
      "prediction: ['00:10, 00:30']. Labels: [['00:13', '00:29']]\n",
      "prediction: ['00:00, 00:30']. Labels: [['00:09', '00:23']]\n",
      "prediction: ['00:00, 00:23']. Labels: [['00:05', '00:14']]\n",
      "prediction: ['00:30, 00:49']. Labels: [['00:09', '00:27']]\n",
      "prediction: ['00:00, 00:33']. Labels: [['00:10', '00:33']]\n",
      "prediction: ['00:10, 00:30']. Labels: [['00:10', '00:22']]\n",
      "prediction: ['00:10, 00:30']. Labels: [['00:10', '00:29']]\n",
      "prediction: ['00:00, 00:29']. Labels: [['00:16', '00:29']]\n",
      "prediction: ['00:35, 00:42']. Labels: [['00:00', '00:06']]\n",
      "prediction: ['00:00, 00:41']. Labels: [['00:10', '00:29']]\n",
      "prediction: ['00:10, 00:30']. Labels: [['00:07', '00:10']]\n",
      "prediction: ['00:10, 00:30']. Labels: [['00:11', '00:26']]\n",
      "prediction: ['00:00, 00:25']. Labels: [['00:16', '00:25']]\n",
      "prediction: ['00:00, 00:35']. Labels: [['00:11', '00:27']]\n",
      "prediction: ['00:00, 00:21']. Labels: [['00:07', '00:16']]\n",
      "prediction: ['00:31, 00:33']. Labels: [['00:15', '00:33']]\n",
      "prediction: ['00:00, 00:28']. Labels: [['00:06', '00:22']]\n",
      "prediction: ['00:00, 00:35']. Labels: [['00:11', '00:27']]\n",
      "prediction: ['00:10, 00:30']. Labels: [['00:03', '00:39']]\n",
      "prediction: ['00:00, 00:30']. Labels: [['00:07', '00:28']]\n",
      "prediction: ['00:00, 00:25']. Labels: [['00:06', '00:16']]\n",
      "prediction: ['00:00, 00:35']. Labels: [['00:11', '00:27']]\n",
      "prediction: ['00:10, 00:30']. Labels: [['00:07', '00:46']]\n",
      "prediction: ['00:00, 00:22']. Labels: [['00:10', '00:22']]\n",
      "prediction: ['00:00, 00:37']. Labels: [['00:23', '00:37']]\n",
      "prediction: ['00:10, 00:30']. Labels: [['00:12', '00:25']]\n",
      "prediction: ['00:30, 00:59']. Labels: [['00:24', '00:39']]\n",
      "prediction: ['00:00, 00:30']. Labels: [['00:09', '00:33']]\n",
      "prediction: ['00:10, 00:30']. Labels: [['00:07', '00:20']]\n",
      "prediction: ['00:00, 00:36']. Labels: [['00:14', '00:28']]\n",
      "prediction: ['00:10, 00:30']. Labels: [['00:03', '00:38']]\n",
      "prediction: ['00:11, 00:37']. Labels: [['00:06', '00:26']]\n",
      "prediction: ['00:00, 00:30']. Labels: [['00:15', '00:41']]\n",
      "prediction: ['00:00, 00:28']. Labels: [['00:15', '00:28']]\n",
      "prediction: ['00:10, 00:30']. Labels: [['00:27', '00:44']]\n",
      "prediction: ['00:00, 00:30']. Labels: [['00:07', '00:45']]\n",
      "prediction: ['00:00, 00:50']. Labels: [['00:11', '00:31']]\n",
      "prediction: ['00:00, 00:30']. Labels: [['00:23', '00:30']]\n",
      "prediction: ['00:30, 00:40']. Labels: [['00:30', '00:39']]\n",
      "prediction: ['00:10, 00:30']. Labels: [['00:28', '00:31']]\n",
      "prediction: ['00:10, 00:30']. Labels: [['00:06', '00:12']]\n",
      "prediction: ['00:30, 00:40']. Labels: [['00:25', '00:30']]\n",
      "prediction: ['00:10, 00:30']. Labels: [['00:05', '00:13']]\n",
      "prediction: ['00:10, 00:30']. Labels: [['00:20', '00:26']]\n",
      "prediction: ['00:10, 00:30']. Labels: [['00:19', '00:32']]\n",
      "prediction: ['00:10, 00:30']. Labels: [['00:16', '00:26']]\n",
      "prediction: ['00:00, 00:25']. Labels: [['00:17', '00:25']]\n",
      "prediction: ['00:10, 00:30']. Labels: [['00:29', '00:34']]\n",
      "prediction: ['00:00, 00:30']. Labels: [['00:23', '00:30']]\n",
      "prediction: ['00:00, 00:23']. Labels: [['00:16', '00:23']]\n",
      "prediction: ['00:30, 00:40']. Labels: [['00:24', '00:39']]\n",
      "prediction: ['00:00, 00:30']. Labels: [['00:05', '00:23']]\n",
      "prediction: ['00:32, 00:39']. Labels: [['00:22', '00:29']]\n",
      "prediction: ['00:10, 00:30']. Labels: [['00:32', '00:42']]\n",
      "prediction: ['00:00, 00:29']. Labels: [['00:09', '00:18']]\n",
      "prediction: ['00:00, 00:30']. Labels: [['00:38', '00:38']]\n",
      "prediction: ['00:10, 00:30']. Labels: [['00:29', '00:41']]\n",
      "prediction: ['00:10, 00:30']. Labels: [['00:07', '00:07']]\n",
      "prediction: ['00:31, 00:41']. Labels: [['00:26', '00:37']]\n",
      "prediction: ['00:00, 00:30']. Labels: [['00:10', '00:18']]\n",
      "prediction: ['00:00, 00:35']. Labels: [['00:29', '00:35']]\n",
      "prediction: ['00:10, 00:30']. Labels: [['00:16', '00:21']]\n",
      "prediction: ['00:10, 00:30']. Labels: [['00:05', '00:18']]\n",
      "prediction: ['00:00, 00:28']. Labels: [['00:22', '00:28']]\n",
      "prediction: ['00:10, 00:30']. Labels: [['00:30', '00:35']]\n",
      "prediction: ['00:10, 00:30']. Labels: [['00:39', '00:42']]\n",
      "prediction: ['00:00, 00:28']. Labels: [['00:04', '00:07']]\n",
      "prediction: ['00:00, 00:25']. Labels: [['00:20', '00:25']]\n",
      "prediction: ['00:00, 00:35']. Labels: [['00:24', '00:35']]\n",
      "prediction: ['00:35, 00:46']. Labels: [['00:46', '00:46']]\n",
      "prediction: ['00:00, 00:22']. Labels: [['00:03', '00:12']]\n",
      "prediction: ['00:00, 00:37']. Labels: [['00:09', '00:23']]\n",
      "prediction: ['00:10, 00:30']. Labels: [['00:06', '00:12']]\n",
      "prediction: ['00:10, 00:30']. Labels: [['00:12', '00:21']]\n",
      "prediction: ['00:30, 00:45']. Labels: [['00:30', '00:39']]\n",
      "prediction: ['00:10, 00:30']. Labels: [['00:22', '00:29']]\n",
      "prediction: ['00:31, 00:41']. Labels: [['00:31', '00:33']]\n",
      "prediction: ['00:10, 00:30']. Labels: [['00:38', '00:45']]\n",
      "prediction: ['00:10, 00:30']. Labels: [['00:26', '00:37']]\n",
      "prediction: ['00:00, 00:30']. Labels: [['00:41', '00:48']]\n",
      "prediction: ['00:00, 00:28']. Labels: [['00:07', '00:20']]\n",
      "prediction: ['00:10, 00:30']. Labels: [['00:13', '00:23']]\n",
      "prediction: ['00:00, 00:30']. Labels: [['00:03', '00:07']]\n",
      "prediction: ['00:10, 00:30']. Labels: [['00:13', '00:26']]\n",
      "prediction: ['00:10, 00:30']. Labels: [['00:21', '00:32']]\n",
      "prediction: ['00:32, 00:41']. Labels: [['00:24', '00:38']]\n",
      "prediction: ['00:31, 00:50']. Labels: [['00:19', '00:50']]\n",
      "prediction: ['00:00, 00:28']. Labels: [['00:04', '00:20']]\n",
      "prediction: ['00:00, 00:30']. Labels: [['00:04', '00:15']]\n",
      "prediction: ['00:32, 00:41']. Labels: [['00:23', '00:38']]\n",
      "prediction: ['00:00, 00:20']. Labels: [['00:15', '00:20']]\n",
      "prediction: ['00:10, 00:30']. Labels: [['00:17', '00:38']]\n",
      "prediction: ['00:00, 00:26']. Labels: [['00:02', '00:26']]\n",
      "prediction: ['00:10, 00:30']. Labels: [['00:26', '00:34']]\n",
      "prediction: ['00:10, 00:30']. Labels: [['00:32', '00:43']]\n",
      "prediction: ['00:32, 00:41']. Labels: [['00:09', '00:24']]\n",
      "prediction: ['00:31, 00:50']. Labels: [['00:08', '00:19']]\n",
      "prediction: ['00:28, 00:32']. Labels: [['00:20', '00:26']]\n",
      "prediction: ['00:10, 00:30']. Labels: [['00:15', '00:23']]\n",
      "prediction: ['00:10, 00:30']. Labels: [['00:06', '00:15']]\n",
      "prediction: ['00:10, 00:30']. Labels: [['00:09', '00:14']]\n",
      "prediction: ['00:31, 00:45']. Labels: [['00:03', '00:17']]\n",
      "prediction: ['00:10, 00:30']. Labels: [['00:04', '00:26']]\n",
      "prediction: ['00:00, 00:34']. Labels: [['00:03', '00:08']]\n",
      "prediction: ['00:00, 00:46']. Labels: [['00:43', '00:46']]\n",
      "prediction: ['00:32, 00:38']. Labels: [['00:21', '00:24']]\n",
      "prediction: ['00:00, 00:50']. Labels: [['00:04', '00:08']]\n",
      "prediction: ['00:28, 00:32']. Labels: [['00:26', '00:28']]\n",
      "prediction: ['00:00, 00:27']. Labels: [['00:23', '00:27']]\n",
      "prediction: ['00:35, 00:42']. Labels: [['00:29', '00:38']]\n",
      "prediction: ['00:00, 00:20']. Labels: [['00:05', '00:11']]\n",
      "prediction: ['00:00, 00:45']. Labels: [['00:38', '00:45']]\n",
      "prediction: ['00:10, 00:30']. Labels: [['00:12', '00:26']]\n"
     ]
    }
   ],
   "source": [
    "final_score = 0\n",
    "with torch.inference_mode():\n",
    "    for batch in test_dataloader:\n",
    "        input_ids, attention_mask, pixel_values_videos, labels, frame_info = batch\n",
    "\n",
    "        # autoregressively generate token IDs\n",
    "        generated_ids = model.generate(\n",
    "            input_ids=input_ids.to(model.device),\n",
    "            attention_mask=attention_mask.to(model.device),\n",
    "            pixel_values_videos=pixel_values_videos.to(model.device),\n",
    "            max_new_tokens=50,\n",
    "            do_sample=False,\n",
    "        )\n",
    "        # turn them back into text, chopping of the prompt\n",
    "        predictions = processor.batch_decode(\n",
    "            generated_ids[:, input_ids.size(1):], \n",
    "            skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "        print(f\"prediction: {predictions}. Labels: {labels}\")\n",
    "        frame_info = batch[-1]\n",
    "        score, _ = mr_iou_score(predictions, frame_info, labels) \n",
    "        final_score += score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Score for original model: 0.42'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"Score for original model: {final_score/135:.2f}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3344f4d75cf64c079d6ad7ceb7e3ce65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "VideoLlavaForConditionalGeneration(\n",
       "  (video_tower): CLIPVisionModel(\n",
       "    (vision_model): CLIPVisionTransformer(\n",
       "      (embeddings): CLIPVisionEmbeddings(\n",
       "        (patch_embedding): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14), bias=False)\n",
       "        (position_embedding): Embedding(257, 1024)\n",
       "      )\n",
       "      (pre_layrnorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (encoder): CLIPEncoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-23): 24 x CLIPEncoderLayer(\n",
       "            (self_attn): CLIPSdpaAttention(\n",
       "              (k_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1024, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1024, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (q_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1024, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (out_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1024, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): CLIPMLP(\n",
       "              (activation_fn): QuickGELUActivation()\n",
       "              (fc1): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1024, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (fc2): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (post_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (image_tower): CLIPVisionModel(\n",
       "    (vision_model): CLIPVisionTransformer(\n",
       "      (embeddings): CLIPVisionEmbeddings(\n",
       "        (patch_embedding): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14), bias=False)\n",
       "        (position_embedding): Embedding(257, 1024)\n",
       "      )\n",
       "      (pre_layrnorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (encoder): CLIPEncoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-23): 24 x CLIPEncoderLayer(\n",
       "            (self_attn): CLIPSdpaAttention(\n",
       "              (k_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1024, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1024, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (q_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1024, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (out_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1024, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): CLIPMLP(\n",
       "              (activation_fn): QuickGELUActivation()\n",
       "              (fc1): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1024, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (fc2): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (post_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (multi_modal_projector): VideoLlavaMultiModalProjector(\n",
       "    (linear_1): lora.Linear(\n",
       "      (base_layer): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "      (lora_dropout): ModuleDict(\n",
       "        (default): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (lora_A): ModuleDict(\n",
       "        (default): Linear(in_features=1024, out_features=8, bias=False)\n",
       "      )\n",
       "      (lora_B): ModuleDict(\n",
       "        (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "      )\n",
       "      (lora_embedding_A): ParameterDict()\n",
       "      (lora_embedding_B): ParameterDict()\n",
       "      (lora_magnitude_vector): ModuleDict()\n",
       "    )\n",
       "    (act): GELUActivation()\n",
       "    (linear_2): lora.Linear(\n",
       "      (base_layer): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "      (lora_dropout): ModuleDict(\n",
       "        (default): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (lora_A): ModuleDict(\n",
       "        (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "      )\n",
       "      (lora_B): ModuleDict(\n",
       "        (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "      )\n",
       "      (lora_embedding_A): ParameterDict()\n",
       "      (lora_embedding_B): ParameterDict()\n",
       "      (lora_magnitude_vector): ModuleDict()\n",
       "    )\n",
       "  )\n",
       "  (language_model): LlamaForCausalLM(\n",
       "    (model): LlamaModel(\n",
       "      (embed_tokens): Embedding(32064, 4096, padding_idx=0)\n",
       "      (layers): ModuleList(\n",
       "        (0-31): 32 x LlamaDecoderLayer(\n",
       "          (self_attn): LlamaSdpaAttention(\n",
       "            (q_proj): lora.Linear(\n",
       "              (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (k_proj): lora.Linear(\n",
       "              (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (v_proj): lora.Linear(\n",
       "              (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (o_proj): lora.Linear(\n",
       "              (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (rotary_emb): LlamaRotaryEmbedding()\n",
       "          )\n",
       "          (mlp): LlamaMLP(\n",
       "            (gate_proj): lora.Linear(\n",
       "              (base_layer): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=8, out_features=11008, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (up_proj): lora.Linear(\n",
       "              (base_layer): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=8, out_features=11008, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (down_proj): lora.Linear(\n",
       "              (base_layer): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=11008, out_features=8, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (act_fn): SiLU()\n",
       "          )\n",
       "          (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "          (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "        )\n",
       "      )\n",
       "      (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "      (rotary_emb): LlamaRotaryEmbedding()\n",
       "    )\n",
       "    (lm_head): Linear(in_features=4096, out_features=32064, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = VideoLlavaForConditionalGeneration.from_pretrained(\n",
    "    Config.hub_repo,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "model.generation_config.max_new_tokens = 32\n",
    "model.config.return_dict = True\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: ['00:07, 00:29']. Labels: [['00:15', '00:29']]\n",
      "prediction: ['00:22, 00:40']. Labels: [['00:25', '00:40']]\n",
      "prediction: ['00:08, 00:20']. Labels: [['00:10', '00:33']]\n",
      "prediction: ['00:13, 00:38']. Labels: [['00:06', '00:41']]\n",
      "prediction: ['00:22, 00:32']. Labels: [['00:15', '00:32']]\n",
      "prediction: ['00:07, 00:20']. Labels: [['00:11', '00:20']]\n",
      "prediction: ['00:21, 00:39']. Labels: [['00:00', '00:39']]\n",
      "prediction: ['00:24, 00:34']. Labels: [['00:05', '00:34']]\n",
      "prediction: ['00:08, 00:33']. Labels: [['00:10', '00:15']]\n",
      "prediction: ['00:16, 00:35']. Labels: [['00:21', '00:35']]\n",
      "prediction: ['00:08, 00:21']. Labels: [['00:10', '00:11']]\n",
      "prediction: ['00:34, 00:50']. Labels: [['00:27', '00:46']]\n",
      "prediction: ['00:05, 00:27']. Labels: [['00:05', '00:23']]\n",
      "prediction: ['00:06, 00:39']. Labels: [['00:06', '00:39']]\n",
      "prediction: ['00:24, 00:31']. Labels: [['00:12', '00:28']]\n",
      "prediction: ['00:06, 00:26']. Labels: [['00:14', '00:26']]\n",
      "prediction: ['00:05, 00:28']. Labels: [['00:07', '00:23']]\n",
      "prediction: ['00:23, 00:33']. Labels: [['00:18', '00:33']]\n",
      "prediction: ['00:06, 00:26']. Labels: [['00:06', '00:20']]\n",
      "prediction: ['00:07, 00:29']. Labels: [['00:05', '00:19']]\n",
      "prediction: ['00:16, 00:26']. Labels: [['00:04', '00:20']]\n",
      "prediction: ['00:06, 00:25']. Labels: [['00:04', '00:15']]\n",
      "prediction: ['00:24, 00:34']. Labels: [['00:13', '00:29']]\n",
      "prediction: ['00:09, 00:28']. Labels: [['00:09', '00:23']]\n",
      "prediction: ['00:04, 00:21']. Labels: [['00:05', '00:14']]\n",
      "prediction: ['00:06, 00:39']. Labels: [['00:09', '00:27']]\n",
      "prediction: ['00:08, 00:20']. Labels: [['00:10', '00:33']]\n",
      "prediction: ['00:17, 00:32']. Labels: [['00:10', '00:22']]\n",
      "prediction: ['00:10, 00:32']. Labels: [['00:10', '00:29']]\n",
      "prediction: ['00:07, 00:29']. Labels: [['00:16', '00:29']]\n",
      "prediction: ['00:29, 00:38']. Labels: [['00:00', '00:06']]\n",
      "prediction: ['00:06, 00:29']. Labels: [['00:10', '00:29']]\n",
      "prediction: ['00:17, 00:32']. Labels: [['00:07', '00:10']]\n",
      "prediction: ['00:11, 00:37']. Labels: [['00:11', '00:26']]\n",
      "prediction: ['00:18, 00:25']. Labels: [['00:16', '00:25']]\n",
      "prediction: ['00:08, 00:21']. Labels: [['00:11', '00:27']]\n",
      "prediction: ['00:07, 00:21']. Labels: [['00:07', '00:16']]\n",
      "prediction: ['00:23, 00:33']. Labels: [['00:15', '00:33']]\n",
      "prediction: ['00:06, 00:28']. Labels: [['00:06', '00:22']]\n",
      "prediction: ['00:08, 00:35']. Labels: [['00:11', '00:27']]\n",
      "prediction: ['00:19, 00:42']. Labels: [['00:03', '00:39']]\n",
      "prediction: ['00:07, 00:28']. Labels: [['00:07', '00:28']]\n",
      "prediction: ['00:06, 00:18']. Labels: [['00:06', '00:16']]\n",
      "prediction: ['00:08, 00:32']. Labels: [['00:11', '00:27']]\n",
      "prediction: ['00:07, 00:46']. Labels: [['00:07', '00:46']]\n",
      "prediction: ['00:07, 00:22']. Labels: [['00:10', '00:22']]\n",
      "prediction: ['00:09, 00:37']. Labels: [['00:23', '00:37']]\n",
      "prediction: ['00:06, 00:25']. Labels: [['00:12', '00:25']]\n",
      "prediction: ['00:24, 00:39']. Labels: [['00:24', '00:39']]\n",
      "prediction: ['00:06, 00:30']. Labels: [['00:09', '00:33']]\n",
      "prediction: ['00:07, 00:29']. Labels: [['00:07', '00:20']]\n",
      "prediction: ['00:06, 00:36']. Labels: [['00:14', '00:28']]\n",
      "prediction: ['00:07, 00:38']. Labels: [['00:03', '00:38']]\n",
      "prediction: ['00:23, 00:37']. Labels: [['00:06', '00:26']]\n",
      "prediction: ['00:07, 00:41']. Labels: [['00:15', '00:41']]\n",
      "prediction: ['00:07, 00:28']. Labels: [['00:15', '00:28']]\n",
      "prediction: ['00:10, 00:44']. Labels: [['00:27', '00:44']]\n",
      "prediction: ['00:07, 00:21']. Labels: [['00:07', '00:45']]\n",
      "prediction: ['00:08, 00:34']. Labels: [['00:11', '00:31']]\n",
      "prediction: ['00:05, 00:27']. Labels: [['00:23', '00:30']]\n",
      "prediction: ['00:33, 00:39']. Labels: [['00:30', '00:39']]\n",
      "prediction: ['00:24, 00:31']. Labels: [['00:28', '00:31']]\n",
      "prediction: ['00:06, 00:18']. Labels: [['00:06', '00:12']]\n",
      "prediction: ['00:23, 00:30']. Labels: [['00:25', '00:30']]\n",
      "prediction: ['00:08, 00:28']. Labels: [['00:05', '00:13']]\n",
      "prediction: ['00:18, 00:26']. Labels: [['00:20', '00:26']]\n",
      "prediction: ['00:07, 00:29']. Labels: [['00:19', '00:32']]\n",
      "prediction: ['00:18, 00:26']. Labels: [['00:16', '00:26']]\n",
      "prediction: ['00:06, 00:25']. Labels: [['00:17', '00:25']]\n",
      "prediction: ['00:29, 00:34']. Labels: [['00:29', '00:34']]\n",
      "prediction: ['00:09, 00:28']. Labels: [['00:23', '00:30']]\n",
      "prediction: ['00:07, 00:23']. Labels: [['00:16', '00:23']]\n",
      "prediction: ['00:24, 00:39']. Labels: [['00:24', '00:39']]\n",
      "prediction: ['00:08, 00:28']. Labels: [['00:05', '00:23']]\n",
      "prediction: ['00:29, 00:32']. Labels: [['00:22', '00:29']]\n",
      "prediction: ['00:32, 00:42']. Labels: [['00:32', '00:42']]\n",
      "prediction: ['00:05, 00:20']. Labels: [['00:09', '00:18']]\n",
      "prediction: ['00:23, 00:38']. Labels: [['00:38', '00:38']]\n",
      "prediction: ['00:29, 00:41']. Labels: [['00:29', '00:41']]\n",
      "prediction: ['00:17, 00:32']. Labels: [['00:07', '00:07']]\n",
      "prediction: ['00:20, 00:37']. Labels: [['00:26', '00:37']]\n",
      "prediction: ['00:06, 00:25']. Labels: [['00:10', '00:18']]\n",
      "prediction: ['00:08, 00:21']. Labels: [['00:29', '00:35']]\n",
      "prediction: ['00:18, 00:21']. Labels: [['00:16', '00:21']]\n",
      "prediction: ['00:08, 00:20']. Labels: [['00:05', '00:18']]\n",
      "prediction: ['00:06, 00:28']. Labels: [['00:22', '00:28']]\n",
      "prediction: ['00:08, 00:32']. Labels: [['00:30', '00:35']]\n",
      "prediction: ['00:32, 00:42']. Labels: [['00:39', '00:42']]\n",
      "prediction: ['00:07, 00:28']. Labels: [['00:04', '00:07']]\n",
      "prediction: ['00:06, 00:25']. Labels: [['00:20', '00:25']]\n",
      "prediction: ['00:16, 00:35']. Labels: [['00:24', '00:35']]\n",
      "prediction: ['00:39, 00:46']. Labels: [['00:46', '00:46']]\n",
      "prediction: ['00:07, 00:22']. Labels: [['00:03', '00:12']]\n",
      "prediction: ['00:06, 00:37']. Labels: [['00:09', '00:23']]\n",
      "prediction: ['00:06, 00:25']. Labels: [['00:06', '00:12']]\n",
      "prediction: ['00:12, 00:39']. Labels: [['00:12', '00:21']]\n",
      "prediction: ['00:33, 00:39']. Labels: [['00:30', '00:39']]\n",
      "prediction: ['00:07, 00:29']. Labels: [['00:22', '00:29']]\n",
      "prediction: ['00:28, 00:36']. Labels: [['00:31', '00:33']]\n",
      "prediction: ['00:31, 00:45']. Labels: [['00:38', '00:45']]\n",
      "prediction: ['00:06, 00:29']. Labels: [['00:26', '00:37']]\n",
      "prediction: ['00:34, 00:48']. Labels: [['00:41', '00:48']]\n",
      "prediction: ['00:07, 00:26']. Labels: [['00:07', '00:20']]\n",
      "prediction: ['00:07, 00:37']. Labels: [['00:13', '00:23']]\n",
      "prediction: ['00:07, 00:21']. Labels: [['00:03', '00:07']]\n",
      "prediction: ['00:08, 00:28']. Labels: [['00:13', '00:26']]\n",
      "prediction: ['00:11, 00:39']. Labels: [['00:21', '00:32']]\n",
      "prediction: ['00:29, 00:38']. Labels: [['00:24', '00:38']]\n",
      "prediction: ['00:38, 00:50']. Labels: [['00:19', '00:50']]\n",
      "prediction: ['00:07, 00:28']. Labels: [['00:04', '00:20']]\n",
      "prediction: ['00:06, 00:27']. Labels: [['00:04', '00:15']]\n",
      "prediction: ['00:23, 00:38']. Labels: [['00:23', '00:38']]\n",
      "prediction: ['00:08, 00:20']. Labels: [['00:15', '00:20']]\n",
      "prediction: ['00:31, 00:45']. Labels: [['00:17', '00:38']]\n",
      "prediction: ['00:06, 00:26']. Labels: [['00:02', '00:26']]\n",
      "prediction: ['00:21, 00:34']. Labels: [['00:26', '00:34']]\n",
      "prediction: ['00:32, 00:46']. Labels: [['00:32', '00:43']]\n",
      "prediction: ['00:26, 00:38']. Labels: [['00:09', '00:24']]\n",
      "prediction: ['00:11, 00:38']. Labels: [['00:08', '00:19']]\n",
      "prediction: ['00:24, 00:28']. Labels: [['00:20', '00:26']]\n",
      "prediction: ['00:19, 00:27']. Labels: [['00:15', '00:23']]\n",
      "prediction: ['00:06, 00:20']. Labels: [['00:06', '00:15']]\n",
      "prediction: ['00:08, 00:14']. Labels: [['00:09', '00:14']]\n",
      "prediction: ['00:10, 00:38']. Labels: [['00:03', '00:17']]\n",
      "prediction: ['00:06, 00:26']. Labels: [['00:04', '00:26']]\n",
      "prediction: ['00:08, 00:21']. Labels: [['00:03', '00:08']]\n",
      "prediction: ['00:32, 00:46']. Labels: [['00:43', '00:46']]\n",
      "prediction: ['00:29, 00:38']. Labels: [['00:21', '00:24']]\n",
      "prediction: ['00:08, 00:31']. Labels: [['00:04', '00:08']]\n",
      "prediction: ['00:26, 00:28']. Labels: [['00:26', '00:28']]\n",
      "prediction: ['00:19, 00:27']. Labels: [['00:23', '00:27']]\n",
      "prediction: ['00:06, 00:12']. Labels: [['00:29', '00:38']]\n",
      "prediction: ['00:08, 00:14']. Labels: [['00:05', '00:11']]\n",
      "prediction: ['00:10, 00:45']. Labels: [['00:38', '00:45']]\n",
      "prediction: ['00:18, 00:26']. Labels: [['00:12', '00:26']]\n"
     ]
    }
   ],
   "source": [
    "new_score = 0\n",
    "with torch.inference_mode():\n",
    "    for batch in test_dataloader:\n",
    "        input_ids, attention_mask, pixel_values_videos, labels, frame_info = batch\n",
    "\n",
    "        # autoregressively generate token IDs\n",
    "        generated_ids = model.generate(\n",
    "            input_ids=input_ids.to(model.device),\n",
    "            attention_mask=attention_mask.to(model.device),\n",
    "            pixel_values_videos=pixel_values_videos.to(model.device),\n",
    "            max_new_tokens=50,\n",
    "            do_sample=False,\n",
    "        )\n",
    "        # turn them back into text, chopping of the prompt\n",
    "        predictions = processor.batch_decode(\n",
    "            generated_ids[:, input_ids.size(1):], \n",
    "            skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "        print(f\"prediction: {predictions}. Labels: {labels}\")\n",
    "        frame_info = batch[-1]\n",
    "        score, _ = mr_iou_score(predictions, frame_info, labels) \n",
    "        new_score += score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Score for trained model: 0.55'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"Score for trained model: {new_score/135:.2f}\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
