{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from project.dataset.collate import DataCollatorWithPadding\n",
    "from project.dataset.prepare import MomentRetrievalDataset\n",
    "from project.trainer.lightning import VideoLlavaModelPLModule\n",
    "from project.trainer.peft import find_all_linear_names\n",
    "\n",
    "from transformers import (\n",
    "    VideoLlavaProcessor,\n",
    "    BitsAndBytesConfig,\n",
    "    VideoLlavaForConditionalGeneration,\n",
    "    LlamaForCausalLM\n",
    ")\n",
    "from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model\n",
    "from datasets import load_from_disk\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from dataclasses import dataclass\n",
    "from lightning import Trainer\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks.model_checkpoint import ModelCheckpoint\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from lightning.pytorch.strategies import DeepSpeedStrategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    lora_r: int = 8\n",
    "    lora_alpha: int = 16\n",
    "    batch_size: int = 2\n",
    "    max_epoch: int = 2\n",
    "    val_check_interval: float = 0.25\n",
    "    learning_rate: float = 2e-5\n",
    "    dataset_dir: str = \"datasets/processed\"\n",
    "    num_frames: int = 14\n",
    "    num_worker: int = 2\n",
    "    hub_repo: str = \"jwnt4/finetune-videollava-qlora\"\n",
    "    accumulate_grad_batches: int = 2\n",
    "    limit_val_batches: float = 24\n",
    "\n",
    "args = Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('medium')\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "stream_handler = logging.StreamHandler(sys.stdout)\n",
    "\n",
    "if not os.path.isdir(\"logs\"):\n",
    "    os.makedirs(\"logs\")\n",
    "\n",
    "log_file = f\"logs/{str(datetime.now()).replace(' ', '_')}.log\"\n",
    "file_handler = logging.FileHandler(log_file)\n",
    "\n",
    "log_formatter = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\", datefmt=\"%m/%d/%Y %H:%M:%S\")\n",
    "stream_handler.setFormatter(log_formatter)\n",
    "\n",
    "logger.addHandler(stream_handler)\n",
    "logger.addHandler(file_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = VideoLlavaProcessor.from_pretrained(\"LanguageBind/Video-LLaVA-7B-hf\", use_fast=False)\n",
    "processor.patch_size = 14\n",
    "processor.vision_feature_select_strategy = \"default\"\n",
    "processor.tokenizer.deprecation_warnings[\"Asking-to-pad-a-fast-tokenizer\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = args.dataset_dir.split(\"/\")[0]\n",
    "processed_dir = args.dataset_dir.split(\"/\")[1]\n",
    "dp = MomentRetrievalDataset(\n",
    "    base_dir=base_dir, processed_dir=processed_dir, num_frames=args.num_frames, num_worker=2, processor=processor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = None\n",
    "try:\n",
    "    dataset = load_from_disk(f\"{args.dataset_dir}/moment_retrieval/timestamp/{args.num_frames}_frames\")\n",
    "except:\n",
    "    dataset = None\n",
    "if dataset is None:\n",
    "    dataset = dp.prepare_dataset(use_frame=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset['train'].select(range(40))\n",
    "eval_dataset = dataset['validation'].select(range(24))\n",
    "train_dataloader = DataLoader(dataset['train'], collate_fn=DataCollatorWithPadding(processor), batch_size=args.batch_size, shuffle=False, num_workers=2)\n",
    "eval_dataloader = DataLoader(dataset['validation'], collate_fn=DataCollatorWithPadding(processor), batch_size=args.batch_size, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "model = VideoLlavaForConditionalGeneration.from_pretrained(\n",
    "    \"LanguageBind/Video-LLaVA-7B-hf\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "model.generation_config.max_new_tokens = 32\n",
    "model.config.return_dict = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=args.lora_r,\n",
    "    lora_alpha=args.lora_alpha,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=find_all_linear_names(model),\n",
    "    init_lora_weights=\"gaussian\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ") \n",
    "\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning import LightningModule\n",
    "from project.trainer.metrics import ao_exact_score, mr_iou_score\n",
    "from deepspeed.ops.adam import DeepSpeedCPUAdam\n",
    "from torch import Tensor\n",
    "from bitsandbytes.optim.adam import Adam8bit\n",
    "\n",
    "\n",
    "class VideoLlavaModelPLModule(LightningModule):\n",
    "    def __init__(self, config, processor, model):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(ignore=[\"model\"])\n",
    "        self.config = config\n",
    "        self.processor = processor\n",
    "        self.model = model\n",
    "\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        input_ids: Tensor\n",
    "        attention_mask: Tensor\n",
    "        pixel_values_videos: Tensor\n",
    "        labels: Tensor\n",
    "        input_ids, attention_mask, pixel_values_videos, labels = batch\n",
    "\n",
    "        outputs = self.model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            pixel_values_videos=pixel_values_videos,\n",
    "            labels=labels\n",
    "        )\n",
    "        loss = outputs.loss\n",
    "\n",
    "        self.log(\"train_loss\", loss)\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "\n",
    "        input_ids, attention_mask, pixel_values_videos, labels, frame_info = batch\n",
    "\n",
    "        # autoregressively generate token IDs\n",
    "        generated_ids = self.model.generate(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            pixel_values_videos=pixel_values_videos,\n",
    "            max_new_tokens=50,\n",
    "            do_sample=False,\n",
    "        )\n",
    "        # turn them back into text, chopping of the prompt\n",
    "        predictions = self.processor.batch_decode(\n",
    "            generated_ids[:, input_ids.size(1):], \n",
    "            skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "        \n",
    "        frame_info = batch[-1]\n",
    "        score, correct = mr_iou_score(predictions, frame_info, labels) \n",
    "        print(score)\n",
    "            \n",
    "        self.log(\"val_accuracy\", score)\n",
    "\n",
    "        return correct\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # use 8 bit optimizer\n",
    "        optimizer = Adam8bit(self.parameters(), min_8bit_size=4096, lr=self.config.get(\"lr\"))\n",
    "        # optimizer = DeepSpeedCPUAdam(self.parameters(), lr=2e-5)\n",
    "        # optimizer = torch.optim.AdamW(self.parameters(), lr=self.config.get(\"lr\"))\n",
    "\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module = VideoLlavaModelPLModule(\n",
    "    config={\n",
    "        \"lr\": args.learning_rate\n",
    "    },\n",
    "    processor=processor,\n",
    "    model=model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit_val_batches = (args.limit_val_batches // args.batch_size) * args.batch_size\n",
    "train_conf = {\n",
    "    \"max_epochs\": args.max_epoch,\n",
    "    \"accumulate_grad_batches\": 1,\n",
    "    \"limit_val_batches\": int(limit_val_batches),\n",
    "    \"val_check_interval\": args.val_check_interval,\n",
    "    \"precision\": \"16-mixed\",\n",
    "    \"gradient_clip_val\": 1.0,\n",
    "    \"num_sanity_val_steps\": None\n",
    "}\n",
    "logger.info(str(train_conf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    **train_conf,\n",
    "    accelerator=\"auto\",\n",
    "    devices=[0],\n",
    "    # callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.validate(module, eval_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(module, train_dataloader, eval_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
