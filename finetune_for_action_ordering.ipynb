{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from project.dataset.prepare import DatasetPreparer\n",
    "from project.dataset.collate import DataCollatorWithPadding\n",
    "from project.trainer.lightning import VideoLlavaModelPLModule\n",
    "from project.trainer.peft import find_all_linear_names\n",
    "\n",
    "from transformers import (\n",
    "    VideoLlavaProcessor,\n",
    "    BitsAndBytesConfig,\n",
    "    VideoLlavaForConditionalGeneration\n",
    ")\n",
    "from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model\n",
    "from datasets import load_from_disk\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from dataclasses import dataclass\n",
    "from lightning import Trainer\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class model_conf:\n",
    "    model_id = \"LanguageBind/Video-LLaVA-7B-hf\"\n",
    "    lora_r = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = VideoLlavaProcessor.from_pretrained(\"LanguageBind/Video-LLaVA-7B-hf\", use_fast=False)\n",
    "processor.patch_size = 14\n",
    "processor.vision_feature_select_strategy = \"default\"\n",
    "processor.tokenizer.deprecation_warnings[\"Asking-to-pad-a-fast-tokenizer\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = DatasetPreparer(base_dir=\"datasets\", processed_dir=\"processed\", processor=processor, num_frames=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    dataset = load_from_disk(\"datasets/processed/action_ordering_v2/robust/14_frames\")\n",
    "except:\n",
    "    dataset = dp.prepare_dataset('action_ordering_v2', use_robust=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset['train'], collate_fn=DataCollatorWithPadding(processor), batch_size=4, shuffle=False, num_workers=2)\n",
    "eval_dataloader = DataLoader(dataset['test'], collate_fn=DataCollatorWithPadding(processor), batch_size=4, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_quant_storage=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True\n",
    ")\n",
    "model = VideoLlavaForConditionalGeneration.from_pretrained(\n",
    "    model_conf.model_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=model_conf.lora_r,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=find_all_linear_names(model),\n",
    "    init_lora_weights=\"gaussian\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = prepare_model_for_kbit_training(model)\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class train_conf:\n",
    "    max_epoch = 2\n",
    "    batch_size = 2\n",
    "    num_nodes = 1\n",
    "    accumulate_grad_batches = 4\n",
    "    lr = 2e-5\n",
    "    limit_val_batches = 32\n",
    "    val_check_interval = (1/4)\n",
    "    precision=\"16-mixed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module = VideoLlavaModelPLModule(\n",
    "    config={\n",
    "        \"lr\": train_conf.lr\n",
    "    },\n",
    "    processor=processor,\n",
    "    model=model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor=\"val_accuracy\", verbose=False, mode=\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    early_stopping\n",
    "]\n",
    "\n",
    "trainer = Trainer(\n",
    "    **(vars(train_conf)),\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
