{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the dataset a-temporal-upgrade\n",
    "\n",
    "The dataset is coming from activitynet 1.3 captions dataset. The original dataset has been used heavily in the industry.\n",
    "\n",
    "The resulting dataset are divided into 2.\n",
    "\n",
    "- Action ordering : presents a question to order the scrambled actions based on what action come earlier in the video\n",
    "- Moment retrieval : presents a question to retrieve the time of the requested action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import torch \n",
    "import datasets\n",
    "from datasets import load_dataset, DatasetDict, load_from_disk, concatenate_datasets\n",
    "import yt_dlp\n",
    "import os\n",
    "import random\n",
    "from huggingface_hub import HfApi\n",
    "import json\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T19:11:16.105066Z",
     "iopub.status.busy": "2024-11-15T19:11:16.104553Z",
     "iopub.status.idle": "2024-11-15T19:11:16.112065Z",
     "shell.execute_reply": "2024-11-15T19:11:16.110643Z",
     "shell.execute_reply.started": "2024-11-15T19:11:16.105017Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "SEED = 18220053 # seed for any randomization\n",
    "dirs = {\n",
    "    \"videos_download\": \"videos/download\",\n",
    "    \"videos_zip\": \"videos/zip\",\n",
    "    \"saved_processed\": \"saved/processed\",\n",
    "    \"saved\": \"saved\"\n",
    "}\n",
    "VIDEOS_DOWNLOAD_PATH = \"videos/download\"\n",
    "VIDEOS_ZIP_PATH = 'videos/zip'\n",
    "DATASET_REPO = 'jwnt4/a-temporal-upgrade'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T19:11:30.373854Z",
     "iopub.status.busy": "2024-11-15T19:11:30.373326Z",
     "iopub.status.idle": "2024-11-15T19:11:31.734255Z",
     "shell.execute_reply": "2024-11-15T19:11:31.733121Z",
     "shell.execute_reply.started": "2024-11-15T19:11:30.373807Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['video_id', 'video_path', 'duration', 'captions_starts', 'captions_ends', 'en_captions'],\n",
       "        num_rows: 856\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['video_id', 'video_path', 'duration', 'captions_starts', 'captions_ends', 'en_captions'],\n",
       "        num_rows: 484\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['video_id', 'video_path', 'duration', 'captions_starts', 'captions_ends', 'en_captions'],\n",
       "        num_rows: 667\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset using huggingface datasets\n",
    "ds = load_dataset('Leyo/ActivityNet_Captions', trust_remote_code=True)\n",
    "ds = ds.filter(lambda e: e[\"duration\"] >= 20 and e[\"duration\"] <= 50)\n",
    "ds = ds.filter(lambda e: len(e[\"en_captions\"]) >= 3 and len(e[\"en_captions\"]) <= 4) \n",
    "ds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T16:48:32.258226Z",
     "iopub.status.busy": "2024-11-14T16:48:32.257801Z",
     "iopub.status.idle": "2024-11-14T16:48:32.266931Z",
     "shell.execute_reply": "2024-11-14T16:48:32.265932Z",
     "shell.execute_reply.started": "2024-11-14T16:48:32.258187Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'video_id': 'v_ogQozSI5V8U',\n",
       " 'video_path': 'https://www.youtube.com/watch?v=ogQozSI5V8U',\n",
       " 'duration': 36.54999923706055,\n",
       " 'captions_starts': [0.0, 7.489999771118164, 19.3700008392334],\n",
       " 'captions_ends': [7.489999771118164, 18.09000015258789, 36.54999923706055],\n",
       " 'en_captions': ['We see a hallway with a wooden floor.',\n",
       "  ' A dog in socks walks slowly out onto the floor as a lady films him.',\n",
       "  ' The dog turns around and goes back to the other room.']}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the dataset\n",
    "ds['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T16:56:42.294851Z",
     "iopub.status.busy": "2024-11-14T16:56:42.294358Z",
     "iopub.status.idle": "2024-11-14T16:56:42.303685Z",
     "shell.execute_reply": "2024-11-14T16:56:42.302408Z",
     "shell.execute_reply.started": "2024-11-14T16:56:42.294805Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "unavailable_videos = set()\n",
    "\n",
    "class MyLogger:\n",
    "    def __init__(self, suppress_warning):\n",
    "        self.supress_warning = suppress_warning\n",
    "\n",
    "    def debug(self, msg):\n",
    "        if not msg.startswith('[debug] '):\n",
    "            self.info(msg)\n",
    "\n",
    "    def info(self, msg):\n",
    "        pass\n",
    "        \n",
    "    def warning(self, msg):\n",
    "        pass\n",
    "\n",
    "    def error(self, msg):\n",
    "        unavailable_videos.add(msg.split(' ')[2].strip(\"':\"))\n",
    "        if not self.supress_warning:\n",
    "            print(msg.split(' ')[2].strip(\"':\"), \"is unavailable\")\n",
    "\n",
    "\n",
    "def download_videos(urls, suppress_warning = False):\n",
    "    ytdlp_config = {\n",
    "        'extract_flat': 'discard_in_playlist',\n",
    "        'format': '[height>=360][height<=1080]',\n",
    "        'fragment_retries': 10,\n",
    "        'format_sort': ['ext'],\n",
    "        'ignoreerrors': 'only_download',\n",
    "        'postprocessors': [{\n",
    "            'key': 'FFmpegConcat',\n",
    "            'only_multi_video': True,\n",
    "            'when': 'playlist'\n",
    "            }],\n",
    "        'outtmpl': {'default': f'{dirs[\"videos_download\"]}/v_%(id)s.%(ext)s'},\n",
    "        'retries': 10,\n",
    "        'logger' : MyLogger(suppress_warning)\n",
    "    }\n",
    "\n",
    "    vid_downloaded = set(os.listdir(dirs['videos_download']))\n",
    "    print(\"total vid in download dir:\", len(vid_downloaded))\n",
    "    vid_all = set([\"v_\" + u.split(\"=\")[1] + \".mp4\" for u in urls])\n",
    "    print(\"all vid to download:\", len(vid_all))\n",
    "    vid_downloaded = vid_all & vid_downloaded\n",
    "    vid_to_download = vid_all - vid_downloaded\n",
    "\n",
    "    num_download, num_downloaded = len(vid_to_download), len(vid_downloaded)\n",
    "    print(\"vid already downloaded:\", num_downloaded)\n",
    "    print(\"remaining vid to download:\", num_download)\n",
    "\n",
    "    vid_to_download = list(vid_to_download)\n",
    "    vid_to_download = [f'https://www.youtube.com/watch?v={v[2:-4]}' for v in vid_to_download]\n",
    "    with yt_dlp.YoutubeDL(ytdlp_config) as ydl:\n",
    "        ydl.download(vid_to_download)\n",
    "\n",
    "    success = num_download - len(unavailable_videos)\n",
    "    return {\n",
    "        \"success_downloads\": success,\n",
    "        \"fail_downloads\": len(unavailable_videos),\n",
    "        \"total_in_disk\": success + num_downloaded\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T09:24:53.073281Z",
     "iopub.status.busy": "2024-11-13T09:24:53.072358Z",
     "iopub.status.idle": "2024-11-13T09:24:53.079307Z",
     "shell.execute_reply": "2024-11-13T09:24:53.078072Z",
     "shell.execute_reply.started": "2024-11-13T09:24:53.073221Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total vid in dir: 990\n",
      "vid to download: 1548\n",
      "vid already downloaded: 972\n",
      "remaining vid to download: 576\n",
      "srARxP_ocyg is unavailable\n",
      "tbKBKWCh6rs is unavailable\n",
      "rIqITS6qMB0 is unavailable\n",
      "y3Zq6RZZNtc is unavailable\n",
      "bDiwuABU45I is unavailable\n",
      "rtJTJ10ppRc is unavailable\n",
      "jmS3NFo4XCc is unavailable\n",
      "9UpVdljXQ4E is unavailable\n",
      "6wTk8QqWxuo is unavailable\n",
      "1_YFTTzzLrI is unavailable\n",
      "Nh-RdjyfGNA is unavailable\n",
      "GBdj6erXjDM is unavailable\n",
      "54K2F3zAZ0o is unavailable\n",
      "3YiGMRp-7B4 is unavailable\n",
      "tMM166j4YEw is unavailable\n",
      "unLrTQt07kI is unavailable\n",
      "IJER0EpbxW4 is unavailable\n",
      "jFZRNe7xFY8 is unavailable\n",
      "ZlwU7HKcoYs is unavailable\n",
      "Pmt3R5olRP0 is unavailable\n",
      "Wyr2o0lsSTU is unavailable\n",
      "Quj1J31xQFM is unavailable\n",
      "HVKveVRZ-JY is unavailable\n",
      "DJyfOeZc2lI is unavailable\n",
      "N1JcXEim40g is unavailable\n",
      "TomBet77rDc is unavailable\n",
      "zMrUSfQ_mzo is unavailable\n",
      "bHAzuAnnvcU is unavailable\n",
      "fU4EgYmISro is unavailable\n",
      "6czh95dpwAA is unavailable\n",
      "KgfKmcsEMK0 is unavailable\n",
      "RNrxxPOyHo4 is unavailable\n",
      "nSuPseBeQI0 is unavailable\n",
      "701qhmCLPxU is unavailable\n",
      "yweAN9o4QYI is unavailable\n",
      "dL-ybVv7Sgs is unavailable\n",
      "e8MK2naV6E8 is unavailable\n",
      "nTNkGOtp7aQ is unavailable\n",
      "It2fslENHXs is unavailable\n",
      "oJ9BFy1KNlY is unavailable\n",
      "qwJhmfZKdNQ is unavailable\n",
      "VOGF4tBFEuw is unavailable\n",
      "vw065HaGq3I is unavailable\n",
      "L5kxbN9wFAg is unavailable\n",
      "WL4iqWa_1Z0 is unavailable\n",
      "Jz7bt59z6Qg is unavailable\n",
      "Y7VWbYGI0Oc is unavailable\n",
      "9RcCkU6dVD0 is unavailable\n",
      "ay_YB-S4qR0 is unavailable\n",
      "9XjHgUP5QW0 is unavailable\n",
      "L6BxxvCbwpQ is unavailable\n",
      "MYWnPFGvxwQ is unavailable\n",
      "t3zAh4NBVko is unavailable\n",
      "ck05xSh9-ig is unavailable\n",
      "ItFq_6cIByw is unavailable\n",
      "3boxQwSpv-8 is unavailable\n",
      "Cc_DmDsXm6M is unavailable\n",
      "mTtBz5d83C4 is unavailable\n",
      "V2QIntSKqhA is unavailable\n",
      "Flh6nxGkf74 is unavailable\n",
      "l8NepxsCh34 is unavailable\n",
      "Zd22n1caVgM is unavailable\n",
      "OM58jhy61Mc is unavailable\n",
      "hRuHqoXEvsI is unavailable\n",
      "Ad9jrt2bP1o is unavailable\n",
      "VYuQAfG0gKw is unavailable\n",
      "k3yRK68SEDE is unavailable\n",
      "WDbG2_sDHow is unavailable\n",
      "w_PJ9N8CMo8 is unavailable\n",
      "4GrPMa_BE6M is unavailable\n",
      "YL3MvJVk6u0 is unavailable\n",
      "5vd8j0hKIgs is unavailable\n",
      "nTsXn3oHf_8 is unavailable\n",
      "0HrPpZa_xv8 is unavailable\n",
      "TfpCjzGqA7w is unavailable\n",
      "7qBA7XPDsC4 is unavailable\n",
      "jHXqbgeq83Y is unavailable\n",
      "PgoRelvwBUI is unavailable\n",
      "vrMWYB0UuGM is unavailable\n",
      "FIaXCUPjFY0 is unavailable\n",
      "MldEr60j33M is unavailable\n",
      "T0wmRC8Ka2Y is unavailable\n",
      "PEpfA3L4m20 is unavailable\n",
      "peaOnHl5YS8 is unavailable\n",
      "OMGTFZ9csg0 is unavailable\n",
      "GsNyn-6DDJM is unavailable\n",
      "bcOFV26B3jk is unavailable\n",
      "Pu5p7SC3sqg is unavailable\n",
      "zYQ-WdosIwI is unavailable\n",
      "aqQ7-J9kbUE is unavailable\n",
      "eil9mWGJB8E is unavailable\n",
      "CG-7jcSB5_c is unavailable\n",
      "6jxqb8FyWnQ is unavailable\n",
      "Lf3oTCD4d08 is unavailable\n",
      "ox2AGCcE9a0 is unavailable\n",
      "_Rcb5kuhn90 is unavailable\n",
      "4efxBizoKyQ is unavailable\n",
      "oAJlaJ8xcwY is unavailable\n",
      "FsXl6whrCWk is unavailable\n",
      "Vnj0j648Emw is unavailable\n",
      "mdwbRGlPn3A is unavailable\n",
      "woRQ2JxcVHA is unavailable\n",
      "1oaJBEdY6ao is unavailable\n",
      "JN1mex2vCjI is unavailable\n",
      "nuEK3POl9jA is unavailable\n",
      "flneQOXwGxw is unavailable\n",
      "B-KSdR2ct00 is unavailable\n",
      "Yi-0wjSu0E0 is unavailable\n",
      "8GxWehFZVRE is unavailable\n",
      "v_Vg4a8igc0 is unavailable\n",
      "HV_yqsiFoKA is unavailable\n",
      "W5g1IIAOZqs is unavailable\n",
      "U-N92yQynQA is unavailable\n",
      "e5_lP2HgtSE is unavailable\n",
      "Ox51OBhM5Ak is unavailable\n",
      "jCVi9xt3GUY is unavailable\n",
      "jmerKGN0VPs is unavailable\n",
      "TdqEtrrPX_Q is unavailable\n",
      "pc_QYeZG9GA is unavailable\n",
      "fRmHJKlQmmw is unavailable\n",
      "uIOIcv5MhuA is unavailable\n",
      "R3MPcPKQYKE is unavailable\n",
      "lztbD1NRU4M is unavailable\n",
      "G5HZX5i26us is unavailable\n",
      "qcsGJTJstZ4 is unavailable\n",
      "rHMMgJBUWh8 is unavailable\n",
      "ZYPKueJon34 is unavailable\n",
      "4x08i2_AYKo is unavailable\n",
      "wlcU-u-xsH4 is unavailable\n",
      "R6INcHHxlNs is unavailable\n",
      "YYmx8EHIjAE is unavailable\n",
      "LAU_pVRs9RQ is unavailable\n",
      "q8mReXud6fE is unavailable\n",
      "DrQgYA5_8VA is unavailable\n",
      "FNAt8Pew0HA is unavailable\n",
      "8Q-P5KEvXN0 is unavailable\n",
      "6TgVNz6PATk is unavailable\n",
      "udpVICVTQrQ is unavailable\n",
      "ShT4biEuQDo is unavailable\n",
      "f-r9g_-5huM is unavailable\n",
      "-DTxZliHCTE is unavailable\n",
      "yj7YkvTZ4zw is unavailable\n",
      "sLtQvJXnrOE is unavailable\n",
      "PL1JmxPH7y4 is unavailable\n",
      "Fe-DUewB8ok is unavailable\n",
      "_roK9m9UOvM is unavailable\n",
      "Ox16PeB954Q is unavailable\n",
      "14AnvDNV5BI is unavailable\n",
      "SFfB6qvT5FI is unavailable\n",
      "U89hsv1dzuQ is unavailable\n",
      "cw0HRDIQ10I is unavailable\n",
      "WaFDgdqY1DM is unavailable\n",
      "2iW1Eq9SDW4 is unavailable\n",
      "jherly5DNjg is unavailable\n",
      "G12fEYNjIR0 is unavailable\n",
      "D0pVkTEYQg8 is unavailable\n",
      "QsfIM28uvHM is unavailable\n",
      "F559bkkKSp8 is unavailable\n",
      "RblRzlmSFak is unavailable\n",
      "zzci2xZ011A is unavailable\n",
      "3joaQzU05MY is unavailable\n",
      "MVUqd8iVUEk is unavailable\n",
      "ZpyCrs-q-so is unavailable\n",
      "Hg1tl2hFWGc is unavailable\n",
      "gN8F0o1baAo is unavailable\n",
      "4l8r_wBuJ6Y is unavailable\n",
      "O1XzCrHZm34 is unavailable\n",
      "o-BGGr-DU5g is unavailable\n",
      "8LB2tdMOZ6g is unavailable\n",
      "F1-PnXa9SwQ is unavailable\n",
      "OD4MrhX85-M is unavailable\n",
      "lk2niPrG3y8 is unavailable\n",
      "StTr5O_wGXI is unavailable\n",
      "maHLwXvNN3w is unavailable\n",
      "6FPoGGaox4g is unavailable\n",
      "QOMvNgo6CQ4 is unavailable\n",
      "Ay6oxBYCSnU is unavailable\n",
      "UCmycSotoy4 is unavailable\n",
      "Taw5ILRt9hI is unavailable\n",
      "Xv2-EY_zKNM is unavailable\n",
      "dE1NAofn3ks is unavailable\n",
      "Zk4EvGw7cAw is unavailable\n",
      "xICaX0kCCF4 is unavailable\n",
      "Q5qIsUsM_-A is unavailable\n",
      "r97vYbzloD8 is unavailable\n",
      "9uHffl5yny4 is unavailable\n",
      "Ly21QMQ4kGA is unavailable\n",
      "b-p57jzkrQI is unavailable\n",
      "8B3qhnSB7U8 is unavailable\n",
      "hZ0jI9U5Nws is unavailable\n",
      "ZkIGGQ9iOSA is unavailable\n",
      "9AqHhUuE9bE is unavailable\n",
      "nE0_PaRBXeA is unavailable\n",
      "rulzKikXMHo is unavailable\n",
      "K0e_DdvGP54 is unavailable\n",
      "K757XUwinrc is unavailable\n",
      "8kkKxLpiMus is unavailable\n",
      "Jd5tpIdMGh8 is unavailable\n",
      "dx5VK79QWlg is unavailable\n",
      "nEcOF04KK0g is unavailable\n",
      "E3UJv-NC1E8 is unavailable\n",
      "AGDsfpZQBIs is unavailable\n",
      "w2HnFjJei7k is unavailable\n",
      "B_-jPPr2RLA is unavailable\n",
      "WHYEBsWp5qY is unavailable\n",
      "FqlXey9KFZA is unavailable\n",
      "Ir_Ul8FaXs4 is unavailable\n",
      "v5i_NAlJX1Y is unavailable\n",
      "aFVthcfDK9Q is unavailable\n",
      "8e80cJTrJDs is unavailable\n",
      "lQWij22wbNU is unavailable\n",
      "VFOjLDa5VtA is unavailable\n",
      "zKHMKAOb1iw is unavailable\n",
      "W2wyahjyTFc is unavailable\n",
      "7knqgoHxuGE is unavailable\n",
      "1y9s_l_DIEk is unavailable\n",
      "PziLzNjG2bI is unavailable\n",
      "IhWxuvzIHkc is unavailable\n",
      "BCzsVKHrN5Y is unavailable\n",
      "hRk-3fep5WQ is unavailable\n",
      "uZpVDAd7da8 is unavailable\n",
      "ByF8Pg3xXNA is unavailable\n",
      "3nX5ZwzHftM is unavailable\n",
      "7qjiHcYuq2Y is unavailable\n",
      "fKFcbNM89MA is unavailable\n",
      "GPWXB0wy5dY is unavailable\n",
      "MWn4qozlaMs is unavailable\n",
      "sY8TfKQHe5w is unavailable\n",
      "kNUpypAppjk is unavailable\n",
      "e6r-A-LAe2E is unavailable\n",
      "XuwqWdp-u2M is unavailable\n",
      "f00gW6PbWDE is unavailable\n",
      "l5QQ1vVctOo is unavailable\n",
      "7hEUl8lziZs is unavailable\n",
      "iGOGz6M_zcE is unavailable\n",
      "5T_P4x0q0VM is unavailable\n",
      "7D5ItfgJFVw is unavailable\n",
      "WjX-xi2Ocbo is unavailable\n",
      "tI87cD7sv-Y is unavailable\n",
      "bZ4r3Y_qceE is unavailable\n",
      "Pfc7KbwqdYk is unavailable\n",
      "ovq0Fqbxt1c is unavailable\n",
      "o8wdvkauJQQ is unavailable\n",
      "CG-itBlFOzc is unavailable\n",
      "NO5J7RjTTTo is unavailable\n",
      "t0XM3ivJYUo is unavailable\n",
      "yJezvcXU4YE is unavailable\n",
      "sFQ7AaId8zg is unavailable\n",
      "fHXgxSFDmJc is unavailable\n",
      "lkC_md7KKq0 is unavailable\n",
      "Q6XjxUlbP2M is unavailable\n",
      "gwbRqyRZguM is unavailable\n",
      "QQNW2ha8WIs is unavailable\n",
      "B39pJK4FU1o is unavailable\n",
      "o_Davs3OrOw is unavailable\n",
      "KCxa27MM7Cg is unavailable\n",
      "8b3ZBE0n3V8 is unavailable\n",
      "kH50-giCeDM is unavailable\n",
      "dJgea9sOlBY is unavailable\n",
      "oYH-XLQzMxU is unavailable\n",
      "rHWOESWciSc is unavailable\n",
      "cLTDcBhgRw8 is unavailable\n",
      "t0y6dkIwEvc is unavailable\n",
      "p4YTDxTASBI is unavailable\n",
      "JfifgnVgJEU is unavailable\n",
      "J2gGPC98yec is unavailable\n",
      "MOOeHWuuxlo is unavailable\n",
      "ZGsYV0KDB-4 is unavailable\n",
      "LkUnT9fMIXc is unavailable\n",
      "W2Wjbhsuacw is unavailable\n",
      "z9MMLl1isUk is unavailable\n",
      "ZCZoL2b6euQ is unavailable\n",
      "nXD-q814KjI is unavailable\n",
      "8iHklV25LaE is unavailable\n",
      "hj7rkE0fPsE is unavailable\n",
      "Xm23RMCpDd8 is unavailable\n",
      "uJ_QCxMDfag is unavailable\n",
      "wIK83guBfM0 is unavailable\n",
      "2ehPAKS6Gpo is unavailable\n",
      "cWBbuw_DA2c is unavailable\n",
      "aTl4KzTuJoU is unavailable\n",
      "XzYtm5WdAE8 is unavailable\n",
      "jDfTrTtPs5s is unavailable\n",
      "H0puoztHMY8 is unavailable\n",
      "BtrGC6PUPJk is unavailable\n",
      "mfJj5gBQg-4 is unavailable\n",
      "MjljlkQaHh4 is unavailable\n",
      "uG_G4g6ixms is unavailable\n",
      "Scv939uhNCc is unavailable\n",
      "_Ga4HoMl6yM is unavailable\n",
      "ndGz8-hHSt4 is unavailable\n",
      "LxntXVcMxtc is unavailable\n",
      "Snq0l-gKpWo is unavailable\n",
      "YPFk9ftkzl4 is unavailable\n",
      "kYrztBFfaZ8 is unavailable\n",
      "HsfrvjsaIDU is unavailable\n",
      "cz2ESqP3PDk is unavailable\n",
      "z5bc9KKiAGI is unavailable\n",
      "Jth2Zlpr1gQ is unavailable\n",
      "2VTEseqA5SA is unavailable\n",
      "hlFJj2dT3sU is unavailable\n",
      "rV9RzL8o7tk is unavailable\n",
      "ZT_gv2W65Zc is unavailable\n",
      "3Z4b34lBnyU is unavailable\n",
      "-oExUcmbTEE is unavailable\n",
      "eMI2x3HFozQ is unavailable\n",
      "GG_Bi89pNlg is unavailable\n",
      "G6ayznrS0tY is unavailable\n",
      "JkcoGLKl_0A is unavailable\n",
      "sZRUTtoxY_s is unavailable\n",
      "snvSHNYvRks is unavailable\n",
      "M-bUoaIqtDk is unavailable\n",
      "3W92sMbvoaE is unavailable\n",
      "HMIv7qpDmH0 is unavailable\n",
      "HatKNbfqL-k is unavailable\n",
      "tilmCzSf1oc is unavailable\n",
      "7QvvqWJRwNo is unavailable\n",
      "uBmUiouilQY is unavailable\n",
      "RLMvrl_vaqc is unavailable\n",
      "owflykBauOA is unavailable\n",
      "Gpjx38IDVT0 is unavailable\n",
      "qwxmpiaT-kk is unavailable\n",
      "h4m7bYDVLAc is unavailable\n",
      "gwpQuO5DPOA is unavailable\n",
      "r4bI22hGTg4 is unavailable\n",
      "q2VG0zzPJMw is unavailable\n",
      "NIY1f2KcEe0 is unavailable\n",
      "ac1DjqY4xHs is unavailable\n",
      "tV_1whw_S4g is unavailable\n",
      "J1fcLhB-Slg is unavailable\n",
      "4mBVik8dq_w is unavailable\n",
      "-lER_VO9LUo is unavailable\n",
      "t6trrsdhMEc is unavailable\n",
      "Jz2xJx1ICCM is unavailable\n",
      "yqkjHCPsdF0 is unavailable\n",
      "LLLuBjEVHI8 is unavailable\n",
      "43OU5XCzLzo is unavailable\n",
      "yvzlX5St_Ok is unavailable\n",
      "KgGQ6dHKl8U is unavailable\n",
      "8DZj0ggPr74 is unavailable\n",
      "hhHiBeL08-M is unavailable\n",
      "aJsDVKt5Igs is unavailable\n",
      "EW3zRMVjkoU is unavailable\n",
      "P3kWD8Oocio is unavailable\n",
      "fkmYC91-biI is unavailable\n",
      "Tc0nHNkf0KM is unavailable\n",
      "_Z71mu4aQy4 is unavailable\n",
      "u3uYs6SZFKo is unavailable\n",
      "zJquKzopJuI is unavailable\n",
      "KBMvitQaXzE is unavailable\n",
      "Qzewn-dGdOI is unavailable\n",
      "xXGc5_0_2QI is unavailable\n",
      "x0tjkH_zfXA is unavailable\n",
      "AS0hqTk_mIs is unavailable\n",
      "TcxOTZ4xnQ4 is unavailable\n",
      "zaPxNw11llc is unavailable\n",
      "6okx-34bDEg is unavailable\n",
      "IcDadC2tw5c is unavailable\n",
      "4p6OjaHHSDs is unavailable\n",
      "cFCN9QE1M0c is unavailable\n",
      "YrS64TBX798 is unavailable\n",
      "s3JuGKwna6o is unavailable\n",
      "-zfOvigQLdA is unavailable\n",
      "3RTmWrwgKek is unavailable\n",
      "Launtf-qjDM is unavailable\n",
      "Bule85koN3o is unavailable\n",
      "fBbjlXgtd50 is unavailable\n",
      "SHT08nPhIb4 is unavailable\n",
      "jnOqi_9KJiE is unavailable\n",
      "CJKwvmOuhJk is unavailable\n",
      "CQocaUwWcQI is unavailable\n",
      "cRDXBF2RcYI is unavailable\n",
      "Uv_6SJlvCl0 is unavailable\n",
      "7mmXZeOJT8w is unavailable\n",
      "VToS7Ma-V4g is unavailable\n",
      "J8WxSDLZwu0 is unavailable\n",
      "xrbKvttgcMA is unavailable\n",
      "yQ2AirKmnTM is unavailable\n",
      "1VwNfMlb4JU is unavailable\n",
      "JJ811udnROI is unavailable\n",
      "CF6Q5ojrAJo is unavailable\n",
      "OXTQsO5abO4 is unavailable\n",
      "UgXPt2LydrY is unavailable\n",
      "iNMxIXAcHYU is unavailable\n",
      "19LxLS1_Yn0 is unavailable\n",
      "E6LJROCxQPA is unavailable\n",
      "G00TjQ7JJ8Y is unavailable\n",
      "zQFC5vNZ_Qs is unavailable\n",
      "Rc_pWU_3WLk is unavailable\n",
      "w0d32MVTY9Q is unavailable\n",
      "rvkVdD2u_yA is unavailable\n",
      "iMwLP3y0VcQ is unavailable\n",
      "s0-xTG38cPw is unavailable\n",
      "a1ltYmbbBYI is unavailable\n",
      "OuVncktxGw0 is unavailable\n",
      "nhky9RGjzwc is unavailable\n",
      "hW25ecQ1GUc is unavailable\n",
      "eC90hOqQ0yk is unavailable\n",
      "z-_snl6eaPE is unavailable\n",
      "UKo5IFacUyE is unavailable\n",
      "ukPz_13Agis is unavailable\n",
      "sfPGQnxbJ3U is unavailable\n",
      "8TqqLqBb3sk is unavailable\n",
      "2eep4G5Tgho is unavailable\n",
      "_CMIO5R_OGA is unavailable\n",
      "nLdRqOTb0Ik is unavailable\n",
      "Ih8bPM3p0rE is unavailable\n",
      "UPwDuuYlLfQ is unavailable\n",
      "fxEcsM0EaA4 is unavailable\n",
      "7LhKz7863kg is unavailable\n",
      "xsBFnpdLWkU is unavailable\n",
      "5aTek77vxBA is unavailable\n",
      "PFYk8lhE7-0 is unavailable\n",
      "dFsFL_WJasg is unavailable\n",
      "CneLYCPg7Es is unavailable\n",
      "WWip1_lFvGg is unavailable\n",
      "lq-8Y-YLcNI is unavailable\n",
      "idACyRv-Sqk is unavailable\n",
      "ZbS9R9faBQk is unavailable\n",
      "JZN0L8pp5hY is unavailable\n",
      "JK8pYBpatAY is unavailable\n",
      "ORI5ZNZARw8 is unavailable\n",
      "m9CbLJdYqHw is unavailable\n",
      "0T7yANM5I5Y is unavailable\n",
      "S2V2TgLAMKg is unavailable\n",
      "lpeyMIH1YqA is unavailable\n",
      "ILwwD00q1ZY is unavailable\n",
      "a2Xwx37YbhE is unavailable\n",
      "xMEwcb1P6dQ is unavailable\n",
      "5oy5Yi6fzJU is unavailable\n",
      "qnDHR-jYWf0 is unavailable\n",
      "3_hJrb_aDWU is unavailable\n",
      "JqFFXs0RAnI is unavailable\n",
      "QT2l100KJe0 is unavailable\n",
      "ibIRzsC9NjY is unavailable\n",
      "1hB5jVAhSDE is unavailable\n",
      "bkRQgwbP0WM is unavailable\n",
      "Qm6HmQv5uOo is unavailable\n",
      "-DGsqL65o4k is unavailable\n",
      "jXIKHEsmVl4 is unavailable\n",
      "aEyTdUOp-qs is unavailable\n",
      "juLxWt_3omw is unavailable\n",
      "Zts8FynhoJs is unavailable\n",
      "pHZogKGkc9o is unavailable\n",
      "lh8ths6sKAE is unavailable\n",
      "ZW46Rcuhqac is unavailable\n",
      "24vWSTx6N5M is unavailable\n",
      "tzwIHzuzG9c is unavailable\n",
      "OUIS4bnEhU0 is unavailable\n",
      "jcX2QAiqP9U is unavailable\n",
      "ZQU0p5OKC04 is unavailable\n",
      "Lmne5ZF0McI is unavailable\n",
      "KkBMOQOGTdk is unavailable\n",
      "oOnKQgQZOZ0 is unavailable\n",
      "f4s1ngeK5P4 is unavailable\n",
      "sUrqd6Qn8Qw is unavailable\n",
      "jfIcmcE320Q is unavailable\n",
      "M_LSDRzVN38 is unavailable\n",
      "vvoqG7UQsdc is unavailable\n",
      "1Xav7gMRCOQ is unavailable\n",
      "qcYRPEEitZU is unavailable\n",
      "OwSdSL_4sxU is unavailable\n",
      "1dvrNvxw43Q is unavailable\n",
      "IDVWoE02zjM is unavailable\n",
      "v9APkG4il4Q is unavailable\n",
      "7VvcQNSAd24 is unavailable\n",
      "Bg_CMSihJl0 is unavailable\n",
      "QMFtjdg6d2A is unavailable\n",
      "D2Trvi7Im_s is unavailable\n",
      "lGAK_3Jp2I8 is unavailable\n",
      "juKQ_gU42EM is unavailable\n",
      "KePjkCySBCs is unavailable\n",
      "F2Igw6lvqwk is unavailable\n",
      "1Y1pKGFm-pQ is unavailable\n",
      "G0vkQmcalvk is unavailable\n",
      "c5Io6wg8D60 is unavailable\n",
      "HguqDEvSN68 is unavailable\n",
      "4qZckue0QU4 is unavailable\n",
      "WBRQ4vHBFMY is unavailable\n",
      "Ttx3kt2fW1o is unavailable\n",
      "aBmKEmXVCqM is unavailable\n",
      "n2wq_9TeNYM is unavailable\n",
      "0vQs3ztG7vg is unavailable\n",
      "NpsOCOnQS6c is unavailable\n",
      "G98dfNXqu4Q is unavailable\n",
      "ZhPL4xb8JD0 is unavailable\n",
      "wZJeEV6sZXE is unavailable\n",
      "OuEQLjwBIPI is unavailable\n",
      "4R37E4Kevs4 is unavailable\n",
      "LZleSe6Kovg is unavailable\n",
      "GcEutQTeAnA is unavailable\n",
      "uAKyRSEaY1s is unavailable\n",
      "A7PBp9PDW80 is unavailable\n",
      "ze4292jVUcQ is unavailable\n",
      "twrPZghmNtA is unavailable\n",
      "QosVN26lb1g is unavailable\n",
      "JeSxkw4ed-I is unavailable\n",
      "AonniE_CsPY is unavailable\n",
      "f5Ja983oTMw is unavailable\n",
      "kSdWy3subNE is unavailable\n",
      "g0B_4IlLn3g is unavailable\n",
      "yaK-giAk4e8 is unavailable\n",
      "JYh2Oejg_lQ is unavailable\n",
      "uPqp30C6MDE is unavailable\n",
      "6nMQRUhOcwM is unavailable\n",
      "-MFzpFMdWZs is unavailable\n",
      "PAGuZzrzSO4 is unavailable\n",
      "o5j6N8O6HS4 is unavailable\n",
      "Db6sq4DjW7E is unavailable\n",
      "qPZBSTNEl78 is unavailable\n",
      "EmM2yXiiz5c is unavailable\n",
      "c9bvuUO9Q0Q is unavailable\n",
      "qr5vqi5tTL8 is unavailable\n",
      "dI1GZfJ-A0E is unavailable\n",
      "Y9xPzIiy6mI is unavailable\n",
      "WJ4tCIdAgVo is unavailable\n",
      "lG5d8bCHLM4 is unavailable\n",
      "uaIu2yDmhNU is unavailable\n",
      "apPeChgjzs4 is unavailable\n",
      "UOL8oxziVwU is unavailable\n",
      "i4SNM6xSLI8 is unavailable\n",
      "Et8xkGzQOTA is unavailable\n",
      "CXbVcrVgNzQ is unavailable\n",
      "cICxG-28hK0 is unavailable\n",
      "xfNYfCAlkM4 is unavailable\n",
      "L36MIRUpcrI is unavailable\n",
      "RHb_nF11Scc is unavailable\n",
      "TLJdzU44My4 is unavailable\n",
      "1PpVSeE2BJ8 is unavailable\n",
      "x4DuEusRR7Q is unavailable\n",
      "dJAZplo9ke0 is unavailable\n",
      "oS7Twj3Pou0 is unavailable\n",
      "hANXaoStVR0 is unavailable\n",
      "ARkMGkD2RDs is unavailable\n",
      "SMpmoqIk3Ts is unavailable\n",
      "knnQ99kDt8w is unavailable\n",
      "dfgwl-_IMic is unavailable\n",
      "ssies4ErWus is unavailable\n",
      "zfU85oBVpfA is unavailable\n",
      "t1urvYx1X_w is unavailable\n",
      "hYj38k-VOFM is unavailable\n",
      "-X7fBYN5fBc is unavailable\n",
      "1cWWCiNIYnc is unavailable\n",
      "v1Vmf5s42No is unavailable\n",
      "zH-fOiPLLxA is unavailable\n",
      "HmqRZ4HPu1U is unavailable\n",
      "FQkvwPpDomw is unavailable\n",
      "m6H1tLAkyjQ is unavailable\n",
      "kmWf36zfL7o is unavailable\n",
      "F9Wv_Lxe_QM is unavailable\n",
      "iH659QSrcDc is unavailable\n",
      "XbN3TvLEm2A is unavailable\n",
      "p771liKjycc is unavailable\n",
      "5c1jHhHUwPI is unavailable\n",
      "G71xFbDSSno is unavailable\n",
      "r-BJYixThME is unavailable\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'success_downloads': 20, 'fail_downloads': 556, 'total_in_disk': 992}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_videos(ds['train']['video_path'] + ds['test']['video_path'] + ds['validation']['video_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['video_id', 'video_path', 'duration', 'captions_starts', 'captions_ends', 'en_captions'],\n",
       "        num_rows: 521\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['video_id', 'video_path', 'duration', 'captions_starts', 'captions_ends', 'en_captions'],\n",
       "        num_rows: 336\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['video_id', 'video_path', 'duration', 'captions_starts', 'captions_ends', 'en_captions'],\n",
       "        num_rows: 455\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter only the available videos\n",
    "ds = ds.filter(lambda e: os.path.isfile(f\"{dirs['videos_download']}/{e['video_id']}.mp4\"))\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 135)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure the test and validation dataset does not contain any videos from splits other then itself\n",
    "\n",
    "train_val = set(ds['train']['video_id'] + ds['validation']['video_id'])\n",
    "train_test = set(ds['train']['video_id'] + ds['test']['video_id'])\n",
    "val_set = []\n",
    "val_to_train = []\n",
    "for vid_id in range(len(ds['validation'])):\n",
    "    if ds['validation'][vid_id]['video_id'] not in train_test:\n",
    "        val_set.append(vid_id)\n",
    "    else:\n",
    "        val_to_train.append(vid_id)\n",
    "\n",
    "test_set = []\n",
    "test_to_train = []\n",
    "for vid_id in range(len(ds['test'])):\n",
    "    if ds['test'][vid_id]['video_id'] not in train_val:\n",
    "        test_set.append(vid_id)\n",
    "    else:\n",
    "        test_to_train.append(vid_id)\n",
    "\n",
    "len(val_set), len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['video_id', 'video_path', 'duration', 'captions_starts', 'captions_ends', 'en_captions'],\n",
       "        num_rows: 1192\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['video_id', 'video_path', 'duration', 'captions_starts', 'captions_ends', 'en_captions'],\n",
       "        num_rows: 70\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['video_id', 'video_path', 'duration', 'captions_starts', 'captions_ends', 'en_captions'],\n",
       "        num_rows: 50\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = ds['test'].select(test_set[:70])\n",
    "val_dataset = concatenate_datasets([\n",
    "    ds['validation'].select(val_set),\n",
    "    ds['test'].select(test_set[70:104]) # move some test set to val set\n",
    "])\n",
    "train_dataset = concatenate_datasets([\n",
    "    ds['train'],\n",
    "    ds['validation'].select(val_to_train),\n",
    "    ds['test'].select(test_to_train),\n",
    "    ds['test'].select(test_set[104:]) # remaining test set to train\n",
    "])\n",
    "ds_processed = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"test\": test_dataset,\n",
    "    \"validation\": val_dataset\n",
    "})\n",
    "ds_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_processed = ds_processed.shuffle(seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "826ad86efb6d44d9b76115f88069f9ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1192 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8b50f8b484e41d19fafaadd219ca655",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/70 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a323b4a0f2d34e0aa9212611d3915b22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_processed.save_to_disk(\"dataset/saved/processed2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_processed = load_from_disk(\"dataset/saved/processed2\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action Ordering Dataset\n",
    "\n",
    "We use half of the first training set for action ordering and half for moment retrieval.\n",
    "\n",
    "We use the same test and validation set for the two dataset since they never contribut to the gradients.\n",
    "\n",
    "It means that the model does not learn from the test / validation set.\n",
    "\n",
    "It also means that we now have more validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['video_id', 'video_path', 'duration', 'captions_starts', 'captions_ends', 'en_captions'],\n",
       "        num_rows: 596\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['video_id', 'video_path', 'duration', 'captions_starts', 'captions_ends', 'en_captions'],\n",
       "        num_rows: 50\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['video_id', 'video_path', 'duration', 'captions_starts', 'captions_ends', 'en_captions'],\n",
       "        num_rows: 70\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ao = DatasetDict({\n",
    "    \"train\": ds_processed['train'].select(range(1192//2)),\n",
    "    \"validation\": ds_processed['validation'],\n",
    "    \"test\": ds_processed['test']\n",
    "})\n",
    "ao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dee35515104446ecaff69fef5063a022",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/596 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e1d7f91a65f457ea944f6e81e26108f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f1a95b7851345cab1585002f5c84d37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/70 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'num_max_caption_len': 618}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ao_maxes = {\n",
    "    \"num_max_caption_len\": 0,\n",
    "}\n",
    "def find_longest(e):\n",
    "    if len(''.join(e['en_captions'])) > ao_maxes['num_max_caption_len']:\n",
    "        ao_maxes['num_max_caption_len'] = len(''.join(e['en_captions']))\n",
    "    return True\n",
    "ao.filter(find_longest)\n",
    "ao_maxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The robust prompt has more instruction, detail, and example but is more lengthy than the normal prompt\n",
    "\n",
    "The wording can be choosen later, but 'actions' is synonymous and related closely to 'scenes' and 'moments' but is more commonly used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_prompt = \"\"\"Your task is to determine the correct chronological order of the scrambled actions from the video.\\\n",
    " Provide your answer as a comma-separated letters, where each letter ({letters}) represents an action in the video.\\\n",
    " The order of letters must match the timeline of actions, with earlier letters representing earlier actions. Do not provide any other explanation in your response.\n",
    "Here is an example: The action E is \"a robber meets a cop\" and the action F is \"the robber runs across the street\".\\\n",
    " If in the video the robber runs after meeting the cop, then action E happens before action F. Therefore, your answer should be \"E, F\" (this is an example).\n",
    "Here is the video context: {context}\n",
    "Here is the question: What is the correct chronological order of the scrambled actions based on when they happen in the video?\n",
    "Here are the scrambled actions:\n",
    "{actions}\"\"\"\n",
    "\n",
    "normal_prompt = \"\"\"The actions below are from the video but the ordering of them is scrambled. Arrange them in the correct chronological order based on when they happen.\n",
    "The video context is: {context}\n",
    "The scrambled actions are:\n",
    "{actions}\n",
    "The answer format: provide your answer as a comma-separated letters, for example: \"A, B\". Each letter represent an action, and earlier actions should appear earlier in your answer.\\\n",
    " Ensure that your answer includes all actions ({letters}) and matches the number of actions provided.\n",
    "Question: What is the correct chronological order of the scrambled actions based on when they happen in the video?\"\"\"\n",
    "\n",
    "def transform_action_ordering(example):\n",
    "    capt = example['en_captions']\n",
    "    ans_key = list(range(1, len(capt)))\n",
    "    ans_val = list(range(1, len(capt)))\n",
    "    random.shuffle(ans_key) # scramble \n",
    "    ans = {ans_key[i]:ans_val[i] for i in range(len(capt) - 1)} # map answers\n",
    "    ans_key = [chr(i + 64) for i in ans_key] # make answer\n",
    "    actions = '\\n'.join([f'{chr(i + 64)}. {capt[ans[i]].strip()}' for i in sorted(list(ans.keys()))]) # assemble actions\n",
    "    letters = 'A and B' if len(capt) == 3 else 'A, B, and C'\n",
    "    context = capt[0].strip(\" \")\n",
    "    context = context[0].upper() + context[1:] \n",
    "    question_normal = normal_prompt.format(context=context, letters=letters, actions=actions)\n",
    "    question_robust = robust_prompt.format(context=context, letters=letters, actions=actions)\n",
    "\n",
    "    ratio_option = len(capt) / 3 \n",
    "    ratio_token = len(''.join(example['en_captions'])) / ao_maxes['num_max_caption_len']\n",
    "    ratio_duration = example['duration'] / 50\n",
    "    complexity = (ratio_option * 1.5 + ratio_duration + ratio_token *1.5 ) / 5\n",
    "\n",
    "    return {\n",
    "        \"video_id\": example['video_id'],\n",
    "        \"question_normal\" : question_normal,\n",
    "        \"question_robust\": question_robust,\n",
    "        \"answer\": ans_key,\n",
    "        \"complexity\": complexity # adds an option for the model to learn easier questions first\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T09:35:46.759517Z",
     "iopub.status.busy": "2024-11-13T09:35:46.758605Z",
     "iopub.status.idle": "2024-11-13T09:35:46.768681Z",
     "shell.execute_reply": "2024-11-13T09:35:46.767381Z",
     "shell.execute_reply.started": "2024-11-13T09:35:46.759473Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'video_id': 'v_VlLq4bAHCXI',\n",
       " 'video_path': 'https://www.youtube.com/watch?v=VlLq4bAHCXI',\n",
       " 'duration': 44.560001373291016,\n",
       " 'captions_starts': [0.0, 7.800000190734863, 35.650001525878906],\n",
       " 'captions_ends': [7.800000190734863, 35.650001525878906, 44.560001373291016],\n",
       " 'en_captions': ['These people are outside talking and  walking along the sidewalk.',\n",
       "  ' There are also people running in their short outfits.',\n",
       "  \" There's also people watching them as they run in the middle of the street.\"]}"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Before\n",
    "ao['train'][15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T09:37:35.817763Z",
     "iopub.status.busy": "2024-11-13T09:37:35.816629Z",
     "iopub.status.idle": "2024-11-13T09:37:35.826206Z",
     "shell.execute_reply": "2024-11-13T09:37:35.824839Z",
     "shell.execute_reply.started": "2024-11-13T09:37:35.817715Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video_id:\n",
      "v_VlLq4bAHCXI\n",
      "\n",
      "question_normal:\n",
      "The actions below are from the video but the ordering of them is scrambled. Arrange them in the correct chronological order based on when they happen.\n",
      "The video context is: These people are outside talking and  walking along the sidewalk.\n",
      "The scrambled actions are:\n",
      "A. There are also people running in their short outfits.\n",
      "B. There's also people watching them as they run in the middle of the street.\n",
      "The answer format: provide your answer as a comma-separated letters, for example: \"A, B\". Each letter represent an action, and earlier actions should appear earlier in your answer. Ensure that your answer includes all actions (A and B) and matches the number of actions provided.\n",
      "Question: What is the correct chronological order of the scrambled actions based on when they happen in the video?\n",
      "\n",
      "question_robust:\n",
      "Your task is to determine the correct chronological order of the scrambled actions from the video. Provide your answer as a comma-separated letters, where each letter (A and B) represents an action in the video. The order of letters must match the timeline of actions, with earlier letters representing earlier actions. Do not provide any other explanation in your response.\n",
      "Here is an example: The action E is \"a robber meets a cop\" and the action F is \"the robber runs across the street\". If in the video the robber runs after meeting the cop, then action E happens before action F. Therefore, your answer should be \"E, F\" (this is an example).\n",
      "Here is the video context: These people are outside talking and  walking along the sidewalk.\n",
      "Here is the question: What is the correct chronological order of the scrambled actions based on when they happen in the video?\n",
      "Here are the scrambled actions:\n",
      "A. There are also people running in their short outfits.\n",
      "B. There's also people watching them as they run in the middle of the street.\n",
      "\n",
      "answer:\n",
      "['A', 'B']\n",
      "\n",
      "complexity:\n",
      "0.5724147627747175\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# after\n",
    "after = transform_action_ordering(ao['train'][15])\n",
    "for k,v in after.items():\n",
    "    print(f\"{k}:\\n{v}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T09:39:50.571841Z",
     "iopub.status.busy": "2024-11-13T09:39:50.571322Z",
     "iopub.status.idle": "2024-11-13T09:39:50.800179Z",
     "shell.execute_reply": "2024-11-13T09:39:50.799133Z",
     "shell.execute_reply.started": "2024-11-13T09:39:50.571800Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5829ac94d414ee694fd525c9aabf38d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/596 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2e154aba554426fbedff7124fe31c26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d24c134ba2949238001551c0718f3bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/70 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['video_id', 'duration', 'captions_starts', 'captions_ends', 'question_normal', 'question_robust', 'answer', 'complexity'],\n",
       "        num_rows: 596\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['video_id', 'duration', 'captions_starts', 'captions_ends', 'question_normal', 'question_robust', 'answer', 'complexity'],\n",
       "        num_rows: 50\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['video_id', 'duration', 'captions_starts', 'captions_ends', 'question_normal', 'question_robust', 'answer', 'complexity'],\n",
       "        num_rows: 70\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ao_tf = ao.map(\n",
    "    function=transform_action_ordering,\n",
    "    remove_columns=['video_path', 'en_captions']\n",
    ")\n",
    "ao_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T09:40:40.144157Z",
     "iopub.status.busy": "2024-11-13T09:40:40.143162Z",
     "iopub.status.idle": "2024-11-13T09:40:40.149921Z",
     "shell.execute_reply": "2024-11-13T09:40:40.148867Z",
     "shell.execute_reply.started": "2024-11-13T09:40:40.144112Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video_id:\n",
      "v_tMTvOaUYNeg\n",
      "\n",
      "duration:\n",
      "23.959999084472656\n",
      "\n",
      "captions_starts:\n",
      "[0.23999999463558197, 3.4700000286102295, 9.350000381469727]\n",
      "\n",
      "captions_ends:\n",
      "[23.360000610351562, 8.630000114440918, 23.719999313354492]\n",
      "\n",
      "question_normal:\n",
      "The actions below are from the video but the ordering of them is scrambled. Arrange them in the correct chronological order based on when they happen.\n",
      "The video context is: One adult and two small children work together to put leaves on a yard into a paper bag.\n",
      "The scrambled actions are:\n",
      "A. The boy puts leaves in the brown bag and the girl picks the leaves up.\n",
      "B. One adult stands with two children on a lawn amidst many leaves with a black truck in the background.\n",
      "The answer format: provide your answer as a comma-separated letters, for example: \"A, B\". Each letter represent an action, and earlier actions should appear earlier in your answer. Ensure that your answer includes all actions (A and B) and matches the number of actions provided.\n",
      "Question: What is the correct chronological order of the scrambled actions based on when they happen in the video?\n",
      "\n",
      "question_robust:\n",
      "Your task is to determine the correct chronological order of the scrambled actions from the video. Provide your answer as a comma-separated letters, where each letter (A and B) represents an action in the video. The order of letters must match the timeline of actions, with earlier letters representing earlier actions. Do not provide any other explanation in your response.\n",
      "Here is an example: The action E is \"a robber meets a cop\" and the action F is \"the robber runs across the street\". If in the video the robber runs after meeting the cop, then action E happens before action F. Therefore, your answer should be \"E, F\" (this is an example).\n",
      "Here is the video context: One adult and two small children work together to put leaves on a yard into a paper bag.\n",
      "Here is the question: What is the correct chronological order of the scrambled actions based on when they happen in the video?\n",
      "Here are the scrambled actions:\n",
      "A. The boy puts leaves in the brown bag and the girl picks the leaves up.\n",
      "B. One adult stands with two children on a lawn amidst many leaves with a black truck in the background.\n",
      "\n",
      "answer:\n",
      "['B', 'A']\n",
      "\n",
      "complexity:\n",
      "0.5235098992505121\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k, v in ao_tf['train'][0].items():\n",
    "    print(f\"{k}:\\n{v}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T09:41:02.670408Z",
     "iopub.status.busy": "2024-11-13T09:41:02.669954Z",
     "iopub.status.idle": "2024-11-13T09:41:02.756432Z",
     "shell.execute_reply": "2024-11-13T09:41:02.755274Z",
     "shell.execute_reply.started": "2024-11-13T09:41:02.670366Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cd1b8790e99455fbb784619664a1c67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/596 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de59c30c5b4447a887e112501f956ac5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84599de1b5e64914917ceff2151aba0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/70 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ao_tf.save_to_disk('dataset/saved/action_ordering_v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload dataset and video to hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['video_id', 'duration', 'captions_starts', 'captions_ends', 'question_normal', 'question_robust', 'answer', 'complexity'],\n",
       "        num_rows: 596\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['video_id', 'duration', 'captions_starts', 'captions_ends', 'question_normal', 'question_robust', 'answer', 'complexity'],\n",
       "        num_rows: 50\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['video_id', 'duration', 'captions_starts', 'captions_ends', 'question_normal', 'question_robust', 'answer', 'complexity'],\n",
       "        num_rows: 70\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ao_tf = load_from_disk('dataset/saved/action_ordering_v2')\n",
    "ao_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T09:41:07.514021Z",
     "iopub.status.busy": "2024-11-13T09:41:07.513231Z",
     "iopub.status.idle": "2024-11-13T09:41:07.525279Z",
     "shell.execute_reply": "2024-11-13T09:41:07.524251Z",
     "shell.execute_reply.started": "2024-11-13T09:41:07.513978Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "634"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos_to_upload = set(ao_tf['train']['video_id'] + ao_tf['test']['video_id'] + ao_tf['validation']['video_id'])\n",
    "len(videos_to_upload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T09:45:25.824886Z",
     "iopub.status.busy": "2024-11-13T09:45:25.824007Z",
     "iopub.status.idle": "2024-11-13T09:45:25.831507Z",
     "shell.execute_reply": "2024-11-13T09:45:25.830275Z",
     "shell.execute_reply.started": "2024-11-13T09:45:25.824828Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if not os.path.isdir(\"dataset/videos/action_ordering_v2\"):\n",
    "    os.makedirs(\"dataset/videos/action_ordering_v2\")\n",
    "for vid_id in videos_to_upload:\n",
    "    shutil.copy(f\"dataset/videos/download/{vid_id}.mp4\", f\"dataset/videos/action_ordering_v2/{vid_id}.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T09:46:40.111710Z",
     "iopub.status.busy": "2024-11-13T09:46:40.110832Z",
     "iopub.status.idle": "2024-11-13T09:46:46.109397Z",
     "shell.execute_reply": "2024-11-13T09:46:46.108347Z",
     "shell.execute_reply.started": "2024-11-13T09:46:40.111668Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "640db2a03f364e11a3f54dda635973e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5615cb1c91a144209219eae14a1b0f5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3767b28435d843ffb5bc2b77f8f5ed61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2293e3dfa6d742398ef86e60092fdd77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b124d7d17624f70b3fc46148b44f2c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b4a6fe1b1224259867265e09836e6d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/jwnt4/a-temporal-upgrade/commit/cd2bf1e721ccf8ff089db02c5ee50b8fdb37f6bb', commit_message='Upload dataset', commit_description='', oid='cd2bf1e721ccf8ff089db02c5ee50b8fdb37f6bb', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/jwnt4/a-temporal-upgrade', endpoint='https://huggingface.co', repo_type='dataset', repo_id='jwnt4/a-temporal-upgrade'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ao_tf.push_to_hub(DATASET_REPO, 'action_ordering_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T09:56:51.554838Z",
     "iopub.status.busy": "2024-11-13T09:56:51.553907Z",
     "iopub.status.idle": "2024-11-13T10:03:01.238215Z",
     "shell.execute_reply": "2024-11-13T10:03:01.236772Z",
     "shell.execute_reply.started": "2024-11-13T09:56:51.554795Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/t-i.jiwanta/dev/ai/a-temporal-upgrade/dataset/videos/zip/action_ordering_v2.zip'"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the archive\n",
    "shutil.make_archive('dataset/videos/zip/action_ordering_v2', 'zip', \"dataset/videos\", 'action_ordering_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T10:55:01.510041Z",
     "iopub.status.busy": "2024-11-13T10:55:01.509636Z",
     "iopub.status.idle": "2024-11-13T11:00:11.885068Z",
     "shell.execute_reply": "2024-11-13T11:00:11.883952Z",
     "shell.execute_reply.started": "2024-11-13T10:55:01.510003Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9a9d1686b6b4a85b62725de11dab9e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "action_ordering_v2.zip:   0%|          | 0.00/1.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/jwnt4/a-temporal-upgrade/commit/5458158640f39bc45cd68e4c7baf2bb3122bcd39', commit_message='Upload videos/action_ordering_v2.zip with huggingface_hub', commit_description='', oid='5458158640f39bc45cd68e4c7baf2bb3122bcd39', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/jwnt4/a-temporal-upgrade', endpoint='https://huggingface.co', repo_type='dataset', repo_id='jwnt4/a-temporal-upgrade'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api = HfApi()\n",
    "api.upload_file(\n",
    "    path_or_fileobj=f\"dataset/videos/zip/action_ordering_v2.zip\",\n",
    "    path_in_repo=\"videos/action_ordering_v2.zip\",\n",
    "    repo_id=DATASET_REPO,\n",
    "    repo_type=\"dataset\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moment retrieval dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T15:42:34.166009Z",
     "iopub.status.busy": "2024-11-15T15:42:34.165597Z",
     "iopub.status.idle": "2024-11-15T15:42:39.395680Z",
     "shell.execute_reply": "2024-11-15T15:42:39.394381Z",
     "shell.execute_reply.started": "2024-11-15T15:42:34.165968Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['video_id', 'video_path', 'duration', 'captions_starts', 'captions_ends', 'en_captions'],\n",
       "        num_rows: 596\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['video_id', 'video_path', 'duration', 'captions_starts', 'captions_ends', 'en_captions'],\n",
       "        num_rows: 70\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['video_id', 'video_path', 'duration', 'captions_starts', 'captions_ends', 'en_captions'],\n",
       "        num_rows: 50\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset using huggingface datasets\n",
    "ds_processed = load_from_disk(\"dataset/saved/processed2\")\n",
    "mr = DatasetDict({\n",
    "    \"train\": ds_processed['train'].select(range(1192//2, 1192)),\n",
    "    \"test\": ds_processed['test'],\n",
    "    \"validation\": ds_processed['validation']\n",
    "})\n",
    "mr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_prompt = \"\"\"Your task is to determine the frame range that best represents an action in the video.\\\n",
    " Provide your answer as two numbers separated by a comma, where the first number is the first frame correlated to the action and the second number is the last frame correlated to the action.\\\n",
    " Do not provide any other explanation in your response.\n",
    "Here is an example: Suppose the video has frames numbered from 1 to N (N is the number of frames sampled). \\\n",
    "If the action in question is \"a man sings on the street\" and the frames that has the most similarities with this action are 5, 6, and 7 your answer should be: \"5, 7\" (this is an example).\n",
    "Number of frames sampled in this video: <num_frames>\n",
    "Here is the video context: {context}\n",
    "Here is the action in question: <action>\n",
    "Here is the question: What is the frame range (start, end) in the video that best represents the action asked?\"\"\"\n",
    "\n",
    "timestamp_prompt = \"\"\"Your task is to determine the timestamp range that best represents an action in the video. \\\n",
    "Use the provided frame-to-timestamp mapping to associate the timestamps with the actual video frames. \\\n",
    "Find the most similar continuous sequence of timestamp with the action asked.\n",
    "Provide your answer as two timestamps in the format \"mm:ss, mm:ss\" (e.g. \"00:10, 00:30\"), where the first timestamp is the start time of the action and the second timestamp is the end time of the action. \\\n",
    "Do not provide any other explanation in your response. \n",
    "Duration of the video: <duration>\n",
    "Number of frames sampled in this video: <num_frames>\n",
    "Here is the frame-to-timestamp mapping for this video:\n",
    "<frame_info>\n",
    "Here is the video context: {context} \n",
    "The action in question is: <action>\n",
    "The question: What is the timestamp range (start, end) in the video that best represents the action asked?\"\"\"\n",
    "\n",
    "def transform_moment_retrieval(sample):\n",
    "    capt = sample['en_captions']\n",
    "    starts, ends = sample['captions_starts'], sample['captions_ends']\n",
    "    capt_len = sorted([[i, ends[i] - starts[i]] for i in range(1, len(capt))], key=lambda e: e[1], reverse=True)\n",
    "    answers = []\n",
    "    actions = []\n",
    "    for cl in capt_len:\n",
    "        if cl[1] <= 0.95 * sample['duration'] and cl[1] >= 2: # filter out too-short or too-long actions\n",
    "            answers.append([starts[cl[0]], ends[cl[0]]])\n",
    "            actions.append(capt[cl[0]].strip())\n",
    "    \n",
    "    complexity = [capt_len[i][1] / sample['duration'] for i in range(len(capt_len))]\n",
    "    complexity = 1 - (sum(complexity) / len(complexity))\n",
    "    prompt_frame = frame_prompt.format(context=capt[0].strip())\n",
    "    prompt_timestamp = timestamp_prompt.format(context=capt[0].strip())\n",
    "    return {\n",
    "        \"prompt_frame\": prompt_frame, \n",
    "        \"prompt_timestamp\": prompt_timestamp,\n",
    "        \"complexity\":complexity, \n",
    "        \"actions\": actions,\n",
    "        \"answers\": answers,\n",
    "        \"complexity\": complexity \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_frame:\n",
      "Your task is to determine the frame range that best represents an action in the video. Provide your answer as two numbers separated by a comma, where the first number is the first frame correlated to the action and the second number is the last frame correlated to the action. Do not provide any other explanation in your response.\n",
      "Here is an example: Suppose the video has frames numbered from 1 to N (N is the number of frames sampled). If the action in question is \"a man sings on the street\" and the frames that has the most similarities with this action are 5, 6, and 7 your answer should be: \"5, 7\" (this is an example).\n",
      "Number of frames sampled in this video: <num_frames>\n",
      "Here is the video context: A mom is sitting at the top of a slide with her little baby.\n",
      "Here is the action in question: <action>\n",
      "Here is the question: What is the frame range (start, end) in the video that best represents the action asked?\n",
      "\n",
      "prompt_timestamp:\n",
      "Your task is to determine the timestamp range that best represents an action in the video. Use the provided frame-to-timestamp mapping to associate the timestamps with the actual video frames. Find the most similar continuous sequence of timestamp with the action asked.\n",
      "Provide your answer as two timestamps in the format \"mm:ss, mm:ss\" (e.g. \"00:10, 00:30\"), where the first timestamp is the start time of the action and the second timestamp is the end time of the action. Do not provide any other explanation in your response. \n",
      "Duration of the video: <duration>\n",
      "Number of frames sampled in this video: <num_frames>\n",
      "Here is the frame-to-timestamp mapping for this video:\n",
      "<frame_info>\n",
      "Here is the video context: A mom is sitting at the top of a slide with her little baby. \n",
      "The action in question is: <action>\n",
      "The question: What is the timestamp range (start, end) in the video that best represents the action asked?\n",
      "\n",
      "complexity:\n",
      "0.7116449447626068\n",
      "\n",
      "actions:\n",
      "['She finally slides down it with baby.', 'When they reach the bottom she lets him go and he starts to walk around.', 'She is contemplating going down for a while.']\n",
      "\n",
      "answers:\n",
      "[[12.319999694824219, 26.40999984741211], [26.40999984741211, 39.130001068115234], [5.28000020980835, 12.319999694824219]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = transform_moment_retrieval(mr['train'][1])\n",
    "for k, v in x.items():\n",
    "    print(f\"{k}:\\n{v}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T18:12:02.481639Z",
     "iopub.status.busy": "2024-11-15T18:12:02.481109Z",
     "iopub.status.idle": "2024-11-15T18:12:02.742772Z",
     "shell.execute_reply": "2024-11-15T18:12:02.741415Z",
     "shell.execute_reply.started": "2024-11-15T18:12:02.481591Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "246f48638b6a4d8ca750dffb54b82f89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/596 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b03c4a2d1c684adb99dffcf15938a352",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/70 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7f122a5becb4e489b0bed70dd20bb6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video_id:\n",
      "v_uIl5Tj74sLw\n",
      "\n",
      "duration:\n",
      "38.56999969482422\n",
      "\n",
      "prompt_frame:\n",
      "Your task is to determine the frame range that best represents an action in the video. Provide your answer as two numbers separated by a comma, where the first number is the first frame correlated to the action and the second number is the last frame correlated to the action. Do not provide any other explanation in your response.\n",
      "Here is an example: Suppose the video has frames numbered from 1 to N (N is the number of frames sampled). If the action in question is \"a man sings on the street\" and the frames that has the most similarities with this action are 5, 6, and 7 your answer should be: \"5, 7\" (this is an example).\n",
      "Number of frames sampled in this video: <num_frames>\n",
      "Here is the video context: a girl stands in front of a bathroom mirror and vigorously rubs her face.\n",
      "Here is the action in question: <action>\n",
      "Here is the question: What is the frame range (start, end) in the video that best represents the action asked?\n",
      "\n",
      "prompt_timestamp:\n",
      "Your task is to determine the timestamp range that best represents an action in the video. Use the provided frame-to-timestamp mapping to associate the timestamps with the actual video frames. Find the most similar continuous sequence of timestamp with the action asked.\n",
      "Provide your answer as two timestamps in the format \"mm:ss, mm:ss\" (e.g. \"00:10, 00:30\"), where the first timestamp is the start time of the action and the second timestamp is the end time of the action. Do not provide any other explanation in your response. \n",
      "Duration of the video: <duration>\n",
      "Number of frames sampled in this video: <num_frames>\n",
      "Here is the frame-to-timestamp mapping for this video:\n",
      "<frame_info>\n",
      "Here is the video context: a girl stands in front of a bathroom mirror and vigorously rubs her face. \n",
      "The action in question is: <action>\n",
      "The question: What is the timestamp range (start, end) in the video that best represents the action asked?\n",
      "\n",
      "complexity:\n",
      "0.6566416073098975\n",
      "\n",
      "actions:\n",
      "['The girl wipes her face with a towel.', 'The girl then splashes water on her face several times.', 'The girl turns on the faucet.']\n",
      "\n",
      "answers:\n",
      "[[22.3700008392334, 38.56999969482422], [9.640000343322754, 24.110000610351562], [3.2799999713897705, 12.34000015258789]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mr_transformed = mr.map(\n",
    "    function=transform_moment_retrieval,\n",
    "    remove_columns=['video_path', 'captions_starts', 'captions_ends', 'en_captions']\n",
    ")\n",
    "for k, v in mr_transformed['train'][2].items():\n",
    "    print(f\"{k}:\\n{v}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video_id:\n",
      "v__UPD2IvdQ_M\n",
      "\n",
      "duration:\n",
      "49.7400016784668\n",
      "\n",
      "prompt_frame:\n",
      "Your task is to determine the frame range that best represents an action in the video. Provide your answer as two numbers separated by a comma, where the first number is the first frame correlated to the action and the second number is the last frame correlated to the action. Do not provide any other explanation in your response.\n",
      "Here is an example: Suppose the video has frames numbered from 1 to N (N is the number of frames sampled). If the action in question is \"a man sings on the street\" and the frames that has the most similarities with this action are 5, 6, and 7 your answer should be: \"5, 7\" (this is an example).\n",
      "Number of frames sampled in this video: <num_frames>\n",
      "Here is the video context: An audience is gathered in a gymnasium to watch the gymnast on the pommel horse.\n",
      "Here is the action in question: <action>\n",
      "Here is the question: What is the frame range (start, end) in the video that best represents the action asked?\n",
      "\n",
      "prompt_timestamp:\n",
      "Your task is to determine the timestamp range that best represents an action in the video. Use the provided frame-to-timestamp mapping to associate the timestamps with the actual video frames. Find the most similar continuous sequence of timestamp with the action asked.\n",
      "Provide your answer as two timestamps in the format \"mm:ss, mm:ss\" (e.g. \"00:10, 00:30\"), where the first timestamp is the start time of the action and the second timestamp is the end time of the action. Do not provide any other explanation in your response. \n",
      "Duration of the video: <duration>\n",
      "Number of frames sampled in this video: <num_frames>\n",
      "Here is the frame-to-timestamp mapping for this video:\n",
      "<frame_info>\n",
      "Here is the video context: An audience is gathered in a gymnasium to watch the gymnast on the pommel horse. \n",
      "The action in question is: <action>\n",
      "The question: What is the timestamp range (start, end) in the video that best represents the action asked?\n",
      "\n",
      "complexity:\n",
      "0.6733681745917499\n",
      "\n",
      "actions:\n",
      "['He completes his routine, and then finishes with a flawless dismount to cheering.', 'He concentrates, and then mounts to begin his routine.', 'He performs first one, and then a second impressive handstand while gripping one handle with both hands.']\n",
      "\n",
      "answers:\n",
      "[[20.139999389648438, 48.7400016784668], [0.0, 12.430000305175781], [12.1899995803833, 19.899999618530273]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k, v in mr_transformed['train'][10].items():\n",
    "    print(f\"{k}:\\n{v}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b067aad960c54468ac50488c28ed5a65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/596 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f86410bb5ece454c810577ca79f2e2ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/70 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5cd38524ae6446abf96bc2172f0cf1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mr_transformed.save_to_disk('dataset/saved/moment_retrieval_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "mr_transformed = load_from_disk('dataset/saved/moment_retrieval_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T18:22:19.905920Z",
     "iopub.status.busy": "2024-11-15T18:22:19.905482Z",
     "iopub.status.idle": "2024-11-15T18:22:19.920808Z",
     "shell.execute_reply": "2024-11-15T18:22:19.919367Z",
     "shell.execute_reply.started": "2024-11-15T18:22:19.905877Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "624"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos_to_upload = set(\n",
    "    mr_transformed['train']['video_id'] + \n",
    "    mr_transformed['test']['video_id'] + \n",
    "    mr_transformed['validation']['video_id']\n",
    ")\n",
    "len(videos_to_upload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T18:22:50.265395Z",
     "iopub.status.busy": "2024-11-15T18:22:50.264904Z",
     "iopub.status.idle": "2024-11-15T18:22:50.273570Z",
     "shell.execute_reply": "2024-11-15T18:22:50.272411Z",
     "shell.execute_reply.started": "2024-11-15T18:22:50.265350Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if not os.path.isdir(\"dataset/videos/moment_retrieval_v2\"):\n",
    "    os.makedirs(\"dataset/videos/moment_retrieval_v2\")\n",
    "for vid_id in videos_to_upload:\n",
    "    shutil.copy(f\"dataset/videos/download/{vid_id}.mp4\", f\"dataset/videos/moment_retrieval_v2/{vid_id}.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T18:24:46.593100Z",
     "iopub.status.busy": "2024-11-15T18:24:46.592593Z",
     "iopub.status.idle": "2024-11-15T18:24:51.735209Z",
     "shell.execute_reply": "2024-11-15T18:24:51.733856Z",
     "shell.execute_reply.started": "2024-11-15T18:24:46.593052Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79d58f49cef24ffdbab60571945a91e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e6feabcb8d64acdac2e903e4c652b1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d71bf3aaa0d24b458092b96adb655ad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfef256029b149b2940774e0b1852a01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1339968d3fd6488ba597ae0496b9957a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66e7066d90944c8cb39422108b580dee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b304ccf4338f4d7ebccf6912d63f355c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/2.33k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/jwnt4/a-temporal-upgrade/commit/f7acc632236cf072eeb6470fca16c1db30616490', commit_message='Upload dataset', commit_description='', oid='f7acc632236cf072eeb6470fca16c1db30616490', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/jwnt4/a-temporal-upgrade', endpoint='https://huggingface.co', repo_type='dataset', repo_id='jwnt4/a-temporal-upgrade'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mr_transformed.push_to_hub(DATASET_REPO, 'moment_retrieval_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/t-i.jiwanta/dev/ai/a-temporal-upgrade/dataset/videos/zip/moment_retrieval_v2.zip'"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the archive\n",
    "shutil.make_archive('dataset/videos/zip/moment_retrieval_v2', 'zip', \"dataset/videos\", 'moment_retrieval_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T18:41:26.589177Z",
     "iopub.status.busy": "2024-11-15T18:41:26.588292Z",
     "iopub.status.idle": "2024-11-15T18:45:17.063267Z",
     "shell.execute_reply": "2024-11-15T18:45:17.059082Z",
     "shell.execute_reply.started": "2024-11-15T18:41:26.589126Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61c9e86bfa1a4f539e76b4798f322131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "moment_retrieval_v2.zip:   0%|          | 0.00/1.48G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/jwnt4/a-temporal-upgrade/commit/9404fca2e897f4bd4b994872a45e118328c1d0df', commit_message='Upload videos/moment_retrieval_v2.zip with huggingface_hub', commit_description='', oid='9404fca2e897f4bd4b994872a45e118328c1d0df', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/jwnt4/a-temporal-upgrade', endpoint='https://huggingface.co', repo_type='dataset', repo_id='jwnt4/a-temporal-upgrade'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api = HfApi()\n",
    "api.upload_file(\n",
    "    path_or_fileobj=f\"dataset/videos/zip/moment_retrieval_v2.zip\",\n",
    "    path_in_repo=\"videos/moment_retrieval_v2.zip\",\n",
    "    repo_id=DATASET_REPO,\n",
    "    repo_type=\"dataset\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expanding data for moment retrieval v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['video_id', 'duration', 'prompt_frame', 'prompt_timestamp', 'complexity', 'actions', 'answers'],\n",
       "        num_rows: 596\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['video_id', 'duration', 'prompt_frame', 'prompt_timestamp', 'complexity', 'actions', 'answers'],\n",
       "        num_rows: 70\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['video_id', 'duration', 'prompt_frame', 'prompt_timestamp', 'complexity', 'actions', 'answers'],\n",
       "        num_rows: 50\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mr = load_dataset(\"jwnt4/a-temporal-upgrade\", \"moment_retrieval_v2\")\n",
    "mr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['video_id', 'duration', 'prompt_frame', 'prompt_timestamp', 'complexity', 'actions', 'answers', 'action', 'answer'],\n",
       "    num_rows: 56\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_1s = mr['train'].filter(lambda e: len(e['actions']) == 1).map(lambda e: {**e, \"action\": e['actions'][0], \"answer\": e['answers'][0]})\n",
    "train_1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['video_id', 'duration', 'prompt_frame', 'prompt_timestamp', 'complexity', 'actions', 'answers', 'action', 'answer'],\n",
       "    num_rows: 842\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_2 = mr['train'].filter(lambda e: len(e['actions']) == 2)\n",
    "train_2s_arr = []\n",
    "for i in range(2):\n",
    "    train_2s_arr.append(train_2.map(lambda e: {**e, \"action\": e['actions'][i], \"answer\": e['answers'][i]}))\n",
    "train_2s = concatenate_datasets(train_2s_arr)\n",
    "train_2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['video_id', 'duration', 'prompt_frame', 'prompt_timestamp', 'complexity', 'actions', 'answers', 'action', 'answer'],\n",
       "    num_rows: 315\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_3 = mr['train'].filter(lambda e: len(e['actions']) == 3)\n",
    "train_3s_arr = []\n",
    "for i in range(3):\n",
    "    train_3s_arr.append(train_3.map(lambda e: {**e, \"action\": e['actions'][i], \"answer\": e['answers'][i]}))\n",
    "train_3s = concatenate_datasets(train_3s_arr)\n",
    "train_3s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['video_id', 'duration', 'prompt_frame', 'prompt_timestamp', 'action', 'answer'],\n",
       "    num_rows: 1213\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mr_train = concatenate_datasets((train_1s, train_2s, train_3s))\n",
    "mr_train = mr_train.map(lambda e: e, remove_columns=['answers', 'actions', 'complexity'])\n",
    "mr_train = mr_train.shuffle(seed=SEED)\n",
    "mr_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'video_id': 'v_0JgcRWHCi4c',\n",
       " 'duration': 22.780000686645508,\n",
       " 'prompt_frame': 'Your task is to determine the frame range that best represents an action in the video. Provide your answer as two numbers separated by a comma, where the first number is the first frame correlated to the action and the second number is the last frame correlated to the action. Do not provide any other explanation in your response.\\nHere is an example: Suppose the video has frames numbered from 1 to N (N is the number of frames sampled). If the action in question is \"a man sings on the street\" and the frames that has the most similarities with this action are 5, 6, and 7 your answer should be: \"5, 7\" (this is an example).\\nNumber of frames sampled in this video: <num_frames>\\nHere is the video context: A woman is seen standing in a living room with a dog holding a frisbee.\\nHere is the action in question: <action>\\nHere is the question: What is the frame range (start, end) in the video that best represents the action asked?',\n",
       " 'prompt_timestamp': 'Your task is to determine the timestamp range that best represents an action in the video. Use the provided frame-to-timestamp mapping to associate the timestamps with the actual video frames. Find the most similar continuous sequence of timestamp with the action asked.\\nProvide your answer as two timestamps in the format \"mm:ss, mm:ss\" (e.g. \"00:10, 00:30\"), where the first timestamp is the start time of the action and the second timestamp is the end time of the action. Do not provide any other explanation in your response. \\nDuration of the video: <duration>\\nNumber of frames sampled in this video: <num_frames>\\nHere is the frame-to-timestamp mapping for this video:\\n<frame_info>\\nHere is the video context: A woman is seen standing in a living room with a dog holding a frisbee. \\nThe action in question is: <action>\\nThe question: What is the timestamp range (start, end) in the video that best represents the action asked?',\n",
       " 'action': 'The woman then begins playing with the dog and spinning around the frisbee.',\n",
       " 'answer': [6.829999923706055, 16.290000915527344]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mr_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['video_id', 'duration', 'prompt_frame', 'prompt_timestamp', 'action', 'answer'],\n",
       "    num_rows: 135\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_1s = mr['test'].filter(lambda e: len(e['actions']) == 1).map(lambda e: {**e, \"action\": e['actions'][0], \"answer\": e['answers'][0]})\n",
    "\n",
    "test_2 = mr['test'].filter(lambda e: len(e['actions']) == 2)\n",
    "test_2s_arr = []\n",
    "for i in range(2):\n",
    "    test_2s_arr.append(test_2.map(lambda e: {**e, \"action\": e['actions'][i], \"answer\": e['answers'][i]}))\n",
    "test_2s = concatenate_datasets(test_2s_arr)\n",
    "\n",
    "test_3 = mr['test'].filter(lambda e: len(e['actions']) == 3)\n",
    "test_3s_arr = []\n",
    "for i in range(3):\n",
    "    test_3s_arr.append(test_3.map(lambda e: {**e, \"action\": e['actions'][i], \"answer\": e['answers'][i]}))\n",
    "test_3s = concatenate_datasets(test_3s_arr)\n",
    "\n",
    "mr_test = concatenate_datasets((test_1s, test_2s, test_3s))\n",
    "mr_test = mr_test.map(lambda e: e, remove_columns=['answers', 'actions', 'complexity'])\n",
    "mr_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['video_id', 'duration', 'prompt_frame', 'prompt_timestamp', 'action', 'answer'],\n",
       "    num_rows: 104\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_1s = mr['validation'].filter(lambda e: len(e['actions']) == 1).map(lambda e: {**e, \"action\": e['actions'][0], \"answer\": e['answers'][0]})\n",
    "\n",
    "val_2 = mr['validation'].filter(lambda e: len(e['actions']) == 2)\n",
    "val_2s_arr = []\n",
    "for i in range(2):\n",
    "    val_2s_arr.append(val_2.map(lambda e: {**e, \"action\": e['actions'][i], \"answer\": e['answers'][i]}))\n",
    "val_2s = concatenate_datasets(val_2s_arr)\n",
    "\n",
    "val_3 = mr['validation'].filter(lambda e: len(e['actions']) == 3)\n",
    "val_3s_arr = []\n",
    "for i in range(3):\n",
    "    val_3s_arr.append(val_3.map(lambda e: {**e, \"action\": e['actions'][i], \"answer\": e['answers'][i]}))\n",
    "val_3s = concatenate_datasets(val_3s_arr)\n",
    "\n",
    "mr_val = concatenate_datasets((val_1s, val_2s, val_3s))\n",
    "mr_val = mr_val.map(lambda e: e, remove_columns=['answers', 'actions', 'complexity'])\n",
    "mr_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mr = DatasetDict({\n",
    "    \"train\": mr_train, \n",
    "    \"test\": mr_test,\n",
    "    \"validation\": mr_val\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['video_id', 'duration', 'prompt_frame', 'prompt_timestamp', 'action', 'answer'],\n",
       "        num_rows: 1213\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['video_id', 'duration', 'prompt_frame', 'prompt_timestamp', 'action', 'answer'],\n",
       "        num_rows: 135\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['video_id', 'duration', 'prompt_frame', 'prompt_timestamp', 'action', 'answer'],\n",
       "        num_rows: 104\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'video_id': 'v_LSCQ1yqocHg',\n",
       " 'duration': 24.59000015258789,\n",
       " 'prompt_frame': 'Your task is to determine the frame range that best represents an action in the video. Provide your answer as two numbers separated by a comma, where the first number is the first frame correlated to the action and the second number is the last frame correlated to the action. Do not provide any other explanation in your response.\\nHere is an example: Suppose the video has frames numbered from 1 to N (N is the number of frames sampled). If the action in question is \"a man sings on the street\" and the frames that has the most similarities with this action are 5, 6, and 7 your answer should be: \"5, 7\" (this is an example).\\nNumber of frames sampled in this video: <num_frames>\\nHere is the video context: There\\'s a man standing in a kitchen and washing his hands in steel kitchen sink.\\nHere is the action in question: <action>\\nHere is the question: What is the frame range (start, end) in the video that best represents the action asked?',\n",
       " 'prompt_timestamp': 'Your task is to determine the timestamp range that best represents an action in the video. Use the provided frame-to-timestamp mapping to associate the timestamps with the actual video frames. Find the most similar continuous sequence of timestamp with the action asked.\\nProvide your answer as two timestamps in the format \"mm:ss, mm:ss\" (e.g. \"00:10, 00:30\"), where the first timestamp is the start time of the action and the second timestamp is the end time of the action. Do not provide any other explanation in your response. \\nDuration of the video: <duration>\\nNumber of frames sampled in this video: <num_frames>\\nHere is the frame-to-timestamp mapping for this video:\\n<frame_info>\\nHere is the video context: There\\'s a man standing in a kitchen and washing his hands in steel kitchen sink. \\nThe action in question is: <action>\\nThe question: What is the timestamp range (start, end) in the video that best represents the action asked?',\n",
       " 'action': 'He then turns on the water and and washes his hands.',\n",
       " 'answer': [12.420000076293945, 20.040000915527344]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mr['train'][17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b101d23b8a2044a484ab9b86a14930c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaac3f6d2e024db299a96672e389e8b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb1cef2198e345278b1b3cb552b92772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b40a69b1678491ab01cd95b19f522f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e59f75413664ea485282b074b12deb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "803752620bd74cd59daff41e84bec353",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/jwnt4/a-temporal-upgrade/commit/3b24df1d52d409244af14bc6ec500a4dbc63c708', commit_message='Upload dataset', commit_description='', oid='3b24df1d52d409244af14bc6ec500a4dbc63c708', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/jwnt4/a-temporal-upgrade', endpoint='https://huggingface.co', repo_type='dataset', repo_id='jwnt4/a-temporal-upgrade'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mr.push_to_hub(\"jwnt4/a-temporal-upgrade\", \"moment_retrieval\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "env_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
